<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[@数据库分库分表]]></title>
    <url>%2F%E6%9C%AA%E5%88%86%E7%B1%BB%2Ffa7ac743.html</url>
    <content type="text"><![CDATA[为什么要分表？当一张表的数据达到几千万时，查询一次所花的时间会变多。 数据量多大的情况下需要分库分表？当某张表的数据量已达到千万甚至上亿（如 1000 万），同时日增数据量在 2%以上。 当然具体需要观察这张表的写入和查询是否已经影响正常业务执行，比如查询速度明显下降，数据库整体 IO 居高不下等。 分表策略 按范围进行划分 按时间范围进行划分，如月表、季度表等 按主键范围进行划分，如 1-10000，10001-20000 此种分表方式适合对数据做归档处理，如：系统默认只提供近三个月历史数据的查询功能，只需要把三个月之前的数据单独移走备份即可 优点：自带水平扩展，不需要过多干预缺点：可能会出现数据不均匀的情况（如某个月数据激增） Hash按照日期范围或主键范围进行水平拆分固然简单，但适用范围比较窄，毕竟大部分数据查询都不想带上时间。如：某用户想查询其所有订单信息。 故，需要调整分表维度，分表算法可以采用主流的 hash+mod的组合。这是一个经典算法，HashMap就是这样存储数据的。 此处的hash便是将我们需要分表的字段进行一次散列运算，使得经过散列的数量尽可能的均匀且不重复。若这个字段为一个整型且不重复则可以省略该步骤，直接进行MOD得到分表下表即可。 分表数量选择（mod 取多少）？上图中的 64是有讲究的，具体设置多少无标准值，需要根据自身业务发展，数据增量进行评估。 大致的经验为： 至少要保证分好之后的小表在业务发展的几年之内都不会出现单表数据量过大（如达到千万级）。但建议在数据库可接受的范围内尽可能的增大这个分表数，毕竟如果后续小表也达到瓶颈需要再进行一次分表扩容，那是非常痛苦的。 并且建议mod的值，与 HashMap 一样，为2^n，这样可以方便在扩容的时候尽可能的少迁移数据 Range + Hash如一开始采用的是 Hash 分表，但是数据增长巨大，导致每张分表数据很快达到瓶颈，这便不得不再做扩容，比如由 64 张表扩容到 256 张表。 但扩容时，要做到不停机迁移数据非常困难，即便是停机，需要停多久，也是个问号。 所以，是否可以在 Mod 分表的基础上再进行水平分表（如：月表），借助于 Range 自身的扩展性就不用考虑后续数据迁移的事情了。（该方式理论可行，未实践过） 数据迁移分表策略确定好后，只是完成了分表的第一步，真正麻烦的是数据迁移，或者说如何做到对业务最小的数据迁移。（除非是一开始就做了分表，所以数据迁移这一步是肯定跑不掉的） 一旦分表上线后所有的数据写入、查询都是针对于分表的，故原有大表内的数据必须迁移到分表里，不然对业务的影响极大 一张 2 亿左右的表进行迁移，大概需要花 4~5天左右的时间才能完成迁移 意味着这段时间内，以前的数据对用户时不可见的，显然这样业务不能接受 兼容处理办法：分表改造上线后，所有新产生的数据写入分表，但对历史数据的操作还走老表，这样就少了数据迁移这一步骤 只是需要在操作数据之前做一次路由判断，当新数据产生的足够多时（如两个月左右），几乎所有的操作都是针对于分表，再从库启动数据迁移，数据迁移完毕后将原有的路由判断去掉 最后所有的数据都从分表产生和写入 业务兼容同时分表之后需要家金融其它业务，如原有的报表业务、分页查询等，该如何处理？ 报表未分表前，查询一张表就可以了，分表后，一张表变为 N 张表。 所以原有的查询需要调整为遍历所有的分表，考虑到性能可以利用多线程并发查询分表数据然后汇总。 但只依靠 Java 来对大量的数据做统计分析还是不现实，后续还得用上大数据平台来处理。 分页查询原有的分页查询肯定是不能用了，毕竟对上亿的数据分页其实没什么意义。 只能提供通过分表字段的查询，比如是按照订单 ID 分表，但查询条件就得带上这个字段，不然就会涉及到遍历所有表。这也是分表后都会遇到的一个问题，除非不用 Mysql 这类关系型数据库。 分库分表完成后可以解决单表的压力，但数据库本身的压力并没有下降。 在完成分表后的一个月内由由于数据库里“其他表”的写入导致数据库 IO 增加，而且这些“其他表”还和业务关系不大。 可以把这几张表单独移到一个新的数据库中，完全和现有的业务隔离开来。 这便会设计到几个改造： 应用自身对这些数据的查询、写入都要改为一个独立的dubbo服务，由这个服务对迁移的表进行操作 暂时不做数据迁移，所以查询时也得按照分表做一个兼容，如果插叙老数据就要在当前库查询，新数据就要调用dubbo接口进行查询 对这些表的一些关联查询改造为dubbo接口，在内存中进行拼接即可 若数据量确实很大，可将同步的dubbo接口换为写入消息队列来提高吞吐量 总结最后需要做一步历史数据归档的操作，将 N 个月之前的数据定期迁移到HBASE之类存储，保证MYSQL中的数据一直保持在一个可接受的范围。 而归档数据的查询便依赖于大数据提供服务。 参考文献 MYSQL 分库分表-51CTO 一次难得的分库分表实践 Mysql分页查询]]></content>
      <categories>
        <category>未分类</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@CentOS7下安装Nginx]]></title>
    <url>%2Fmanual%2Fe3099e01.html</url>
    <content type="text"><![CDATA[环境：centos7.5 step1: 安装依赖 1yum install -y gcc gcc-c++ prce prce-devel zlib zlib-devel openssl openssl-devel step2: 下载 stable 版 nginx，下载地址：http://nginx.org/en/download.html step3：解压编译安装下载下来的为源码包，如：nginx-1.16.1.tar.gz，需要编译才可安装，编译安装时，若不指定任何参数，以默认方式安装，nginx 将被安装在 /usr/local/nginx 12345tar -xzf nginx-1.16.1.tar.gzcd nginx-1.16.1./configuremakemake install 常用命令123456789101112131415161718cd /usr/local/nginx/sbin# 指定配置文件启动 nginxnginx -c xxx.conf# 不启动 nginx 下，验证nginx 配置文件是否有错误nginx -t# 显示版本信息nginx -v# 显示详细版本信息，包括 gcc 版本，系统版本等nginx -V# 停止服务，处理完当前所有请求再停止服务nginx -s quit# 强制停止 nginxnginx -s stop# 使正在运行的 nginx 重新加载配置文件nginx -s reload# 日志文件回滚，会将当前日志改名或转移备份，再打开一个新的日志文件，可防止日志文件过大nginx -s reopen]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@yum离线下载安装软件包]]></title>
    <url>%2Fmanual%2F1281edc4.html</url>
    <content type="text"><![CDATA[问题：如何在不能联网且缺少 yum 源的 redhat/centos 机器中搭建 gitlab 服务器？如何才能解决安装 gitlab 时，缺失相关依赖包的问题？ 解决方案：在一台可以联网的机器中，下载好所有安装包，再导入到不可联网的机器中，通过 rpm -ivh 的方式进行安装。（这台可联网的机器应该与不可联网的机器操作系统版本及其内核版本一致，且最好是初始安装的系统，可通过 docker/虚拟机的方式临时配置一台） step1. 安装 yum-plugin-downloadonly 插件1[root@localhost ~]# yum install -y yum-plugin-downloadonly 安装完成后，在使用 yum 的时候使用 --downloadonly 参数。这个参数将告诉yum只下载程序包，不进行安装，而且可在控制台中看到安装该包所需要的所有依赖，如，下载 openssh-server包：1[root@localhost ~]# yum install --downloadonly openssh-server -y 注：--downloadonly参数将自动下载程序包安装时所需要的所有依赖，所以建议在全新的系统中使用本命令，因为在已经安装过部分依赖的系统上，yum 不会将所有需要的依赖下载完全此时要下载的程序包已经被放置到了 yum 的默认存放位置，在 CentOS 6 x86_64 下，这个默认路径是：/var/cache/yum/x86_64/6/&lt;repo&gt;/packages/如果要指定 yum 的下载目录，还需要一个 --downloaddir 参数，如：1[root@localhost~ ]# yum install —downloadonly —downloaddir=. openssh-server -y 结果如下： 可以看到安装包已经下载到当前目录下了： 下载完成后，在不可联网的机器执行下面的命令进行安装：12345[root@localhost ~]# rpm -ivh openssh-server-5.3p1-124.el6_10.x86_64.rpm \openssh-5.3p1-124.el6_10.x86_64.rpm \openssh-askpass-5.3p1-124.el6_10.x86_64.rpm \openssh-clients-5.3p1-124.el6_10.x86_64.rpm \openssl-1.0.1e-57.el6.x86_64.rpm 参考文献 CentOS 7 Yum离线下载安装软件包]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@CentOS6下搭建 gitlab]]></title>
    <url>%2Fmanual%2F20173b43.html</url>
    <content type="text"><![CDATA[step1. 安装相关的依赖1[root@localhost ~]# yum install -y curl policycoreutils-python openssh-server cronie step2. 安装邮件服务，亦可使用别的邮件服务，如：smtp 等，可参考此文。123[root@localhost ~]# yum install -y postfix[root@localhost ~]# service postfix start[root@localhost ~]# chkconfig postfix on step3. 安装 gitlab1234# 下载安装脚本，配置gitlab 源[root@localhost ~]# curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh | bash# 安装 gitlab-ee[root@localhost ~]# yum install -y gitlab-ee step4. 修改 /etc/gitlab/gitlab.rb，配置 gitlab 并启动12345678910vi /etc/gitlab/gitlab.rb#修改访问地址以及默认端口，为如下：external_url 'http://gitlab.seyvoue.com'unicorn['port'] = 18080#初始化 gitlabgitlab-ctl reconfigure#启动 gitlabgitlab-ctl start#查看 gitlab 状态gitlab-ctl status step5. 若 gitlab 布置在虚拟机中，需要在宿主机 hosts 文件增加：1虚拟机IP external_url step6. 验证。在浏览器中访问 http://gitlab.seyvoue.com/ 即可 参看链接 Omnibus package installation 从零开始搭建Gitlab服务器 搭建Gitlab+maven+jenkins持续集成环境]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@CentOS6下安装配置jenkins]]></title>
    <url>%2Fmanual%2F77bc273.html</url>
    <content type="text"><![CDATA[step1. 安装 Jenkins123[root@localhost ~]# yum install jenkins#查看 Jenkins 安装路径[root@localhost ~]# rpm -ql jenkins step2. 修改默认端口 80801234[root@localhost ~]# vi /etc/sysconfig/jenkins:set ignorecase/jenkins_portJENKINS_PORT=“8000” 注：若本机的 jdk 环境并非使用的是系统自带的 openjdk，而是通过在 /etc/profile 等中配置环境变量的方式安装的 jdk 环境的话，需要在 /etc/init.d/jenkins 中添加你自己安装的 jdk 路劲，12345678910[root@localhost ~]# vi /etc/init.d/jenkinscandidates="/usr/local/jdk1.8.0_121/bin/java &lt;==在这里添加你的 jdk 路径/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/bin/java"]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@CentOS6.4下安装 docker]]></title>
    <url>%2Fmanual%2F9cb3f9b7.html</url>
    <content type="text"><![CDATA[step1. 创建用户 user，用于之后 docker 启动、停止、运行的默认用户1234567#创建用户 user[root@localhost ~]# useradd user[root@localhost ~]# passwd user#给 user sudo 权限[root@localhost ~]# visudoadd the following lineuser ALL=(ALL) NOPASSWD: ALL step2. 配置 docker yum 源1234567[root@localhost ~]# vi /etc/yum.repo.d/docker.repo[docker-repo]name=Docker Repobaseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/enabled=1gpgcheck=1gpgkey=https://yum.dockerproject.org/gpg step3. 安装 docker-engine，并将其配置为系统服务123456789[root@localhost ~]# su - user[user@localhost ~]$ sudo yum install docker-engine[user@localhost ~]$ sudo chkconfig docker on[user@localhost ~]$ sudo service docker start[user@localhost ~]$ sudo service docker statusdocker (pid 3389) is running…[user@localhost ~]$ ps aux | grep dockerroot 3189 3.0 0.5 466152 22552 ? Sl 05:26 0:16 /usr/bin/docker -duser 3568 0.0 0.0 103232 864 pts/0 S+ 05:35 0:00 grep docker 注：若出现以下情况，需要升级 device-mapper-libs 包，如下1234[user@localhost ~]$ sudo service docker stautsdocker dead but pid exists#若出现以上的情形，可以通过升级 device-mapper-libs 包，或者 yum update -y 的方式更细系统版本到最新版本[user@localhost ~]$ sudo yum update -y device-mapper-libs step4. 将 user 添加到 docker 用户组中，并验证是否可通过 user 用户使用 docker 基本功能1234567891011[user@localhost ~]$ sudo usermod -aG docker user[user@localhost ~]$ id useruid=501(user) gid=501(user) groups=501(user),492(docker)#切到 root 用户停止 docker 服务[user@localhost ~]$ exit[root@localhost ~]# service docker stop#切回到 user 用户，验证是否可使用 docker 基本功能[root@localhost ~]# su - user[user@localhost ~]$ sudo service docker restart[user@localhost ~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE step5. 下载 centos 镜像，创建并启动容器123456789101112[user@localhost ~]$ docker pull centos:centos6[user@localhost ~]$ docker pull centos:latest[user@localhost ~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEcentos centos6 4f2ed42dccff 12 weeks ago 193.9 MBcentos latest ee2526f4865b 12 weeks ago 201.8 MB[user@localhost ~]$ docker run -it —name test_docker centos:centos6 /bin/bash[root@34d076f4dac3 /]# exitexit[user@localhost ~]$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES34d076f4dac3 4f2ed42dccff &quot;/bin/bash&quot; 14 seconds ago Exited (0) 3 seconds ago test_docker 参考文献 Install docker on CentOS 6 or 7]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@构建第二大脑的方法：借助 Evernote 和 OmniFocus]]></title>
    <url>%2Fmanual%2F1b43f668.html</url>
    <content type="text"><![CDATA[写在前面构建第二大脑的重要性？ 影片 永无止境 男主角一开始是一位郁郁不得志的小说家，直到某天服下一种药物 NZT，忽然成为文思泉涌、判断力与创造力惊人的天才，有趣的是，这颗药丸到底带给原本二流小说家什么效用呢？ 我的解读是，这粒药丸的作用是让男主可以在每次需要的时候想起一生所学习、经历、阅读、思考过的所有内容，并在大脑内重新组织连接，于是当他写小说时可以旁微博引自己过去所有累积的资料，当他分析股市时可以统整过去所有的案例来做出更好的分析，简单来说，这粒药丸让男主： 把过去所有的积累，善用到每一个当下情境 不是我沒有才能，而是我沒有善用自己過去的积累：其实我们大多数人就像是 「永无止境」电影里一开始的男主角，或许觉得自己缺乏创意、觉得自己效率低下，但这并不表示我们才能不足，而很有可能是因为我们 「没有办法善用自己过去的积累」： 文章需要多一個引文，却忘记自己几年前读过的书里面有相关的资料企划需要一个新想法，却忘记自己几年前有相似的思考与笔记问题需要一个解决方案，却忘记自己曾遇过、看过类似问题并解决掉工作需要一个新计划，却没有善用自己过去曾做过的类似工作架构 工作与思考上的双重时间浪费：比起「重新去找」、「从头再想」，遇到什麼工作都先开始找新资料、新方法，却没有好好珍惜与利用之前花时间积累的东西，相当于「双重时间浪费」：浪費了过去认真努力过的时间，也浪费了现在必须从头努力的时间。 要怎样解决这个问题呢？拥有「第二大脑」这样的知识库就是必要的。让我们的第一大脑，与透过工具构建的「第二大脑」同时运作，就类似「永无止境」电影里吃了药的男主角一样，当我们可以跟过去的自己取经，并且在翻越高山时永远都「先从已经积累的地方开始往上爬」，那么我们就可以持续的向上前进，而不会每次都要从头开始踏步。 本文将与大家分享的是我如何利用 evernote 构建第二大脑的实践经验。 概述目标： 把过去自己所有的累积，善用到当下每一个情境 给大脑减负，让其承担“CPU”和“内存”的角色，工具承担“硬盘”角色 每天的工作始于印象笔记终于印象笔记 方案： 将自己所有的阅读、学习、思考、想法、计划和资料都放入 evernote 中 通过 evernote 的笔记本+标签（轻分组重标签），构建网状的知识结构 使用搜索功能，获得过往经验/知识 借助GTD工具如 OmniFocus，与 evernote 协同工作，以更好的管理时间，让计划/任务可以高效顺利的完成。 下文将从以下几个方面进行展开： 如何搭建一个系统化的笔记框架？包括笔记本如何分类，标签系统如何构建 如何打通 evernote 和 OmniFocus？通过 evernote 中的 GTD 标签，借助 IFTTT 工具，将 evernote 和 OmniFocus 连接 如何利用好这个笔记框架？使其在一定程度上成为“第二大脑” 注：evernote 对应知识管理，OmniFocus 对应时间管理 下面的导图即为最终的笔记框架，你可以根据本文的方法构建一套属于你自己的： “第二大脑”的特性这部分描述我们所构建的“第二大脑”—— evernote，应该具备哪些特性（是什么样的？），有什么作用。 是行动指南 当我们打开 evernote 时，我们便可以知道在未来一段时间（短期/长期），我们需要做什么，如何做 是收藏夹 我们可以将自己的灵感、想法、思考、欲望清单（想买、想去、想看等）、会议记录、读书笔记、学习笔记，有价值的帖子、资料，快速的记录/收藏到 evernote 中 是工作室 当有一个项目、长期计划、复杂的任务等需要我们投入大块时间去专注完成的时候 是知识库（第二大脑的核心） 单纯的累积或收集也会有帮助，但那终究是他人的，你需要的是一个 「自己曾经思考过的」 个人知识库，一个更完整、并且可以随时向它取经的「过去的自己」。 笔记本分类策略笔记本分类原则： 不要将笔记本作为分类笔记的载体，应该将其当做我们工作流中的一环。（因为若以笔记本作为分类笔记的主体，最终的结果是得到一个树状结构的知识库，显然这并不是一个好的策略） 让笔记本的分类，一定程度上代表笔记的加工程度。比如：对于直接从微信公众号剪藏过来的笔记，就是未经过加工处理过的，不要偷懒的以为一篇有价值的文章被你收藏到笔记本中就属于你了，这篇笔记中的内容也许当下你已经理解/消化了，但并不表示未来的某一刻，当你真正需要它的时候，它就能再次的出现在你的面前，你需要将它纳入到你的知识体系中，并可被索引到。 印象笔记工作流：计划 -&gt; 收集 -&gt; 练习 -&gt; 归档 -&gt; 分享 -&gt; 总结 首先制定计划，明确要做什么，并制定行动指南；然后在执行的过程中，你需要收集资料/他人的经验，或者记录下突然冒出的想法/灵感；通过不断的投入时间/精力，不断的学习和总结；最终完成制定的一项项计划/任务，并将最终的结果/总结/经验存档；通过各种形式分享给他人以反哺，并定期反思/回顾过去一段时间的学习，以此形成一个闭环。 根据以上的工作流，我将笔记本分为了七大类： 0Ability 这个笔记本组对应「计划」这个工作流。我是根据我希望具备的能力这个粒度进行分类的，比如：专业、工具控等等 1Inbox 这个笔记本组对应「收集」这个工作流。我是根据信息的来源、原创与否进行分类的，比如：剪藏、快速笔记、灵感等。 2Workspace 这个笔记本组对应「练习」这个工作流。选择使用「练习」这个词是受到格拉德威尔《异类》一书中提出的「一万小时定律」（刻意的训练）的启发，只是在这里，我将近期我需要投入大量时间/精力的内容，以项目/专题为粒度放入这个笔记本组中，当我完成后便从该笔记本组中移除并归档，以表示我完成了并从形式上表征我最近需要做的几件比较重要的事。 3KnowledgeBase 这个笔记本组对应「归档」这个工作流。以“知识库”命名，是因为该笔记本组中的所有笔记均经过分类和消化最终纳入到自己构建的知识体系中了，每一篇均有再利用的价值，且很容易的被搜索到。 4Share 这个笔记本组对应「分享」这个工作流。将学习成果/经验分享到博客，分享是最好的学习检验。 5Review 这个笔记本组对应「总结」这个工作流。像什么月度总结、年度总结都在这里。 [Archive] 设立这个笔记本组，是为了将形成 「知识库」的中间产物，以及之前制定的计划和行动指南封存。一方面就是单纯的将过去封存，另一方面也是写总结报告的参考来源。 以上笔记本中有两个特殊笔记本 11Memo 和 [DayLog]，前者记录灵感，后者相当于日志（不是日记，相当于流水账），这两个笔记本中的笔记我是借助 alfred 工具，自动产生的。 比如：我在网上冲浪的时候，突然冒出了某个想法，此时我只需要，连按两下 option键，就会弹出 Alfred，然后我只需要记录我当下的想法，便会在 evernote 的 11Memo 笔记本中自动记录下这个内容，并会附带时间戳以及正打开的那个网页，当我未来某一天将这个想法落地后，我还以在时间戳前面的框框中打上 ✅，非常方便。如下图： 标签系统构建策略笔记本承担了工作流的载体，标签则承担了将笔记连接成更易检索的网状结构的载体。 虽然即使我们没有打好标签，依旧可以从 evernote 中搜索到部分我们所需要的内容，但随着时间的推移和笔记数量的增多，若前期没有规划好标签，那些曾经的笔记将会石沉大海很难再检索到。 比如，在使用 evernote 初期，对于剪藏的笔记我都自动保存到默认笔记本中，对于一些比较重要的笔记我也会打上一些跟笔记主题相关的标签，但随着 evernote 体量的增大，仅仅这个默认笔记本就有1000多条，这可如何是好，难道把笔记本重新分类？不打上标签如何证明我看过/消化了？以后又怎么应用和检索这些资料？… 所以最终我决定采用 笔记本+多标签 的形式分类这些笔记，且以“偏重标签”而不是“偏重分组”的方式进行笔记的分类，又对标签系统做了大致的规划，以应对笔记本体量越来越大后无法搜索到需要的相关笔记。 标签分类原则与方法基本使用原则： 注意歧义：以保证搜索时不会搜索出不相干笔记 禁用语义比较弱的词（或称用词模糊），如：“服装”标注一本书也在标注流行搭配 注意同义词标签，如：“苹果手机”和“iphone” 标签尽量不要与笔记中任何词语重复 标签不是越多越好 需要添加什么标签？ 用问题产生标签，如：是什么？为什么？怎么做？… 思考你希望这条笔记会在哪些场景下被搜索到。如：当你在准备一次培训时，你在网上发现了一篇帖子可被用到培训中，那么你需要给这篇笔记贴上，“素材”、“xxx培训”等标签 重点不是看到上面，而是想到什么 如何判断是否有必要添加标签？ 如果一条笔记即使不添加标签，也能确保下次当需要它的时候也可被搜索到，则可以不添加标签 当一篇笔记你觉得不需要添加标签的时候，你就要考虑这篇笔记是否有存在 evernote 中的必要了标签的格式？ 能用中文就不要用英文，用英文就全用小写 能用全程就尽量不要用简称，根据出现频率和检索习惯来 注意标签中若带有符号，不要与搜索语法有冲突，如：*, -等 标签中的符号都应以英文状态下输入。如：不要出现【】，而应该是[] 每个便签最好都在最前面打上通配符，如此便不仅可以让标签按照你所希望的顺序在标签系统中排列，还可以让你更快的打上标签。如：在标签名最前面加上 “.”, “@“, “~”等通配符 标签分类方案首先对于 evernote 中的笔记我划分了两大类： 原创：这部分笔记最终都会归入到 30Library 笔记本中 非原创：这部分笔记会先默认保存到 12Clipped 笔记本中，打过标签后最终都会归入 31References 中 其次对于标签系统，我将所有的标签分为三大类：（标签的具体分类见最前面） .description描述信息类标签。这类标签类似于 html 网页中的 meta，分别从 rating, what, when, where, who几个维度描述这条笔记 .projects项目类标签。区别于 2Workspace 笔记本，笔记本中仅仅只存放了与项目相关的原创笔记，而标签中的笔记还包含了非原创的笔记，而且当项目完成后，2Workspace 中的项目笔记本是会被移除的最终所有与项目相关的笔记、收集的文章等都会打上对应的项目标签 .keywords关键词类标签。为笔记打上与其文章主旨相关的标签。 这里重点探探 .descrption 标签 在收藏一篇文章前，我们要先问问自己，这篇文章的核心价值是什么？ 所以，我在 .description 标签下设立了 .what 标签，将文章的核心价值分为了四大类： 观点 综述 手册 经验 这样做的目的是通过这个标签组我们可以更快的知道，可以从这条笔记中获得什么： 获得：一个 idea 获得：对某件事的整体认识 获得：对某个问题的解决方法 获得：获得他人的经验，以对事物有个更深的认识 .projects &gt; .descriptions &gt; .keywords 三类标签以不同的粒度对笔记进行了分类 下表即为最终的分类方案： 如何将 evernote 与 OmniFocus 进行连接关于如何将 evernote 和 GTD 工具进行连接，见我的另一篇博文。 如何使用这个笔记框架回到我们建立笔记框架的初衷是为了： 每天的工作始于印象笔记终于印象笔记 给大脑减负，让其承担“CPU”和“内存”的角色，工具承担“硬盘”角色 把过去自己所有的累积，善用到当下每一个情境 对于第一点，如何实现？通过笔记本组，这个工作流的载体。 笔记本组的顺序，0Ability -&gt; 1Inbox -&gt; 2Workspace -&gt; 3KnowledgeBase -&gt; 4Share -&gt; 5Review，则代表了工作流 计划 -&gt; 收集 -&gt; 练习 -&gt; 归档 -&gt; 分享 -&gt; 总结。 每当打开 evernote： 0Ability 这个笔记本组，就会提醒我们为之奋斗的目标，以及具体的行动指南 1Inbox 这个笔记本组，则保存了我们收集到的所有资料和想法 2Workspace 这个笔记本组，则是我们工作的地方，如：200项目A，200专题B，201专题A，201项目B… 3KnowledgeBase 这个笔记本组，便是我们的结晶啦，所有自己曾经的知识/经验，都在这儿。 4Share 这个笔记本组，便是我们所分享过的内容的存档 5Review 这个笔记本组，就是定期总结 所以，我们只需要根据当前处于工作流中的哪一环，就进入相应的笔记本中就可以了。整理笔记的过程，也是你不断学习/总结的过程，这在一定程度上，也帮助你养成持续学习的习惯。另外对于 1Inbox 这个笔记本组，必定是会随着时间的推移，体量越来越大的，你需要定期清理。我是写了一个AppleScript脚本去监控 1Inbox 中的笔记，当达到前文表格中提到的清理周期，便会自动在我的 GTD 工具 OmniFocus 中建立一条待办事项，提醒我去整理笔记。 脚本 monitor.scpt 如下：123456789101112131415161718192021222324252627282930313233tell application &quot;印象笔记&quot; set tempNums to the length of (find notes of &quot;notebook:10QuickNote&quot;) set memoNums to the length of (find notes of &quot;notebook:11memo&quot;) set clippedNums to the length of (find notes of &quot;notebook:12Clipped&quot;)end tellon newInboxTask(taskName) tell application &quot;OmniFocus&quot; tell default document set theTask to make new inbox task with properties &#123;name:taskName&#125; set tagName to make new tag with properties &#123;name:&quot;Today&quot;&#125; add tagName to tags of theTask end tell end tellend newInboxTaskif tempNums &gt; 5 then display notification &quot;整理10QuickNote&quot; with title &quot;印象笔记&quot; set taskName to &quot;印象笔记：整理 10QuickNote&quot; newInboxTask(taskName)end ifif memoNums &gt; 3 then display notification &quot;整理11Memo&quot; with title &quot;印象笔记&quot; set taskName to &quot;印象笔记：整理 11Memo&quot; newInboxTask(taskName)end ifif clippedNums &gt; 30 then display notification &quot;整理12Clipped&quot; with title &quot;印象笔记&quot; set taskName to &quot;印象笔记：整理 12Clipped&quot; newInboxTask(taskName)end if 然后加了个定时任务，命令行执行crontab -e，该定时任务每四天的22:30执行一次。130 22 */4 * * osascript ~/scripts/monitor.scpt &gt;&gt; /Users/seyvoue/personal/data/scripts/logs/applescript.log 2&gt;&amp;1 参考文献 How I Organize Evernote？——A Peek Inside My Personal System 一种帮你理出头绪的笔记模版：三层空间格式法]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>alfred</tag>
        <tag>evernote</tag>
        <tag>omnifocus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@给 Mac 优雅地一键装机]]></title>
    <url>%2Fmanual%2Fa204ccfd.html</url>
    <content type="text"><![CDATA[Mac 重装系统最简单的方式就是：日常通过 TimeMachine 对 mac 进行定期备份，在重装系统时，直接用它进行还原即可。但是，如果我们想要一个更加干净的新系统，不想在新 Mac 上直接迁移旧电脑的数据，但又不想手动下载安装以前经常使用的应用程序，不想对每个应用程序重新进行个性化配置，那么，此时通过 TimeMachine 还原的方式就不适用了。 本文将介绍通过脚本实现，将新的 mac 一键恢复到之前的状态。 原理思考：首先明确我们希望 mac 恢复到什么样的状态？ 自动安装好以前常用的应用程序。不需要先回忆之前安装了哪些应用程序，然后一个一个的下载和安装 每个应用程序不需要再手动个性化配置，只需要使用以前的配置文件或者配置信息与用户绑定，登录用户后即可恢复到以前的配置 安装之前使用过的破解软件（建议如果经济允许，还是多支持正版） 几个 mac 日常安装和使用应用程序的建议： 对于 git、python等命令行软件统一使用 homebrew 下载安装 对于 chrome、qq、sublime 等 GUI 应用程序优先使用 homebrew cask 下载管理 对于 app store 中的应用程序可使用终端上的 mas 进行下载安装 如果经济允许，对于经常使用的软件，最好购买正版，不仅方便日常的升级更新，也省去了寻找破解安装包的时间，而且更安全 各软件的配置文件建议都保存在本地（如 google drive 中），这样便不会丢失配置信息，而且也方便重装软件时刻通过本地配置文件恢复到之前的使用习惯 如果你坚持按照上面的建议管理 mac 上要安装的软件，那么，本文的方法便适合你。 定期自动备份 macOS 软件列表一般而言，macOS 中软件来源及其安装位置有以下几种： Mac App Store 安装，位置：/Applications 手动下载安装，位置：/Applications Homebrew 安装，位置：/usr/local/Cellar，主要是一些命令行工具 Homebrew Cask 安装，位置：/usr/local/Caskroom，主要是各种普通软件，如 Alfred、Steam 等 还有一些软件会安装在用户目录下Applications的文件夹中（/Users/xx/Applications），如 Steam 中下载的游戏。这些一般不需要备份。 这些七零八落的软件，手动备份列表是很麻烦的。而且，我们可能经常安装或删除一些软件，需要定期更新软件列表。所以，最好能够定期自动备份，并且是保存在云上，保证数据安全。而要保存在云上，macOS 自带的 iCloud 或者 google drive 都是比较好的选择。 自动备份软件类别的脚本如下：12345678# 生成/Applications文件夹中的所有软件列表ls -lh /Applications &gt; $&#123;backupFolder_BASE&#125;/applist/All_AppList# 来自 Mac App Store 的 app 列表/usr/local/bin/mas list &gt; $&#123;backupFolder_BASE&#125;/applist/MAS_AppList # 生成 Homebrew 安装的命令行工具列表/usr/local/bin/brew list &gt; $&#123;backupFolder_BASE&#125;/applist/Brew_AppList # 生成 Homebrew Cask 安装的普通软件列表/usr/local/bin/brew cask list &gt; $&#123;backupFolder_BASE&#125;/applist/BrewCask_AppList 自动安装需要说明的是，第一行命令生成的所有软件列表，鱼龙混杂，需要你自己挑选并安装，而且如果你有使用破解软件的话，该列表中也会包含有破解软件，对于破解软件只能手动安装，所以建议手动维护一份破解软件列表。（所以，如果经济允许的话请支持正版） 后面几种可以自动安装。但是，在安装前，你应该检查列表文件，去除一些不再需要的 App，确保内容无误。 12345678910111213141516171819applistFolder=/Users/xxx/autobackup/applistappInstallerFolder=/Users/xxx/reinstall-system# 安装 Homebrew 和 MAS/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"brew install mas# 生成 MAS_AppList 安装命令cat "$&#123;applistFolder&#125;/MAS_AppList" | sed "s/(.*)//g" | sed -Ee 's/([0-9]+) (.+)/mas install \1 #\2/g' &gt; $&#123;appInstallerFolder&#125;/AppInstaller# 生成 Brew_AppList 安装命令echo "\nbrew install $(cat $&#123;applistFolder&#125;/Brew_AppList | tr '\n' ' ')" &gt;&gt; $&#123;appInstallerFolder&#125;/AppInstaller# 生成 BrewCask_AppList 安装命令echo "\nbrew cask install $(cat $&#123;applistFolder&#125;/BrewCask_AppList | tr '\n' ' ')" &gt;&gt; $&#123;appInstallerFolder&#125;/AppInstaller# 开始安装chmod u+x $&#123;appInstallerFolder&#125;/AppInstaller$&#123;appInstallerFolder&#125;/AppInstaller]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@借助 Alfred 简化博客发布流程]]></title>
    <url>%2Fmanual%2F7845c42e.html</url>
    <content type="text"><![CDATA[为了方便管理已经发布的博文，所以目前本地使用 Mweb 的外部模式对已有博文进行管理，所以整个博文发布流程变得有点繁琐，需要在终端与 Mweb 两个程序间进行不断的切换，而且每次发布过程都需要输入重复指令，如：hexo new post &#39;title&#39;, hexo clean, hexo g -d,git add -A git commit -m &#39;message&#39;等等。为了能够简化这个发布流程，选择采用 Alfred 的工作流来解决这个问题。 目前的发布流程: 为什么要在 Mweb 外部模式和文档库模式各保留一份markdown笔记？ 因为 Mweb 的外部模式，只是加载了本地目录中的文件，不具备对目录中的文件进行整理的功能（如分类、打标签等），而 Mweb 文档库模式更适合作为一个知识管理工具，所以我将所有笔记都统一使用 Mweb 文档库模式进行记录和管理，使用外部模式中管理要发布到博客的笔记。 可以看到整个发布流程有点繁琐，理想状态应该是： 解决方案：Alfred+工作流将博文发布过程自动化目前已经可以做到： nblog title：打开 Mweb 外部模式，新增一条名为”titile”的hexo博文，同时在 Mweb Library 模式中新增一篇“title”的笔记 dblog: 将新增博文发布到博客站点 sblog message: 将变更同步更新的 github。message 为：新增的博文标题 cblog：将最新的一篇博文内容复制到 Mweb Library 最新的一篇笔记中 这个解决方案，基本简化了博文的发布和创建流程，但仍旧存在以下问题： 关于博文内容复制功能cblog，可能会出现外部模式那篇博文复制到Library 模式的不同名笔记中 是否可将博文复制过程自动化op1=>operation: 以 Mweb 文档库模式（快捷键 command+L），打开 Mweb op2=>operation: 新建一条名为 “title”的笔记A op3=>operation: 打开 iterm op4=>operation: cd 到博客博目录 op5=>operation: 执行 hexo new post 'title' op6=>operation: 打开 Mweb 外部模式（command+e） op7=>operation: 找到名为“title”的博文B，将笔记A的内容复制到博文B中 op8=>operation: 给博文B打上标签、分类等博文元数据 op9=>operation: 打开 iterm op10=>operation: 在博客根目录执行 hexo g -d 发布新的博文 op1->op2->op3->op4->op5->op6->op7->op8->op9->op10{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);op1=>operation: 执行一条命令，便可在 Mweb 外部模式新增一条 hexo 博文，并打开 Mweb 外部模式，同时会在 Mweb Library 模式新增一篇同名笔记 op2=>operation: 在 Mweb 外部模式中编辑博文 op3=>operation: 执行一条命令，便可将将博文发布 op4=>operation: 执行一条命令，便可将外部模式的那篇博文内容复制到 Mweb Library 模式的同名笔记中 op1->op2->op3->op4{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>alfred</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@借助工具 OmniFocus+toggl 实践GTD]]></title>
    <url>%2Fmanual%2Fb2c3d29f.html</url>
    <content type="text"><![CDATA[GTD 即 Getting Things Done 的缩写，翻译过来就是“把事情做完”，是一个管理时间的方法。GTD 的核心理念概括就是必须记录下来要做的事，然后整理安排并使自己一一去执行。GTD的五个核心原则是：收集、整理、组织、回顾、执行。—— 百度百科 对于我来说，GTD是一种工具，可以督促我按时完成计划，并辅助我更好的制定和管理计划。下图为我的GTD流程图： 借助工具实践GTD：OmniFocus 作为任务管理、toggl 作为时间追踪。在执行 OmniFocus 中的某项动作时，使用 toggl 记录该动作的执行时间，这样做的好处是： 方便日后回顾完成每项任务所需要的时间，提高对时间的敏感度，以更好的制定计划 可以利用 toggl 实施番茄工作法，提高专注度和效率]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>effectiveness</tag>
        <tag>GTD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@用 Omnifocus 搭建任务管理系统]]></title>
    <url>%2Fmanual%2F4d5e7556.html</url>
    <content type="text"><![CDATA[笔者是一个自控力极差的拖延症患者，尝试了各种方式和工具都没能很好的解决这个问题，直到看到此文。 根据该文的思路，可以解决笔者目前在执行计划时常碰到的几个问题： OmniFocus + 番茄工作法，辅助自己更好的量化任务（目标）、完成任务 使每一个被丢进todolist 的任务都会被很好的执行。而不像之前：有些任务丢进去后由于没有回顾就忘记了，事后再看见该任务的时候，已经不想做了；有些任务制定的不够清晰，到执行的时候感觉有难度，然后拖着拖着就不做了。 什么是一个好的任务管理系统首先，任务管理系统的目的是为了更好得完成任务，一切脱离这个基本条件的系统都是不可用的。如果你觉得一个最简单的 Todo List 就能很好地完成任务，那么这就是最适合你的任务管理系统。 在我看来，一个优秀的任务管理系统至少需要满足以下条件： 收集能力 在特定的情况下知道可以做哪些事情 为什么需要至少满足这两个条件呢，或者说这两个条件对于任务管理系统来说，重要在哪里？ 收集能力指的是这个任务系统要能够容纳（几乎）所有的内容，一个任务、一条想法、一封未读的邮件、一个笔记、一个链接、没有报销的发票等等。 如果有读过《Getting Things Done》或者了解过 GTD 理论的同学可能就知道，收集 是整个流程中最开始的一环。如果要做的任务散乱在各处，难免会有遗忘的时候，任务没有被收集到，也就没有后面的处理流程了。 具体实践起来并不是真的需要把所有的东西都塞进任务系统里面，例如我使用 Evernote 作为剪裁和笔记的工具，很显然把每条笔记都复制一份到 OmniFocus 中很不现实，但是我会在 OmniFocus 中添加一个「定期清理 Evernote Inbox」的任务，这样就相当于把 Evernote 作为 OmniFocus 的子 Inbox，来统一进行管理。对于一些支持 URL Schema 的应用，完全可以在 OmniFocus 中建立一个链接直接指定，这样在 OmniFocus 中也可以直接打开其他应用中的内容了。 收集能力决定了要处理的内容，第二个条件则决定了一个任务系统是否是稳定可用的。具体的情境来说，你要知道早上的时候该干哪些事，工作的时候该干哪些事，无聊的时候又该干哪些事等。这样，在某一情境下，可以直接进入状态，而不是要花时间思考现在到底要做什么。 一个任务系统如果做好了这两件事情，那么就不会让你身处「感觉有很多事情要做，却不知道要做什么」的尴尬境地了。 任务管理系统的三要素到现在为止，我还没有讲到具体工具的使用。因为工具是次要的，了解了本质的思想，使用什么工具都没有问题。纵观各种任务管理的工具：OmniFocus、Todoist、Things、org-mode，它们支持的功能也各不相同，Project、无限层级、Defer、Due、Repeat、Context、Label、Tag、Filter、Perspective 等等，有没有被这些名词给吓到？难道我们每切换一种系统都需要再重新学习一遍？ 抛开这些名词，我们来分析一下一个任务系统到底是由什么组成的。在我看来，一个任务系统最本质的东西只有三个：任务、附加元素和过滤器。 任务：一个 最小可执行 的单元即为一个任务。这个是最好理解的，所以不做过多解释。 附加元素：作用在任务上的不同维度的限制。这句话读起来有点拗口，举个简单例子，「去 XXX 取快递（截止今天 10:00）」，其中，「截止今天 10:00」就是在时间维度上对这个任务的一个限制。同样的，「项目」、「标签」等等这些都是作用在某个任务上的附加元素。 过滤器：组合不同附加元素的过滤规则。只有附加元素并没有什么实际的作用，但是有了过滤器之后，就可以编写不同的过滤规则来过滤指定规则的任务。例如，我想知道「最近 10 天内重要的事情」，那么过滤规则可能就是「Due date &lt; 10 and flagged」。 了解了上面三个基本的概念，那么再重新审视各种任务管理工具，就可以从一个比较宏观的角度来看待了，这也可以避免切换工具造成的重新学习成本。 这三个概念和 Hum 在《用更现代的方式做任务管理》提出的「LTF（列表、标签、过滤）」理论十分类似，并且 Hum 用了更大的篇幅来叙事这个概念，有兴趣的可以订阅这个栏目阅读。 OmniFocus 3 实践把上面任务系统的基本三要素运用到 OmniFocus 上，任务就是一个个的单独 Todo item，附加元素就是 Todo item 所属的项目、Due Date、Defer Date、Tags、Flag、Repeat rule 等，过滤器就是透视（Perspective）。 接下来的内容我会通过 OmniFocus 3 为载体，来具体介绍如何实现一个可靠的任务管理系统，并介绍一些实际实践过的 Workflow 流程。 项目的设定如果想保证项目比较有序，分成三个层级即可：大的领域（Folder）- 子领域（Folder）- 项目（Project）。 例如，我的项目分级如下： 主要分成了5个比较大的项目：系统、学习、工作、生活、兴趣，基本上可以涵盖涉及到所有的领域了。在每个大的项目中再细分出小的项目，这个可以根据自己的需要进行积分。OmniFocus 支持无限极的项目划分，但是个人建议不要超过3层，最后一层直接是任务就可以了，这样可以保证项目层级不会过于复杂。 可以看到很多项目下面都有用[]括起来的项目，这个是 Single List 项目，这样一些不属于某个项目里面的内容就可以放到这个列表里了。 一些项目设定的 Tips： 如果不是 Single List，项目需要一个既定的完成条件，在某一时刻或某一条件下，这个项目是要能够被标记为 Completed 或者 Dropped，这样可以避免一个项目长时间地呆在任务系统中； 项目中的任务最好是最小可执行的，如果是比较大的任务，可以利用 OmniFocus 的无限任务层级继续细分。 标签的设定例如，我的标签如下： 一个任务在时间维度上应该有有截止日期（Due）和安排日期（Schedule）两个元素，Due 表示在某一天之前必须被完成，Schedule 表示被安排到某一天做，所以可以设定如下标签来完成 Schedule 的功能： Schedule： Today：被安排到今天 Recently：最近需要做的事 ThisWeek：被安排到这周 ThisMonth：被安排到这个月 ThisYear：被安排着这年 这样在做计划的时候，打上对应的标签，就可以使用过滤器过滤出对应的任务了，比如我想看「这个月和工作相关的任务」，那么就可以指定 Project 为「Work」项目，标签为「ThisMonth」，这样对应的任务就可以使用这个过滤器过滤出来，具体的过滤器设定下面会讲到。若一项任务没有被打上 Schedule 标签，则该任务不该被认为为一项可执行的任务，因为一项未被安排的任务在未来很有可能会被你忽略，所以，对于要添加进 OmniFocus 的任务，一定要打上 Schedule 标签，否则就不要添加进去。 另外一个可以借鉴的设定就是精力值标签： Energy LowEnergy MediumEnergy HighFocus 例如，我们工作了一整天之后，还剩一段时间才下班，精力已经下降到一个很低的值，这个时候已经不适合完成一些需要非常专注的工作了，但是一些工作上的杂事，例如打印东西，提交报表等简单的工作可以利用这个时间来完成，这个时候我们就可以设定一个过滤器，过滤出 Project 为「Work」，标签为「LowEnergy」的任务。 我们可以看到，标签系统可以极大地扩展附加元素的内容，给过滤器添加更多的过滤维度。标签系统的设定应该根据自己的需求来，如果设定的标签却没有在过滤器中用到的话，那么也仅仅是个任务添加了一个没有用上的附加元素而已，意义不大。 过滤器设定例如，我的过滤器如下： 过滤器的目的就是组合各种条件，过滤出所需要的任务来，之前所有的任务上的附加元素都是为了过滤器而设定的。 同标签系统一样，过滤器的设定依然需要结合自己的情况来。我主要设定了以下几个过滤器，这些过滤器都是在实践中经常使用到的。 Routine 过滤器这个过滤器主要被用于制定计划。例如：由于我每天晚上睡得比较晚，所以我创建了一个 Evening Review，来规划明天需要做的任务。 过滤器的详细设定如下： 其中，「Routines」Folder 中就是设定的具体内容： 这一个过滤器的设定是和我的 Workflow 紧密相连的，如果你没有做 Morning Review 之类的习惯，可以不需要设定这个过滤器。 Today 过滤器这个过滤器被使用的次数最多，过滤器的详细设定如下： 这个过滤器将会把符合以下条件的任务过滤出来： 即将截止或者标注为 Today 标签的任务 状态为 Available 的任务 非 Routine Folder 下的任务 显示方式以 Project 为维度显示： 对比 Forecast Perspective，它只是把对应的任务都展示了出来，在任务的层级上没有自定义的那么清晰。 Work 过滤器这个过滤器和 Today 类似，只不过指定了所属项目为「Work」文件夹下面的任务，这个主要是在工作中只想专注于和工作相关的任务。 过滤器的详细设定如下： 除了指定了特殊的项目目录，其他的设置和 Today 的设定没有区别。 To-Sth 过滤器日常的使用中，我会把没有看的文章、需要写的东西、要读的书、要搜索的内容都存在 OmniFocus 中，所以需要一个过滤器能够快速过滤出这些内容。 首先使用这个过滤器需要先设置一套标签系统： 过滤器的详细设定如下： 实际的使用场景：比如我想阅读一些和 Python（一门编程语言）相关的内容，那么我只需要打开这个 Perspective，挑选标签为 To-Read，然后从搜索框中搜索 Python 关键字就可以了。 Future 过滤器这个过滤器主要被用于制定计划，在 Weekly Review 和 Daily Review 中会被频繁地使用到。需要基于以下的标签设定： 过滤器的详细设定如下： EasyDo 过滤器这个过滤器会把一些简单的或者不需要太多精力的任务过滤出来。 过滤器的详细设定如下： 完成时间小于 15 分钟或者被标注为LowEnergy标签的任务会被过滤出来。 工作流在整个 Workflow 中，主要分为三个部分：计划、执行、总结。 当按照上述思路完成以 OmniFocus 对任务管理系统的搭建后： 每天我必须要完成的具体任务全部都在 Today 过滤器中 只需要根据Routine的提示，便可得到日计划、周计划、月计划 当无聊或想利用碎片时间完成一些简单的事情时，只需要去 EasyDo过滤器中去领取就可以了 阅读清单、购物清单等等只需要去To-Sth过滤器中找就可以了 并且可以从Future过滤器中知道日周月计划 计划很多人都不重视计划这个环节，想到什么做什么，这样不仅会做事没有条理，也会分不清任务的优先级。 一般来说，如果不知道怎么做计划的话，有一个长期计划和一个短期计划就可以了。长期计划主要是一个大体的方向，可以是年度计划或者月度计划；短期计划则需要明确具体要做哪些事情，可以是周计划或者日计划。 实践过程中使用最多的就是周计划和日计划，以及月计划和年计划。在 OmniFocus 中，我设定了几个项目，分别是 Morning Review、Evening Review、Weekly Review、Monthly Review、Annual Review。 Evening Review 由于我晚上睡得比较晚，所以我会在每天晚上通过 Future过滤器，从ThisWeek 和 Recently标签中的任务挑出一些作为明天的任务，并将它们打上Today标签。 Morning Review 通过Today过滤器，知悉今天要完成的任务 Weekly Review 通过 Future过滤器，从ThisMonth标签中挑选出本周的任务，并将它们打上ThisWeek标签 Monthly Review 通过 Future过滤器，从ThisYear标签中挑选出本月的任务，并将它们打上ThisMonth标签 执行执行应该是整个 Workflow 中最重要的一个环节，如果只是计划了，但是最后任务却没有被完成，那做计划也只是白费力气。 执行的关键就是要在对的时间内做对的事，这也是为什么要设置那么多过滤器的原因，在工作的时候就只展示工作相关要做的事，在没有精力的时候就只展示简单易做的事情。 如果你做事情的时候很容易分心，可以参考一下番茄工作法，一般我会设置为专注 50 分钟，然后休息 10 分钟。默认的 25 分钟时间过短，可能刚进入状态就要被打断。 另外可以尝试使用「结构化拖延法」（Structured Procrastination）。结构化拖延法就是忽略优先级高的事，而是从小的事，优先级比较低的事情开始做，这样慢慢地进入工作的状态，然后再去完成优先级高的事情。 总结OmniFocus 3 提供了自带的 Review 透视，建立每个项目的时候可以选择多少天 Review 一次。实践上，一般工作上需要每天跟进的项目，会把 Review 的时间设置为每天一次，一般的项目设置为一周 Review 一次即可。为了防止忘记 Review，可以把这个 Review 的任务添加到 Morning Review 或者 Weekly Review 中。 常用的脚本脚本的安装方法：step1: 将后缀为scpt的脚本文件拷贝到 OmniFocus 的脚本目录 (可以使用 OmniFocus 的 Help-&gt;Open Scripts Folder 直接打开);step2: OmniFocus 工具栏上右键, 在弹出的菜单上选择Customize Toolbar…, 找到新增脚本对应的 icon 拖到工具栏上即可。 任务执行时间统计脚本如果能够直接在OmniFocus中记录任务的执行时间, 并统计出任务和项目的执行时间就更好了, 所以有了本文所描述的工作。共三个AppleScript脚本文件: start.scpt, stop.scpt和report.scpt.（下载地址） start.scpt 开始一个任务, 此脚本将在该任务的标题前添加#Ongoing:, 表示该任务正在进行, 并在该任务的备注 (note) 属性尾部增加一个记录时间的字符串(或修改这个记录时间的字符串, 如果该任务之前已经开始执行过). 如果开始任务时该任务的 Defer Until 没有填写, 那么将其设置为当前时间, 作为报告中的任务开始时间. stop.scpt 停止一个任务, 该脚本可以停止已经开始的任务 (标题前有”#Ongoing:” 文本的任务, 停止后删除任务标题中的”#Ongoing”文本), 并根据该任务备注 (note) 属性中的时间记录字符串计算该任务已执行时间. 注意: 任务的执行可以分为多次启动/停止, 一个任务的总执行时间是多次执行时间之和. report.scpt 该脚本统计已完成的任务及其执行时间, 并累加各个项目中所有任务的执行时间作为项目执行时间.对原脚本 (OmniFocus&gt; Prepare Task Completion Report Version 2.0.0) 所做的修改如下: 增加一个属性用于设置保存报告的 Evernote 笔记本名称; 统计范围中增加 Year, 并设置 Today 为默认统计范围; 根据 start 和 stop 脚本记录在备注 (note) 中的时间字符串, 在报告中为任务增加执行时间数据; 统计项目执行时间, 其值为项目下的所有任务执行时间之和; 将报告的标题改为统计的日期范围; 如果某项没有设定值, 报告中将不显示该项数据; 如何使用启动任务 选中一个任务后, 点击工具栏的start 脚本图标. 任务启动后, 会弹出任务开始执行通知. 点击start脚本后, 任务标题前将添加#Ongoing:字符串, 并且任务备注 (note) 尾部将添加时间字符串. 停止任务 在任务执行一段时间需要停止时, 例如被打断或暂时休息或完成了该任务, 点击工具栏的”stop”脚本图标. 停止后的任务会记录本次任务执行的时间, 可以在备注 (note) 尾部时间字符串中看到变化. 任务停止后, 会弹出任务停止执行通知. 生成报告 任何时候点击report脚本图标, 将会首先弹出报告时间范围选择窗口, 如下图所示. 选择一个时间范围后, 点击”OK” 按钮, 将会生成统计报告并在 Evernote 的Omnifocus_reports 笔记本中创建一个统计报告, 如下图. 笔记本名称Omnifocus_reports 可以在脚本中修改. 报告中, 每个任务如果使用了start 和stop 脚本记录任务执行时间, 将会显示执行时间, 并会统计一个项目的总执行时间, 如上图中下方的蓝色文本. 注意事项 使用start和stop脚本记录任务执行时间后, 将会在该任务的备注 (note) 的尾部添加时间字符串, 不要删除它或手动修改它, 并且一定不要将备注文本放在时间字符串之后, 否则会影响执行时间的统计. 统计报告中的备注文本会自动忽略掉时间字符串; 任务开始后会在任务标题头部增加一个标记字符串#Ongoing:, 任务停止后自动删除, 不要手动修改它.]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>effectiveness</tag>
        <tag>GTD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Mac 终端配置策略：iterm2+oh-my-zsh+powerlevel9k]]></title>
    <url>%2Fmanual%2Fe5c8b56.html</url>
    <content type="text"><![CDATA[本文适用于 mac 用户原则：避免扰乱你的开发环境，尽可能使用 homebrew 来安装需要的包套件 配置完后的效果如下： 安装 iterm2step1: 使用 homebrew 安装 iterm212345# 若是第一次执行 brew cask 的话，需要先执行brew tap caskroom/cask# 安裝 iTerm2brew cask instal iterm2 step2：修改 Report Terminal Type，以支持绚丽的配色安装 iterm2 后，修改 Report Terminal Type为 xterm-256color：依次Preferences &gt; Profiles &gt; Terminal &gt; Report Terminal Type，设为xterm-256color 修改 iterm2 的配色方案设定路径：Preferences &gt; Profiles &gt; Colors &gt; Color Presets... 内建的 color scheme 不是很好看，可以去iTerm2 Color Schemes克隆到本地，然后 import 到 iterm2 中 刚才克隆下来的 iTerm2-Color-Schemes 有很多文件夹，从 schemes 資料夾裡面選一個喜歡的 color scheme，这里我选择的是 Tomorrow Night Eighties 安装 powerline font由于我们要使用的 theme 会用到很多特殊的 icon，所以 iTerm2 选用的字体必须为支持这些特殊 icon 的字体。这类型的字体统称为 powerline font（另外还有加强版支持更多特殊 icon 的为 nerd font） 若沒有安装 powerline font 的话，遇到字体所不支持的 icon 时会像这样： 安装了 powerline font 后： 支持 powerline 的字体很多，这里选用的是 Sauce Code Pro Nerd Font Complete step1：使用 homebrew 安装字体1234# 先執行這行，才能用 homebrew 安裝字型。曾經執行過的人可以跳過這個指令brew tap caskroom/fonts# 安裝指令brew cask install font-sourcecodepro-nerd-font 如果想要安装別的字体，brew 上面也有很多字型可以挑，关键词是 nerd：1brew search nerd step2：修改字体装完后，依次Preferences &gt; Profiles &gt; Text &gt; Change Font，将字体改成SauceCodePro Nerd Font或你自己下载的字体： 可能出现的问题若在切换字体后，发生 iTerm2 无法正常运作，有可能是遇到同一字体有重复版本的问题，请按一下步骤进行修改：打开 Font Book.app -&gt; 选择刚安装的字体 -&gt; 选择自动解决版本问题 设定默认 shell 为 zsh123456# 查看支持的 shellcat /etc/shells# 若没有 zsh，则安装brew install zsh# 将 zsh 设定为默认的 shellchsh -s /bin/zsh 安装 oh-my-zsh上一步装完 zsh 后，就可以开始调整我们想要的 command line 外观设定了，但是原始的 zsh 因为设定太难搞，所以多年前刚出现的时候没有受到太多关注，直到有人写了一套叫 oh-my-zsh 的 framework 来帮助大家使用 zsh，zsh 才火了起来。现在几乎所有 zsh 好用的工具都有支援 oh-my-zsh，所以当然是要装这东西。 step1：安装 oh-my-zsh1sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 注：这会直接执行 oh-my-zsh 的 install.sh 有疑虑的人可以先稍微研究一下 oh-my-zsh github 上的 install.sh，觉得放心再执行 执行完以后如果没有出现什么错误讯息就代表成功了，同时会发现多了 oh-my-zsh 的文件夹 ~/.oh-my-zsh 安装 powerlevel9k 主题刚装完 oh-my-zsh 以后，预设是使用内建的 theme robbyrussell，多了 git 资讯，颜色也看起来比原生 bash 好一些： 不过 oh-my-zsh 内建很多 theme，在它的 github wiki 上有很多截图可以参考： 切换内建的 theme 很简单，直接修改你的 ~/.zshrc，把原本 ZSH_THEME=”robbyrussell” 改成你想要的：12# 編輯 ~/.zshrcZSH_THEME=”agnoster” # 試試看把 robbyrussell 改成 agnoster 任何的 zsh 设定修改完后，还要执行以下命令才可以生效：1exec $SHELL agnoster 看起来比 robbyrussel 漂亮多了。 本文推荐 powerlevel9k 主题！文章开头的图片就来自 powerlevel9k 的 github powerlevel9k 不只是像上面的示范图显示一些基本的资讯，还可以，比如像下图那样，显示 WiFi 信号强度、笔记本剩余电量、CPU loading、system free memory 等等信息在 command line step1：克隆powerlevel9k到~/.oh-my-zsh/custom/themes/ 1git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9k step2：編輯~/.zshrc ，把 ZSH_THEME 设为 powerlevel9k123# nerd-font activePOWERLEVEL9K_MODE=&apos;nerdfont-complete&apos;ZSH_THEME=&quot;powerlevel9k/powerlevel9k&quot; Note：必须在ZSH_THEME前增加 POWERLEVEL9K_MODE，否则可能会出现部分 icon 无法显示。 step3：调整 command line 的提示符以及显示样式1234567891011121314151617# 提示符修改# command line 左侧要显示的信息POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(dir dir_writable rbenv vcs)# command line 右侧要显示的信息POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(status root_indicator background_jobs ram load history time)# 提示符分两行显示POWERLEVEL9K_PROMPT_ON_NEWLINE=true# 在提示符与要输入的指令之间增加空格POWERLEVEL9K_MULTILINE_FIRST_PROMPT_PREFIX=&quot;%f&quot;# 当前用户为 root 时，提示符为&quot;#&quot;，否则为&quot;$&quot;local user_symbol=&quot;$&quot;if [[ $(print -P &quot;%#&quot;) =~ &quot;#&quot; ]]; then user_symbol = &quot;#&quot;fiPOWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX=&quot;%&#123;%B%F&#123;black&#125;%K&#123;yellow&#125;%&#125; $user_symbol%&#123;%b%f%k%F&#123;yellow&#125;%&#125; %&#123;%f%&#125;&quot;# 没执行完一条指令在最后增加一空行POWERLEVEL9K_PROMPT_ADD_NEWLINE=true 最终的效果如下：]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@手把手教你如何搭建个人博客（五）]]></title>
    <url>%2Fmanual%2F85fb1e68.html</url>
    <content type="text"><![CDATA[本文主要介绍 Hexo 博客的SEO优化方法，让你的博客被 google 和 baidu 收录，并提高博文在搜索引擎的排名。 查看你的博客是否被搜索引擎收录在谷歌或者百度的搜索链接中，使用以下格式搜索自己的域名，如果能搜索到就说明已经被收录，反之则没有。可以直接搜索自己的域名，或者加一些关键词来更好地判断，例如：1site:seyvoue.com 提交网站到搜索引擎若未被搜索引擎收录，则需进行以下配置，首先要让搜索引擎先验证我们对网站的所有权。两个搜索引擎提交的入口分别为： Google Search Console 百度站长平台 有多重验证方式，这里选择html meta方式，将给出的元标记复制到blog/themes/next/layout/_partials/head/head.swig文件中： 123456&lt;meta charset=&quot;UTF-8&quot;/&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=2&quot;/&gt;&lt;meta name=&quot;theme-color&quot; content=&quot;&#123;&#123; theme.android_chrome_color &#125;&#125;&quot;&gt;&lt;meta name=&quot;baidu-site-verification&quot; content=&quot;qTlbubWUyw&quot; /&gt;&lt;meta name=&quot;google-site-verification&quot; content=&quot;Y9hBxOOKK4YNywVJN3FRwq2Xbry6ouA_XdM14MMdATU&quot; /&gt; 添加后运行hexo clean; hexo g; hexo d将改动提交。稍后就可以验证成功了。 给博客添加 sitemap这一步的目的在于告诉搜索引擎你的站点结构。 step1：安装插件 12$ npm install hexo-generator-sitemap --save$ npm install hexo-generator-baidu-sitemap --save step2：在Hexo 配置文件blog/_config.yml中添加： 12345#hexo sitemapsitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml step3：执行 hexo g 生成 sitemap.xml 和 baidusitemap.xml 执行完后，将会在blog/public目录下生成 sitemap.xml 和 baidusitemap.xml 提交 sitemap 到搜索引擎分别到谷歌和百度的站长工具网站上提交sitemap就可以了。如果不主动提交sitemap，搜索引擎可能无法自己找到sitemap，即使找到，速度也会很慢。 在 google search console 输入 sitemap.xml 在 百度站长平台 输入 seyvoue.com/baidusitemap.xml Note:对于百度提交链接，建议使用 主动提交链接+sitemap 的方式，具体见下文介绍。 添加 robots.txt 文件在blog/source/下新建robots.txt，告诉搜索引擎，哪些是可以爬的，哪些是不可以爬的，内容如下： 123456789101112131415161718#hexo robots.txtUser-agent: *Allow: /Allow: /archives/Allow: /tags/Allow: /categories/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: http://seyvoue.com/sitemap.xmlSitemap: http://seyvoue.com/baidusitemap.xml Google 抓取方式 如果上方的输入框留空表示抓取首页，抓取方式可以选择桌面，智能手机等等，自行根据需要选择。填好 url 之后，点击抓取。 抓取完成后可能会有几种状态：完成、部分完成和已重定向等，不过无需担心，这些状态并不会影响提交。此时点击请求编入索引即可，至此博客就成功提交到了 Google，你的博客在google搜索上排名想不靠前都难了，马上上google搜索一下你的关键词和博客title测试一下吧。 百度主动提交链接方式某些主机，比如Github，禁止百度爬虫访问博客，导致博客无法被百度收录。该方法可直接推送网页的链接给百度而避免百度无法爬取github中链接的问题。 另外，使用主动推送还会达到如下功效： 及时发现：可以缩短百度爬虫发现您站点新链接的时间，使新发布的页面可以在第一时间被百度收录 保护原创：对于网站的最新原创内容，使用主动推送功能可以快速通知到百度，使内容可以在转发之前被百度发现 step1：进入 百度站长平台，然后再 数据引入-&gt;链接提交-&gt;主动推送中找到token step2：安装插件 hexo-baidu-url-submit 1$ npm install hexo-baidu-url-submit --save step3：在 blog/_config.yml 中添加一些内容： 12345baidu_url_submit: count: 3 ## 比如3，代表提交最新的三个链接 host: https://seyvoue.com ## 在百度站长平台中注册的域名 token: eszIK5AKJsyOAD9l ## 请注意这是您的秘钥， 请不要发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里 step4：查看blog/_config.yml文件中 url 的值， 必须包含是百度站长平台注册的域名，比如:12345# URLurl: http://seyvoue.comroot: /#permalink: :year/:month/:day/:title/permalink: posts/:category/:abbrlink.html step5：在blog/_config.yml添加新的 deploy type： 123456789#Deploymentdeploy:- type: git repo: git@github.com:seyvoue/seyvoue.github.io.git branch: master- type: git repo: git@git.coding.net:seyvoue/seyvoue.git branch: master- type: baidu_url_submitter ##增加这个!!! 之后执行hexo deploy后该插件将自动进行主动推送至百度。 百度自动提交链接方式修改主题配置文件blog/themes/next/_config.yml的baidu_push字段为true，如下：1baidu_push: true 参考链接 了解抓取和呈现的重要性-google search console Hexo插件之百度主动提交链接 Hexo博客Next主题SEO优化方法 hexo的SEO方法]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Node.js的安装及其版本管理神器 nvm（macOS Mojave）]]></title>
    <url>%2Fmanual%2F9e29d568.html</url>
    <content type="text"><![CDATA[建议使用 nvm 管理计算机中的 Node.js，如果你已经安装过 Node.js ，可以先删除,如何删除參考这篇文章。 安装 nvmstep1: 使用 Homebrew 來安裝 nvm1$ brew install nvm step2: 修改~/.zshrc（因为笔者默认的 shell 为 zsh）123#nvmexport NVM_DIR=&quot;$HOME/.nvm&quot;source $(brew --prefix nvm)/nvm.sh step3：验证是否安装成功12$ nvm --version0.33.11 安装 Node.jsstep1: 查看可安装的 node 版本1234567891011121314$ nvm ls-remote v0.1.14 v0.1.15 v0.1.16 v0.1.17 ... v8.11.4 (LTS: Carbon) v8.12.0 (LTS: Carbon) v8.13.0 (Latest LTS: Carbon) v10.10.0 v10.11.0 v10.12.0 v10.13.0 (Latest LTS: Dubnium) ... step2：安装 Node.js，这里安装 10.13.01$ nvm install 10.13.0 也可以直接安装目前的稳定版：1$ nvm install stable step3: 切换到想用的 Node.js 版本1$ nvm use 10.13.0 step4：验证 Node.js 是否安装成功12$ node -vv10.13.0 nvm 会将 不同版本的 node 安装在$NVM_DIR/versions/目录下，如下：12$ type nodenode is /Users/seyvoue/.nvm/versions/node/v10.13.0/bin/node]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@手把手教你如何搭建个人博客（四）]]></title>
    <url>%2Fmanual%2Fea65db2f.html</url>
    <content type="text"><![CDATA[本文将以 Next 主题为例，教你如何进一步定制/优化自己的博客，扩展博客的功能。环境：1234os: macOS Majavehexo: 1.1.0node: 10.13.0theme: NexT.Mist v6.5.0 123456789101112131415161718$ hexo --versionhexo: 3.8.0hexo-cli: 1.1.0os: Darwin 18.2.0 darwin x64http_parser: 2.8.0node: 10.13.0v8: 6.8.275.32-node.36uv: 1.23.2zlib: 1.2.11ares: 1.14.0modules: 64nghttp2: 1.34.0napi: 3openssl: 1.1.0iicu: 62.1unicode: 11.0cldr: 33.1tz: 2018e 建议： 在定制博客前完成博客的备份工作，方便回滚和记录博客的变更。 写在前面 授之于鱼不如授之于渔希望我们都能够理解其源码，制作出属于自己专属的个性化博客(•̀ᴗ•́) 我们需要改的文件其实也就那么几个，大部分是不需要更改的，NexT 都已经帮我们配置好了~ 了解 hexo 引擎博客的目录结构默认目录结构： 1234567891011.├── .deploy_git├── public├── scaffolds├── scripts├── source| ├── _drafts| └── _posts├── themes├── _config.yml└── package.json .deploy_git：执行 hexo deploy 命令部署到GitHub上的内容目录 public：执行 hexo generate 命令，输出的静态网页内容目录 scaffolds：layout模板文件目录，其中的 md文件可以添加编辑 scripts：扩展脚本目录，这里可以自定义一些 javascript 脚本 source：文章源码目录，该目录下的 markdown 和 html 文件均会被 Hexo 处理。该页面对应 repo 的根目录，404文件、favicon.ico 文件，CNAME 文件等都应该放这里，该目录下可新建页面目录。 drafts：草稿文章 posts：发布文章 themes：主题文件目录 _config.yml：全局配置文件，大多数的设置都在这里 package.json：应用程序数据，指明 Hexo 的版本、已安装插件等信息，类似于一般软件中的关于按钮 我们最先修改的应该是在 Hexo 根目录下的配置文件 _config.yml 文件，这里是配置整个站点的配置信息。 其次就是我们的主题配置文件，在对应的主题下的 _config.yml 因为我使用的是 NexT 主题，所以目录的路径为 blog\themes\next\_config.yml 这里配置的是使用主题的配置文件，这个配置文件的东西就有点多了，我们大部分的修改也是在这个文件下完成的。比如说使用集成的第三方插件，默认为 false，我们需要将其改为 true 并且配置相应的app_key 就可以使用该插件了~有木有很方便(^ ◕ᴥ◕ ^) 然后我们需要修改样式的话是需要设置 css 和甚至是修改模板。页面展现的全部逻辑都在每个主题中控制，源代码在 hexo\themes\你使用的主题\ 中。 NexT 主题的目录结构1234567891011121314151617181920212223242526272829303132333435363738├── .github #git信息├── languages #多语言| ├── default.yml #默认语言| └── zh-Hans.yml #简体中文| └── zh-tw.yml #繁体中文| └── ...├── layout #布局，根目录下的*.ejs文件是对主页，分页，存档等的控制| ├── _custom #可以自己修改的模板，覆盖原有模板| | ├── _header.swig #头部样式| | ├── _sidebar.swig #侧边栏样式| ├── _macro #可以自己修改的模板，覆盖原有模板| | ├── post.swig #文章模板| | ├── reward.swig #打赏模板| | ├── sidebar.swig #侧边栏模板| ├── _partial #局部的布局| | ├── head #头部模板| | ├── search #搜索模板| | ├── share #分享模板| ├── _script #局部的布局| ├── _third-party #第三方模板| ├── _layout.swig #主页面模板| ├── index.swig #主页面模板| ├── page.swig #页面模板| └── tag.swig #tag模板├── scripts #script源码| ├── tags #tags的script源码| ├── marge.js #页面模板├── source #源码| ├── css #css源码| | ├── _common #*.styl基础css| | ├── _custom #*.styl局部css| | └── _mixins #mixins的css| ├── fonts #字体| ├── images #图片| └── js #javascript源代码├── _config.yml #主题配置文件└── README.md #用GitHub的都知道 定制博客添加 changelog 页建议：先给博客增加 changelog 页，即使你不想增加这个页面，其中的 git commit 规范对你也会很有帮助。 changelog 符合 AngularJS 规范，借助工具基于 git commit message 自动生成。相关介绍可参考： Commit message 和 Change log 编写指南, from 阮一峰 Contributing to Angular，from github git-commit的规范 规范你的 commit message 并且根据 commit 自动生成 CHANGELOG.md 如何打造规范的开源项目workflow 如何规范 commit comment 优雅的提交你的 Git Commit Message commitizen, from github commitlint, from github husky, from github step1: 自动化生成符合 Angular 规范的 changelog，所需的插件安装 1234567891011121314151617181920# local Installing the command line tool$ npm install --save-dev commitizen# Install your preferred commitizen adapter globally$ npm install --save-dev cz-conventional-changelog#OR initialize your project to use the cz-conventional-changelog adapter by typing: $ npx commitizen init cz-conventional-changelog --save-dev --save-exact#Install commitlint cli and conventional config$ npm install --save-dev @commitlint/&#123;config-conventional,cli&#125;#Configure commitlint to use conventional config$ echo "module.exports = &#123;extends: ['@commitlint/config-conventional']&#125;" &gt; commitlint.config.js#install husky$ npm install husky --save-dev#install conventional-changelog-cli$ npm install --save-dev conventional-changelog-cli step2：在 blog/package.json 中添加： 123456789101112&#123; "husky": &#123; "hooks": &#123; "commit-msg": "commitlint -E HUSKY_GIT_PARAMS" &#125; &#125;, "scripts": &#123; "commit": "git-cz", "changelog": "conventional-changelog -p angular -i /Users/seyvoue/personal/data/blog/source/changelog/index.md -s -w -r 0", "addChangeLog": "conventional-changelog -p angular -i /Users/seyvoue/personal/data/blog/source/changelog/index.md -s" &#125;&#125; step3: 博客增加 changelog 页面首先，新建页面：1$ hexo new page changelog 执行完后，删除blog/source/changelog下刚生成的index.md文件。 然后，修改主题配置文件blog/themes/next/_config.yml，增加changelog123456menu: home: / || home tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive changelog: /changelog/ 然后，修改blog/themes/next/languages/zh-CN.yml，增加changelog123456789101112menu: home: 首页 archives: 归档 categories: 分类 #告知 hexo 将 changelog 翻译为 “变更” changelog: 变更 tags: 标签 about: 关于 search: 搜索 schedule: 日程表 sitemap: 站点地图 commonweal: 公益 404 然后，生成 changelog，你只需执行：1$ conventional-changelog -p angular -i /Users/seyvoue/google-drive/blog/source/changelog/index.md -s -w -r 0 执行hexo clean; hexo g; hexo d将博客发布，即可在博客中看到新增了一个名为变更的页面，里面的内容即为刚刚生成的 changelog。 以后只需执行以下代码，即可自动生成 changelog。1234#全部重新生成changlog$ npm run changelog增量生成changelog 不会覆盖以前的changelog$ npm run addChangeLog 添加标签页step1: 新建页面1$ hexo new page tags 执行上述命令，将会在 blog/source/ 下新增 tages 目录，且在该目录下会新增文件index.md step2: 修改blog/source/tags/index.md的内容为如下： 123456---title: tagsdate: 2018-11-20 05:40:58type: "tags"comments: false--- step3: 修改 博客根目录/themes/next/_config.yml添加 tags 到 menu中1234menu: home: / archives: /archives/ tags: /tags/ 添加分类页同 添加标签页，故略。 设置头像修改 blog/themes/next/_config.yml 中 url字段：1234567# Sidebar Avataravatar: #url 为你头像的路径 url: http://ipic-markdown.oss-cn-shanghai.aliyuncs.com/blog/2017-08-08-avatar.jpg rounded: true opacity: 1 rotated: true 其中的 rounded 控制头像为圆形/正方形，rotated字段控制鼠标悬停时头像是否旋转。 Note：本文将头像上传到了图床，故 url 为网址，你也可以参考此文将头像上传到本地，并指定为本地的路径。 侧边栏添加社交信息修改 blog/_config.yml 中的 social字段：1234567891011social: #在这里添加你的社交链接 GitHub: https://github.com/yourname || github E-Mail: mailto:your eamil address || envelope #Weibo: https://weibo.com/yourname || weibo# 控制是否显示社交图标 social_icons: enable: true icons_only: false transition: false 修改博客底部建站时间和图标这个时间将在站点的底部显示，例如 © 2013 - 2015。 编辑 blog/themes/next/_config.yml。其中 icon 的内容去https://fontawesome.com/v4.7.0/icons找一个自己喜欢的 icon，如：将 icon name 替换为fighter-jet 12345678910# 在这里修改建站时间since: 2016icon: # Icon name 去上面提到的那个网站找 name: fighter-jet # 控制图标动画 animated: true # 控制图标颜色 color: "#808080" 设置代码高亮主题修改主题配置文件bolg/themes/next/_config.yml 12# 支持的主题有: normal | night | night eighties | night blue | highlight_theme: night 增加代码块复制功能修改主题配置文件blog/themes/next/_config.yml123456codeblock: border_radius: #在代码块的右上角添加悬浮显示的复制按钮 copy_button: enable: true show_result: true 增加代码块折叠功能关于如何实现 hexo next 显示/隐藏代码块？大多用的都是此文的方法，该方法太过于繁琐，其实 markdown 本身便支持显示/隐藏代码块功能，语法如下： 1234567&lt;details&gt;&lt;summary&gt;点击显/隐内容&lt;/summary&gt;&lt;p&gt;此处为要显示/隐的内容，亦可在此添加代码块，注意上下各空一行，&lt;/p&gt;&lt;/details&gt; 效果如下： 点击显/隐内容 1print("hello world!") 注意：&lt;p&gt;&lt;/p&gt;之间需要隐藏的内容要空一行。 文章末尾增加版权信息页step1: 查看并确认 blog/themes/next/layout/_macro/post.swig的内容 12345&#123;% if theme.creative_commons.license and theme.creative_commons.post and not is_index %&#125; &lt;div&gt; &#123;% include &apos;../_partials/post-copyright.swig&apos; with &#123; post: post &#125; %&#125; &lt;/div&gt; &#123;% endif %&#125; 从这段代码可以看出，是否显示版权信息，依赖三个变量的值，分别是： theme.creative_commons.license 不为空 theme.creative_commons.post 应为 true is_index 不是 index 页 以上三个变量可在blog/themes/next/_config.yml进行修改。 step2: 修改博客根目录/themes/next/_config.yml为：1234creative_commons: license: by-nc-sa # &lt;--看这里！！！ sidebar: false post: true # &lt;--看这里！！！ step3: 修改 blog/themes/next/languages/zh-CN.yml中 copyright字段下的内容：123456789101112post: ... copy_success: 复制成功 copy_failure: 复制失败 copyright: # &lt;--看这里！！！修改为以下内容 author: 本文作者 title: 本文标题 posted: 发布时间 modified: 最后更新 link: 本文链接 license_title: 版权声明 license_content: "本博客所有文章除特别声明外，均采用 %s 许可协议。转载请注明出处！" step4: 确认themes/next/source/css/_common/components/post/下有post-copyright.styl和 post.style 若没有，则手动添加这两个文件。 post-copyright.styl的内容如下： 1234567891011.post-copyright &#123; margin: $post-copyright.margin; padding: $post-copyright.padding; border-left: $post-copyright.border.width $post-copyright.border.style $post-copyright.border.color; background-color: $post-copyright.bg; list-style: none; i.fa &#123; font-size: 15px; &#125;&#125; post.style含有以下代码段： 1@import &quot;post-copyright&quot; if hexo-config(&apos;creative_commons.post&apos;); step5: 确认并修改blog/themes/next/layout/_partials/post-copyright.swig为以下： 1234567891011121314151617181920212223242526272829303132333435363738&#123;% set ccLicense = theme.creative_commons.license | lower %&#125;&#123;% set ccIcon = &apos;&lt;i class=&quot;fa fa-fw fa-creative-commons&quot;&gt;&lt;/i&gt;&apos; %&#125;&#123;% set ccText = ccLicense | upper %&#125;&#123;% if ccLicense === &apos;zero&apos; %&#125; &#123;% set ccType = &apos;publicdomain/zero/1.0/&apos; %&#125;&#123;% else %&#125; &#123;% set ccType = &apos;licenses/&apos; + ccLicense + &apos;/4.0/&apos; %&#125;&#123;% endif %&#125;&#123;% set ccURL = &apos;https://creativecommons.org/&apos; + ccType %&#125;//版权页的内容由以下部分控制，故想定制自己版权页显示的内容可在此修改&lt;ul class=&quot;post-copyright&quot;&gt; &lt;li class=&quot;post-copyright-author&quot;&gt; &lt;strong&gt;&#123;&#123; __(&apos;post.copyright.author&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125; &lt;/strong&gt;&#123;# #&#125;&#123;&#123; post.author || author &#125;&#125;&#123;##&#125;&lt;/li&gt; &lt;li class=&quot;post-copyright-title&quot;&gt; &lt;strong&gt;&#123;&#123; __(&apos;post.copyright.title&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125;&lt;/strong&gt; &#123;&#123; page.title &#125;&#125; &lt;/li&gt; &lt;li class=&quot;post-copyright-posted&quot;&gt; &lt;strong&gt;&#123;&#123; __(&apos;post.copyright.posted&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125;&lt;/strong&gt; &#123;&#123; page.date.format(&quot;YYYY/MM/DD - HH:MM&quot;) &#125;&#125; &lt;/li&gt; &lt;li class=&quot;post-copyright-modified&quot;&gt; &lt;strong&gt;&#123;&#123; __(&apos;post.copyright.modified&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125;&lt;/strong&gt; &#123;&#123; page.updated.format(&quot;YYYY/MM/DD - HH:MM&quot;) &#125;&#125; &lt;/li&gt; &lt;li class=&quot;post-copyright-link&quot;&gt; &lt;strong&gt;&#123;&#123; __(&apos;post.copyright.link&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125;&lt;/strong&gt; &#123;% set postURL = post.url || post.permalink %&#125; &#123;&#123; next_url(postURL, postURL, &#123;title: post.title&#125;) &#125;&#125; &lt;/li&gt; &lt;li class=&quot;post-copyright-license&quot;&gt; &lt;strong&gt;&#123;&#123; __(&apos;post.copyright.license_title&apos;) + __(&apos;symbol.colon&apos;) &#125;&#125; &lt;/strong&gt;&#123;# #&#125;&#123;&#123; __(&apos;post.copyright.license_content&apos;, next_url(ccURL, ccIcon + ccText)) &#125;&#125;&#123;##&#125;&lt;/li&gt;&lt;/ul&gt; 经过以上五步后，发布的每篇博文都会在文章末尾添加版权信息，其样式如下图所示： 添加打赏功能修改主题配置文件blog/themes/next/_config.yml:12345reward: enable: true comment: 希望对你有帮助！ wechatpay: http://ipic-markdown.oss-cn-shanghai.aliyuncs.com/blog/2017-08-08-wechatpay.jpg alipay: http://ipic-markdown.oss-cn-shanghai.aliyuncs.com/blog/2017-08-08-alipay.jpg 唯一化链接也许你会数次更改文章题目或者变更文章发布时间，在默认设置下，文章链接都会改变，不利于搜索引擎收录，也不利于分享。唯一永久链接才是更好的选择。安装插件hexo-abbrlink后，不要在 hexo s 模式下更改文章文件名，否则文章将成空白。 修改前每篇博文的链接形式为http://yoursite.com/posts/文章标题，若博文包含中文或标点符号，则链接会变得很丑且若文章标题发生变更，则之前的链接可能会失效。通过以下配置，给每篇博文生成一个固定的abbrlink，可解决上述问题。修改后博文的链接变更为http://yoursite.com/posts/:categories/:abbrlink.html。如：http://www.seyvoue.com/posts/tech/e2a845a8.html step1: 安装 hexo-abbrlink 插件1$ npm install hexo-abbrlink --save step2: 修改 blog/_config.yml 为以下：12345678url: http://yoursite.comroot: /permalink: posts/:category/:abbrlink.html # “posts/:category” 可自行更换permalink_defaults:# abbrlink configabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 其中的 permalink 也可以为 posts/:abbrlink，但还是建议在末尾加上html，便于被识别为静态网页。 修改文章内链接文本样式打开文件themes\next\source\css\_common\components\post\post.styl，在末尾添加以下css样式: 1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125; 其中颜色可以自定义,在这里选中状态为橙色,链接样式为蓝色。选择.post-body是为了不影响标题，选择p是为了不影响首页 “阅读全文” 的显示样式。 添加博文搜索功能静态站关于实现站内搜索的方式，它有两种方式：一是本地建立索引，二是采用第三方线上服务。在 next 主题所在目录下的 /layout/_partials/search 目录中分别有三个文件：localsearch.swig、swiftype.swig、tinysou.swig ，其中 tinysou 这个项目已经很长时间没在维护了，不推荐使用。剩下的两个就是本地搜索和第三方线上服务。然而 swiftype 不再提供免费账户(老用户还可以免费用)了，那剩下的就只有 localsearch 这条路了。 step1：安装插件 1$ npm install hexo-generator-searchdb --save step2：在 blog/_config.yml中添加以下内容：123456#searchsearch: path: search.xml field: post format: html limit: 10000 step3：编辑主题配置文件blog/themes/next/_config.yml，弃用本地搜索功能：123# Local searchlocal_search: enable: true 添加文章字数统计功能step1：安装插件 hexo-symbols-count-time 1npm install hexo-symbols-count-time --save step2：在blog/_config.yml中添加以下内容：12345678#wordcountsymbols_count_time: # 文章内是否显示 symbols: true time: false # 网页底部是否显示 total_symbols: true total_time: true step3：在blog/themes/next/_config.yml 修改symbols_count_time 下的内容为： 123456789101112# Post wordcount display settings# Dependencies: https://github.com/theme-next/hexo-symbols-count-timesymbols_count_time: separated_meta: true #文章中的显示是否显示文字（本文字数|阅读时长） item_text_post: false #网页底部的显示是否显示文字（站点总字数|站点阅读时长） item_text_total: true # Average Word Length (chars count in word) awl: 2 # Words Per Minute wpm: 300 Note： 字段awl和wpm的设置可参考https://github.com/theme-next/hexo-symbols-count-time 添加文章阅读次数统计功能关于这部分内容也可参考： Leancloud访客统计插件重大安全漏洞修复指南 【NexT】用hexo框架NexT主题搭建博客踩过的坑 为NexT主题添加文章阅读量统计功能 step1：前往 Leancloud 官网进行注册，并登陆。 step2：然后依次点击控制台-&gt;创建应用，应用名称随意，这里命名为seyvoue-blog： 创建完成后，会出现： step3：设置Web安全域名确保域名调用安全，依次点击设置-&gt;安全中心，然后再 web 安全域名中填入你自己的域名： step4：依次点击设置-&gt;存储-&gt;创建 class，新建一个名为Counter的 Class，并指定为无限制，如下图： step5：依次点击设置-&gt;应用 key，将会看到该应用的 APP ID 和 APP KEY粘贴App ID和App Key到主题配置文件·blog/themes/next/_config.yml对应位置：123456leancloud_visitors: enable: true app_id: 粘贴到这 #&lt;app_id&gt; app_key: 粘贴到这 #&lt;app_key&gt; security: false betterPerformance: false 以上五步便可完成阅读次数统计的功能，接下类的内容为可选项，目的是为了保证阅读次数统计功能的安全性以及放置被恶意篡改。 部署云引擎以保证访客数量不被随意篡改（可选，建议设置）step1：依次点击云引擎-&gt;部署-&gt;在线编辑： step2：点击创建函数，按下图完成函数的创建：其中的代码为：12345678var query = new AV.Query(&quot;Counter&quot;);if (request.object.updatedKeys.indexOf(&apos;time&apos;) !== -1) &#123; return query.get(request.object.id).then(function (obj) &#123; if (obj.get(&quot;time&quot;) + 1 !== request.object.get(&quot;time&quot;)) &#123; throw new AV.Cloud.Error(&apos;Invalid update!&apos;); &#125; &#125;)&#125; step3：部署到生产环境，如下图，点击部署： 等待出现部署成功字样后，关闭 以上，便完成了云引擎的部署，任何非法的访客数量更改请求都将失败。 进一步设置权限（可选，建议设置）step1：修改主题配置文件blog/themes/next/_config.yml，将其中的security字段设为 true123456leancloud_visitors: enable: true app_id: TyFNsWV8F6tFUPr7cq0lXU32-9Nh9j0Va #&lt;app_id&gt; app_key: TW5MEsTnMVUdznvEagcTrSBa #&lt;app_key&gt; security: true betterPerformance: false step2：安装插件hexo-leancloud-counter-security 1npm install hexo-leancloud-counter-security --save 对betterPerformance选项的说明：由于Leancloud免费版的云引擎存在请求线程数和运行时间限制以及休眠机制，很多时候访客数量加载会很慢。如果设置betterPerformance为true，则网页则会在提交请求之前直接显示访客人数为查询到的人数+1，以增加用户体验。 step3：在全局配置文件blog/_config.yml中添加：123456leancloud_counter_security: enable_sync: true app_id: &lt;&lt;your app id&gt;&gt; app_key: &lt;&lt;your app key&gt; username: password: Note： 将 username 和 password 替换为你自己的用户名和密码（不必与leancloud的账号）相同。此用户名和密码将在hexo部署时使用。 step4：安装插件 hexo-leancloud-counter-security 1npm install hexo-leancloud-counter-security --save step5：使用插件 hexo-leancloud-counter-security 设定部署使时的用户 1hexo lc-counter register &lt;&lt;username&gt;&gt; &lt;&lt;password&gt;&gt; step6：修改全局配置文件blog/_config.yml，将username和password替换为你刚刚设置的用户名和密码，但建议将 password 留空123456leancloud_counter_security: enable_sync: true app_id: &lt;&lt;your app id&gt;&gt; app_key: &lt;&lt;your app key&gt; username: &lt;&lt;your username&gt;&gt; #如留空则将在部署时询问 password: &lt;&lt;your password&gt;&gt; #建议留空以保证安全性，如留空则将在部署时询问 step7：在全局配置文件blog/_config.yml的deploy下添加： 123deploy: # other deployer - type: leancloud_counter_security_sync step8：返回 LeanCloud 控制台页面，依次点击存储-&gt;_User，发现_User表中会新增一条记录，如下：若没有新增记录，最简单的办法重头来过，严格按照本教程的顺序操作。 step8：在LeanCloud 控制台页面，依次点击存储-&gt;Counter，进入 Counter表，打开权限设置： 设置 addField 权限为： 设置 Create 权限为： 设置 Delete 权限为： 至此权限已设置完成，数据库记录只能在本地增删。每次运行 hexo d 部署的时候，插件都会扫描本地source/_posts下的文章并与数据库对比，然后在数据库创建没有录入数据库的文章记录。如果在博客配置文件中留空username或password，则在部署过程中程序会要求输入。 关于 ERROR Too many requests 429出现这个问题的报错信息是too many requests,原因是我们使用leanCloud的免费版本线程数是十分受限的,在我们deploy的时候发送了太多的同步请求导致线程栈溢出而报错，解决方法： step1：删除blog/public/leancloud.memostep2：执行hexo d 如果你博文很多的话，step2 后，可能还是会报 429 错误，忽略此时的报错，继续执行hexo d知道不报429错误为止，你会发现没多执行一次hexo d，leancloud.memo中的记录就会多一些。 文末添加评论功能Hexo的评论系统有很多，常见的有以下几个： 多说 网易云跟帖 畅言（来自国内，需要备案号） 来必力（来自韩国，使用邮箱注册） Disqus Hypercomments（来自俄罗斯的评论系统，使用谷歌账号注册。） valine（基于Leancloud的极简风评论系统） gitment 国内主流评论服务多说，网易云跟帖，停止服务，其次畅言需要备案，Disqus，Hypercomments和LiveRe都是国外的，加载速度贼慢，甚至有被墙的可能。 使用 gitmentGitment 是作者实现的一款基于 GitHub Issues 的评论系统。支持在前端直接引入，不需要任何后端代码。可以在页面进行登录、查看、评论、点赞等操作，同时有完整的 Markdown / GFM 和 代码高亮支持。尤为适合各种基于 GitHub Pages 的静态博客或项目页面。 step1：Register a new OAuth application，即登录 github 后，依次点击settings-&gt;Developer Settings-&gt;New Oauth App Application name：随意 Homepage URL：你的博客域名或https://xxx.github.io Application description：随意 Authorization callback URL：一般与 Homepage URL 相同 Note：在初次注册的时候，如何你指定Homepage URL为你购买的域名时，可能会报unvalid url，此时你可以先指定为https://xxx.github.io，等注册完成后，再去修改。 stpe2：修改主题配置文件blog/themes/next/_config.yml中 gitment下的内容为：12345678910111213gitment: enable: true mint: true count: true lazy: true cleanly: false language: github_user: seyvoue # 你的 github 用户名 github_repo: seyvoue.github.io # 你存放评论的 github 仓库地址。方便起见，可选择你的静态博客仓库地址 client_id: #见 step1 的截图 client_secret: # 见 step1 的截图 proxy_gateway: # Address of api proxy, See: https://github.com/aimingoo/intersect redirect_protocol: step3：安装插件 gitment1npm i --save gitment 以上便完成了 gitment 的配置，接下来你需要随机打开一片博文，滚动到评论区，登录你的 github 账号，然后点击Initialize Comments即可，如下图： 可能会碰到的问题使用 gitment，要先在评论区登录 github，否则显示Error: Comments Not Initialized(中文显示评论不可用之类)；登录后点击Initialize Comments。另外可能会报错[object ProgressEvent]或者gh-oauth.imsun.net链接不上。这是因为gh-oauth.imsun.net网站证书失效了！解决方法（可参看imsun/gitment/issues#102，object ProgressEvent）： 方案一：单独访问这个网站 https://gh-oauth.imsun.net/，加入例外，允许浏览器访问。但这个方案，别人看你博客的人不一定知道要加，所以不好。 方案二（推荐）：更改node_modules/gitment/dist/gitment.js中https://gh-oauth.imsun.net，直接改为请求 github 认证的接口https://github.com/login/oauth/access_token 使用 Valine（方便，但邮件提醒不方便）step1：首先你需要拥有 LeanCloud 账号。具体操作同本文添加文章阅读次数统计功能的 step1-step3 step2：修改主题配置文件 blog/themes/next/_config.yml 中 Valine下的内容为：1234567891011valine: enable: true appid: # your leancloud application appid appkey: # your leancloud application appkey notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 昵称--即你的网名；邮箱--请告知我联系你的方式；网址--你正在浏览的这个页面 avatar: mm guest_info: nick,mail,link pageSize: 10 visitor: false 将 enalbe 置为 true，并在appid和appkey填入你step1所创建应用的APP ID 和 APP KEY 至此，执行hexo d部署后，便可在文章的末尾看到新增的 Valine 评论了： 每当新增一条评论，都会在 LeanCloud 的存储-&gt;Comments表中新增一条记录。 Valine 评论增加邮件提醒功能（未实践）首先需要确保 Valine 的基础功能是正常的，即已经可以在文末发起评论，并且当你登录 LeanCloud，可在存储-&gt;Comments表中看到新增的评论，如下图： 接下来的配置过程，可参考： https://panjunwen.com/valine-admin-document/ https://github.com/panjunwen/Valine-Admin Hexo 优化 —- 支持邮件通知的评论 Valine 增强版 Valine Admin 配置手册 增加友情链接功能在主题配置文件中找到 links 属性，修改 links_title 属性的值为“友情链接”（也可以是其他文字），然后添加上好友的博客名称和博客地址，其格式如下： 123456# Blog rollslinks_title: 友情链接#links_layout: blocklinks_layout: inlinelinks: seyvoue: https://www.seyvoue.com/ 设置网页 logo主题配置文件blog/themes/next/_config.yml关于网页logo是由favicon控制的，默认提供了四种类型，只需将你的 logo 放入blog/themes/next/source/images/下即可。你也可以将 logo 上传到图床，然后将链接贴到响应类型的后面即可。Note：一般来说，我们只需要更改 medium 字段的值即可。1234567favicon: #small: /images/favicon-16x16-next.png #medium: /images/favicon-32x32-next.png #apple_touch_icon: /images/apple-touch-icon-next.png #safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml 增加 RSS 订阅功能step1：安装hexo-generator-feed插件： 1$ npm install hexo-generator-feed --save step2：在 blog/_config.yml 中，增加以下内容： 1234567891011#RSS 订阅插件plugin:- hexo-generator-feed#RSS 插件配置feed: type: rss2 path: rss.xml limit: 20 hub: content: true 增加 404 页面step1：创建404页面1hexo new page 404 step2：修改blog/source/404/index.md为：12345---title: 404 Not Foundcomments: falsepermalink: /404--- 经过上面的设置后，404界面已生效，其编辑方式与一般文章无异。我们可以在.md文件正文中插入一些 CSS 样式，使得该页面与博客中的一般文章有所区别。 参考：在 Hexo 中创建匹配主题的404页面 文末增加分享功能修改主题配置文件blog/themes/next/_config.yml的baidushare字段： 12baidushare: type: button 博客增加支持 Markdown 语法画流程图1npm install --save hexo-filter-flowchart 参考资料 hexo 官方文档 Jacman基于Pacman修改的Hexo主题 hexo高阶教程：next主题优化之加入网易云音乐、网易云跟帖、炫酷动态背景、自定义样式，打造属于你自己的定制化博客]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@手把手教你如何搭建个人博客（三）]]></title>
    <url>%2Fmanual%2F5d48c24a.html</url>
    <content type="text"><![CDATA[按照前两篇博文便可成功搭建一个外网可访问的个人博客了，笔者将在接下来的两篇教程中，介绍如何对博客进行优化。Hexo 默认的主题 landscape比较大众，本文将介绍如何更换博客的主题，以及如何进行博客的备份和恢复。 你可以在这里寻找主题： hexo-theme hexo-github-theme-list 有那些好看的hexo主题？—知乎 我选择的是: IIssNan 的 NexT 那么，如何将当前的主题更换为 NexT ？ 下载主题将主题 clone 到博客目录下的 themes 文件夹中(即 blog/themes) 将主题 clone 到博客目录下的 themes 文件夹中(即 blog/themes) 建议： 先将NexT主题 fork到自己的仓库在克隆到本地，方便之后博客的备份和恢复，笔者已经将主题fork到了自己的仓库故地址由https://github.com/theme-next/hexo-theme-next—&gt;git@github.com:seyvoue/hexo-theme-next.git 并在本地创建一个dev分支，并将 dev 分支作为日常的常用分支。这样的好处是，每当 NexT 版本升级时，你都先 pull 到 master，然后在将其合并到 dev，以保证master始终为官方稳定版，dev为博客定制版 123cd bloggit clone git@github.com:seyvoue/hexo-theme-next.git themes/nextgit checkout -b dev 启用主题与所有 Hexo 主题启用的模式一样(主题均统一放在 theme 目录下)。 当 克隆/下载 完成后，打开站点配置文件 blog/_config.yml， 找到 theme 字段，并将其值由默认的landscape更改为 next。 到此，NexT 主题安装完成。下一步我们将验证主题是否成功启用。在发布到 github 之前，建议先以本地调试的模式验证博客，如果没有问题，再将其部署到 github 中。 使用 hexo server 命令验证主题是否成功启用，你会发现主题已经切换成功。 主题切换成功后，便可将博客部署到 github 上了： 123$ github clean$ github generate$ github deploy 访问 https://seyvoue.github.io 或 http://www.seyvoue.com，此时的主题已经切换到 NexT了。 备份博客Hexo 博客的目录结构如下： 1234567891011.├── .deploy_git├── public├── scaffolds├── scripts├── source| ├── _drafts| └── _posts├── themes├── _config.yml└── package.json 在介绍如何备份博客前，我们有必要先了解 hexo deploy 这条命令会将哪些内容推送到 github 仓库中，这条命令会将.deploy_git中的所有内容上传到 github 的 master 分支。 所以，笔者采用给仓库seyvoue.github.io建立新分支backup的方法备份博客，Git相关操作请参考廖雪峰的Git教程。 分别执行以下命令，将本地博客备份到仓库的 backup 分支：1234567891011#切换到博客根目录cd blog#在博客根目录下初始化生成 .git 目录git init#将本地的 git 仓库与远程 github 仓库关联git remote add git@github.com:seyvoue/seyvoue.github.io.git#将博客根目录的所有文件和文件提交到本地仓库git add -Agit commit -m '博客备份'#将本地仓库上传到远程仓库的 backup 分支上git push -u origin master:backup 完成上述的步骤后，笔者建议将 github 的默认分支由master -&gt; backup，以方便日后恢复博客。 建议： 不要将全局配置文件blog/_config.yml上传到远程仓库seyvoue.github.io，因为该文件中可能包含有敏感信息 不要将 themes 目录内的内容上传到远程仓库seyvoue.github.io 中 故修改blog/.gitignore文件为以下：123456789.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/_config.ymlthemes/next/* 个人备份习惯：先备份博客根目录，再备份NexT；日常在本地的 writ_blog 分支更新博客，不要直接在 master 分支上操作 12345678910111213#将博客根目录备份到 seyvoue.github.io 的 backup 分支cd bloggit statusgit add .git commitgit push -u origin master:backup#将主题 next 备份到 seyvoue/hexo-theme-next 的 backup 分支cd blog/themes/nextgit statusgit add .git commitgit push -u origin write_blog:backup 恢复博客step1：将博客克隆到本地（克隆前确认分支为 backup 而不是 master），假设当前目录为~123456789git clone git@github.com:seyvoue/seyvoue.github.io.git ~/workspace/blogcd bloggit checkout -b write_blog origin/backup#记得复制之前备份在本机的 _config.yml 到 blog 目录下#因为.gitignore 文件是忽略上传全局的_config.yml 文件的git clone git@github.com:seyvoue/hexo-theme-next.git themes/nextcd themes/nextgit checkout -b write_blog origin/backupgit checkout -b master origin/master step2：安装必要的插件，恢复 node_modules1234#切换到博客根目录$ cd blog$ npm install -g hexo-cli$ npm install 因为笔者笔者部署 hexo 博客时，node 版本为 v10.13.0，npm 版本为 v6.4.1，所以执行 npm install 后，会根据 package.json 和 package-lock.json 这两个文件，安装所有之前安装过的依赖。]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@手把手教你如何搭建个人博客（二）]]></title>
    <url>%2Fmanual%2F10566118.html</url>
    <content type="text"><![CDATA[在上一篇文章中，笔者介绍了如何快速搭建一个本地博客，本文将介绍如何将你的博客部署到 github page 上（另外也介绍了如何同时部署到 github page 和 coding.net 上），以及如何绑定域名，使其可以像访问http:/www.baidu.com 一样，供所有人访问，而不仅仅只能在本地访问。 首先，你需要一个 github 账号，且本机已安装 git（git 的安装参考这篇文章），具体注册过程本文略。如笔者的 github 账号的 username 为 seyvoue。 在 github 上创建仓库在 github 上创建一个名为 seyvoue.github.io 的仓库。 Note: 这里的仓库名必须严格按照 username.github.io 的形式命名。 关联 github将本地的博客目录 blog 与刚创建的仓库关联。 step1：切换到你的博客根目录，安装 hexo-deployer-git 插件 12$ cd blog$ npm install hexo-deployer-git --save step2：修改配置文件 blog/config.yml 12345# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:dog/dog.github.io.git,master Note：此处的 branch 必须为 master，否则 github page 会 build faied。 若想同时部署在 coding.net 上，参考此文，只需将配置文件修改为： 12345deploy: type: git repo: github: git@github.com:seyvoue/seyvoue.github.io.git,master coding: git@git.coding.net:seyvoue/seyvoue.git,master 将博客部署到 github 上每次你在本地写好博文后，依次执行以下命令，即可将博客发布到 github 上，并可通过 http://dog.github.io 访问你的博客。 123$ hexo clean$ hexo generate$ hexo deploy 绑定域名step1: 申请域名在万网购买自己喜欢的域名（.com的会贵一点，.site 和 .xyz的相对便宜一些，有的只需要几块钱一年就可以），如笔者的域名为seyvoue.com。 step2：在 blog/source/ 下创建 CNAME 文件，编辑其内容为：1yoursite.com 注意：不是 http://www.yoursite.com step3：修改配置文件blog/_config.yml中的 url为申请的域名 123# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://seyvoue.com]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@手把手教你如何搭建个人博客（一）]]></title>
    <url>%2Fmanual%2F20408dc0.html</url>
    <content type="text"><![CDATA[本文介绍如何在本地快速的搭建一个基于 Hexo 的博客。你只需要用 markdown 语法写好博文，并保存在指定的文件夹中，然后输入 hexo server 命令，访问http://localhost:4000/，便可立刻看到生成的博客效果。 环境准备要在本地搭建一个基于 hexo 的博客，你需要做好以下工作： 安装 homebrew (参考@HomeBrew 的安装与使用） 安装 node.js （参考@Node.js的安装及其版本管理神器 nvm（macOS Mojave） 安装 hexo 执行下面的命令，完成 hexo 的安装： 1$ npm install -g hexo-cli 搭建本地博客先搭建一个可在本地访问的博客，使用 hexo 默认的主题。@手把手教你如何搭建个人博客（二） 将会继续介绍，如何将博客托管在 github 上，并绑定自己的域名，供所有人访问。 step1: 新建一个新的空白目录blog，作为博客根目录1$ mkdir blog step2: 依次执行下面的命令，部署本地 hexo 博客1234$ cd blog$ hexo init$ npm install$ hexo server 执行完后，blog 目录下的结构如下：123456789101112$ tree . -L 1.├── _config.yml├── db.json├── node_modules├── package-lock.json├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 恭喜！！！ 至此，一个可本地访问的博客创建完毕。可通过访问 http://localhost:4000/，浏览所创建的博客内容，如下图： 写博文 那么如何在本地博客新增一篇博文呢？ 只需要执行下面的命令，即可创建一篇博文。 12$ hexo new post '博文的标题'$ hexo s 执行完hexo new post &#39;博文的标题&#39;后，hexo 会在 source/_posts 目录下创建一个 .md 文件，将博文内容以 markdown 语法，写在此文件中，并执行hexo server，博文便发布在你的博客上了。]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@手把手教你如何搭建个人博客系列教程]]></title>
    <url>%2Fmanual%2Fbb3e57d7.html</url>
    <content type="text"><![CDATA[本文将以自己博客搭建的整个过程为例，手把手教你如何搭建一个基于 Hexo 的个人独立博客。笔者用的是 mac，若你是 windows 用户，本系列教程可能不完全兼容，但整个搭建过程基本是类似的，你可以通过阅读本系列教程，了解搭建个人博客的大致流程。 这个系列教程包括以下内容： @手把手教你如何搭建个人博客（一） 本文介绍如何在本地快速的搭建一个基于 Hexo 的博客。你只需要用 markdown 语法写好博文，并保存在指定的文件夹中，然后输入 hexo server 这段命令，访问http://localhost:4000/，便可立刻看到生成的博客效果。另外，本文还简单介绍了，如何发布一篇博文。 @手把手教你如何搭建个人博客（二） 在上一篇文章中，笔者介绍了如何快速搭建一个本地博客，本文将介绍如何将你的博客部署到 github page 上（另外也介绍了如何同时部署到 github page 和 coding.net 上），以及如何绑定域名，使其可以像访问http://www.baidu.com 一样，供所有人访问，而不仅仅只能在本地访问。 @手把手教你如何搭建个人博客（三） 按照前两篇博文便可成功搭建一个外网可访问的个人博客了，笔者将在接下来的两篇教程中，介绍如何对博客进行优化。Hexo 默认的主题 landscape比较大众，本文将介绍如何更换博客的主题，以及如何进行博客的备份和恢复。 @手把手教你如何搭建个人博客（四） 本文将以 Next 主题为例，教你如何进一步定制/优化自己的博客，扩展博客的功能，包括： 添加 changelog 页 添加标签页 添加分类页 设置头像 侧边栏添加社交信息 修改博客底部建站时间和图标 设置代码高亮主题 增加代码块复制功能 增加代码块折叠功能 文章末尾增加版权信息页 添加打赏功能 唯一化链接 修改文章内链接文本样式 添加博文搜索功能 添加文章字数统计功能 添加文章阅读次数统计功能 文末添加评论功能 增加友情链接功能 设置网页 logo 增加 RSS 订阅功能 要想最快的知道这些功能的效果，请移步我的个人博客：www.seyvoue.com 我的博客最初创建于2017年8月，用的是 NexT 主题，集成了很多的插件。很多功能只需要在主题配置文件中将默认的false改为true即可，但是我们也仍然需要知道都有哪些新的功能，最有效的方法是直接去查看官网的api：next官网 建议：若你是第一次自己搭建博客，建议按照笔者的系列教程的顺序，逐步完成，可以避免走一些不必要的坑。 @手把手教你如何搭建个人博客（五） 本文主要介绍 Hexo 博客的SEO优化方法，让你的博客被 google 和 baidu 收录，并提高博文在搜索引擎的排名。 参考链接 Hexo博客设置进阶 Hexo 官网 Next 官网]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@python多版本管理及虚拟环境策略：homebrew + pyenv + pyenv-virtualenv（macOS Majave）]]></title>
    <url>%2Fmanual%2F77fe63cf.html</url>
    <content type="text"><![CDATA[概述背景 Python 解释器版本混乱, 2和3差别巨大, 而且细分版本也不尽相同, 难以选择和管理。 不同 Linux 发行版自带 Python 不同, 如 macOSX 自带 2.7 版本, 其中系统许多组件依赖于自带解释器, 一旦删除或者更改都可能会造成系统出问题。 不同的 Python 解释器软件包管理也是问题, 如 pip 和 ipython 等必备包组件, 而且在项目开发中如何保证不同的包环境互不干扰也是一个问题。 那么有没有一个终极的解决办法能在管理不同解释器版本的同时控制不同的包环境呢? 有的, 就是 pyenv. pyenv 是什么? 能干什么? pyenv 是一个 forked 自 ruby 社区的简单、低调、遵循 UNIX 哲学的Python 环境管理工具, 它可以轻松切换全局解释器版本, 同时结合 vitualenv 插件可以方便的管理对应的包源。 使用 pyenv 我可以方便的下载指定版本的 python 解释器, pypy, anaconda 等, 可以随时自由的在 “shell环境、本地、全局”切换python解释器。 开发的时候不需要限定某个版本的虚拟环境, 只需要在部署的时候用 pyenv 指定某个版本就好了。 pyenv 切换解释器版本的时候, pip 和 ipython 以及对应的包环境都是一起切换的, 所以如果你要同时运行 ipython2.x 和 ipython3.x 多个解释器验证一些代码时就很方便。 pyenv 也可以创建好指定的虚拟环境, 但不需要指定具体目录, 自由度更高, 使用也简单。 基本原理如果要讲解pyenv的工作原理，基本上采用一句话就可以概括，那就是：修改系统环境变量PATH。 对于系统环境变量PATH，相信大家都不陌生，里面包含了一串由冒号分隔的路径，例如/usr/local/bin:/usr/bin:/bin。每当在系统中执行一个命令时，例如python或pip，操作系统就会在PATH的所有路径中从左至右依次寻找对应的命令。因为是依次寻找，因此排在左边的路径具有更高的优先级。 而pyenv做的，就是在PATH最前面插入一个$(pyenv root)/shims目录。这样，pyenv就可以通过控制shims目录中的Python版本号，来灵活地切换至我们所需的Python版本。 如何安装？安装 pyenv本文只介绍 mac 下利用 homebrew 的安装过程，其它系统安装过程大同小异，具体可参考官方的安装手册。 step0: preinstall 1234#确保本机已安装 xcode 且为最新版[mac]xcode-select --install#确保本机已安装相关依赖[mac]brew install zlib openssl readline xz sqlite step1: 安装 pyenv 1[mac] brew install pyenv step2: 在 ~/.zshrc 添加以下内容 123456#pyenvexport PYENV_ROOT=$(brew --prefix pyenv)export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then eval &quot;$(pyenv init -)&quot;fi step3: 使 .zshrc 生效，并重新启动 shell 12[mac] source ~/.zshrc[mac] exec $SHELL step4：验证是否安装成功 12[mac]pyenv -vpyenv 1.2.8 可能遇到的问题 若遇到无法安装的问题可参考 此文1 此文2，即可解决。 笔者在使用 brew install pyenv 后遇到以下问题： 问题1：笔者在安装 pyenv 之前，mac 中已装有以下 python： 系统自带的 python 2.7 homebrew 安装的 python@2 和 python3(python 3.7.1) 123[mac]pyenv install -lAvailable versions:/usr/local/bin/python-build: /usr/local/bin/sort: /usr/local/opt/python3/bin/python3.6: bad interpreter: No such file or directory 于是，笔者便分别查看了文件/usr/local/bin/python-build和文件/usr/local/bin/sort，发现 /usr/local/opt/python3/bin/ 中并没有 python3.6，只有 python3.7，于是手动 ln -s [python3.7的 bin 路径] /usr/local/opt/python3/bin/python3.6，修改后发现又出现了问题2。 问题2 123456[mac]pyenv install -lAvailable versions:Traceback (most recent call last): File "/usr/local/bin/sort", line 7, in &lt;module&gt; from sort import cliModuleNotFoundError: No module named 'sort' 于是，vi /usr/local/bin/sort: 12def cli(): print('This is suroegin's package - sort') 没发现有什么问题，试着将print(&#39;This is suroegin&#39;s package - sort&#39;) -&gt; print(&quot;This is suroegin&#39;s package - sort&quot;)，又出现了问题3。 问题3具体的报错信息忘记了，大致包含以下关键词： 12[mac]pyenv install -lunmatched &apos; 最后 1[mac]pip3 uninstall sort 所有问题就解决了。 总结：因为笔者之前有安装 python，导致安装 pyenv 后，pyenv 的相关依赖使用了笔者系统中已安装的模块，以致出现相关依赖问题。所以，一个好的版本管理策略是多么重要，仅仅依赖 homebrew 的 brew switch python 3.x.x 并不能从根本上解决 python 的版本管理问题。 安装 pyenv-virtualenvstep1: install 1[mac]brew install pyenv-virtualenv step2: 修改 ~/.zshrc为以下： 123456789#pyenvexport PYENV_ROOT=$(brew --prefix pyenv)export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;if which pyenv 1&gt;/dev/null 2&gt;&amp;1; then eval &quot;$(pyenv init -)&quot;fiif which pyenv-virtualenv-init &gt; /dev/null; then eval &quot;$(pyenv virtualenv-init -)&quot;fi step3: 使 .zshrc 生效 1[mac]$ source ~/.zshrc 如何使用pyenv 常用命令pyenv 的主要功能如下： 123456789101112131415161718$ pyenv -hUsage: pyenv &lt;command&gt; [&lt;args&gt;]Some useful pyenv commands are: commands List all available pyenv commands local Set or show the local application-specific Python version global Set or show the global Python version shell Set or show the shell-specific Python version install Install a Python version using python-build uninstall Uninstall a specific Python version rehash Rehash pyenv shims (run this after installing executables) version Show the current Python version and its origin versions List all Python versions available to pyenv which Display the full path to an executable whence List all Python versions that contain the given executableSee `pyenv help &lt;command&gt;' for information on a specific command.For full documentation, see: https://github.com/pyenv/pyenv#readme 比如： 123456789101112131415161718192021222324252627282930# 查看当前激活的是那个版本的Pythonpyenv version# 查看所有已安装的版本pyenv versions# 查看所有可安装的版本pyenv install --list# 安装指定版本pyenv install 3.6.5# 安装完成后必须rehashpyenv rehash# 删除指定版本pyenv uninstall 3.5.2# 指定局部版本，当前目录生效pyenv local 3.6.5# 指定全局版本，整个系统生效pyenv global 3.6.5# 指定多个全局版本, 3版本优先pyenv global 3.6.5 2.7.14# 取消设置pyenv local --unset# 实际上当你切换版本后, 相应的pip和包仓库都是会自动切换过去的 使用 pyenv：切换 python 版本pyenv 可以从三个维度来管理Python环境，简称为：当前系统(global)、当前目录(local)、当前shell。这三个维度的优先级从左到右依次升高，即当前系统的优先级最低、当前shell的优先级最高。 如果想修改系统全局的Python环境，可以采用 pyenv global PYTHON_VERSION 命令。该命令执行后会在 $(pyenv root) 目录中创建一个名为 version 的文件（如果该文件已存在，则修改该文件的内容），里面记录着系统全局的Python版本号。 12345[mac]$ pyenv global system[mac]$ cat $(pyenv root)/versionsystem[mac]$ pyenv versionsystem (set by /usr/local/opt/pyenv/version) 通常情况下，对于特定的项目，我们可能需要切换不同的Python环境，这个时候就可以通过pyenv local PYTHON_VERSION 命令来修改当前目录的Python环境。命令执行后，会在当前目录中生成一个.python-version文件（如果该文件已存在，则修改该文件的内容），里面记录着当前目录使用的Python版本号。 12345678[mac]$ cd ~/workspace/test-pyenv[mac]pyenv local 2.7.8[mac]$ cat .python-version2.7.8[mac]$ pyenv version2.7.8 (set by /Users/seyvoue/workspace/test-pyenv/.python-version)[mac]$ pip -Vpip 18.1 from /usr/local/opt/pyenv/versions/2.7.8/lib/python2.7/site-packages/pip (python 2.7) 可以看出，当前目录中的.python-version配置优先于系统全局的$(pyenv root)/version配置。 另外一种情况，通过执行 pyenv shell PYTHON_VERSION 命令，可以修改当前shell的Python环境。执行该命令后，会在当前shell session（Terminal窗口）中创建一个名为PYENV_VERSION 的环境变量，然后在当前shell的任意目录中都会采用该环境变量设定的Python版本。此时，当前系统和当前目录中设定的Python版本均会被忽略。 123456789101112131415[mac]$ cd ~/workspace/test-pyenv[mac]pyenv local 2.7.8[mac]$ cat .python-version2.7.8[mac]$ pyenv version2.7.8 (set by /Users/seyvoue/workspace/test-pyenv/.python-version)[mac]$ echo $PYENV_VERSION[mac]$ pyenv shell 3.7.1[mac]$ echo $PYENV_VERSION3.7.1[mac]$ cat .python-version2.7.8[mac]$ pyenv version3.7.1 (set by PYENV_VERSION environment variable) 顾名思义，当前shell的Python环境仅在当前shell中生效，重新打开一个新的shell后，该环境也就失效了。如果想在当前shell中取消shell级别的Python环境，采用unset命令重置PYENV_VERSION环境变量即可。 123456cat .python-version2.7.8[mac]$ pyenv version3.7.1 (set by PYENV_VERSION environment variable)[mac]$ unset PYENV_VERSION2.7.8 (set by /Users/seyvoue/workspace/test-pyenv/.python-version) 特别建议： 12系统全局用系统默认的Python比较好，不建议直接对其操作pyenv global system 12用local进行指定版本切换，一般开发环境使用。pyenv local 2.7.10 12对当前用户的临时设定Python版本，退出后失效pyenv shell 3.5.0 12取消某版本切换pyenv local 3.5.0 --unset 输入python即可使用新版本的python系统自带的脚本会以 /usr/bin/python 的方式直接调用老版本的python，因而不会对系统脚本产生影响；如果通过homebrew安装python，那么pip会同时安装。 使用 pyenv-virtualenv：管理多个依赖库环境经过以上操作，我们在本地计算机中就可以安装多个版本的Python运行环境，并可以按照实际需求进行灵活地切换。然而，很多时候在同一个Python版本下，我们仍然希望能根据项目进行环境分离，在pyenv中，pyenv-virtualenv 插件可以实现这个功能。 使用方式如下： 1$ pyenv virtualenv PYTHON_VERSION PROJECT_NAME 其中，PYTHON_VERSION是具体的Python版本号，例如，3.7.1，PROJECT_NAME是我们自定义的项目名称。比较好的实践方式是，在PROJECT_NAME也带上Python的版本号，以便于识别。 现假设我们有test-pyenv这么一个项目，想针对Python 2.7.8和Python 3.7.1分别创建一个虚拟环境，那就可以依次执行如下命令。 12$ pyenv virtualenv 3.7.1 py37_test-pyenv$ pyenv virtualenv 2.7.8 py27_test-pyenv 创建完成后，通过执行pyenv virtualenvs命令，就可以看到本地所有的项目环境。 12345$ pyenv virtualenvs 2.7.8/envs/py27_test-pyenv (created from /usr/local/opt/pyenv/versions/2.7.8)3.7.1/envs/py37_test-pyenv (created from /usr/local/opt/pyenv/versions/3.7.1)py27_test-pyenv (created from /usr/local/opt/pyenv/versions/2.7.8)py37_test-pyenv (created from /usr/local/opt/pyenv/versions/3.7.1) 通过这种方式，在同一个Python版本下我们也可以创建多个虚拟环境，然后在各个虚拟环境中分别维护依赖库环境。 例如，py37_test-pyenv虚拟环境位于$(pyenv root)/versions/3.7.1/envs目录下，而其依赖库位于$(pyenv root)/versions/3.7.1/lib/python3.7/site-packages中。 12345$ cd ~/workspace/test-pyenv$ pyenv version2.7.8 (set by /Users/seyvoue/workspace/test-pyenv/.python-version)$ pip -Vpip 18.1 from /usr/local/opt/pyenv/versions/2.7.8/lib/python2.7/site-packages/pip (python 2.7) 后续在项目开发过程中，我们就可以通过pyenv local XXX或pyenv activate PROJECT_NAME命令来切换项目的Python环境。 12345678$ cd ~/workspace/test-pyenv$ pyenv local py37_test-pyenv$ pyenv versionpy37_test-pyenv (set by /Users/seyvoue/workspace/test-pyenv/.python-version)$ python -VPython 3.7.1$ pip -Vpip 10.0.1 from /usr/local/opt/pyenv/versions/3.7.1/envs/py37_test-pyenv/lib/python3.7/site-packages/pip (python 3.7) 可以看出，切换环境后，pip命令对应的目录也随之改变，即始终对应着当前的Python虚拟环境。 对应的，采用pyenv deactivate命令退出当前项目的Python虚拟环境。 如果想移除某个项目环境，可以通过如下命令实现。 1$ pyenv uninstall PROJECT_NAME 以上便是日常开发工作中常用的pyenv命令，基本可以满足绝大多数依赖库环境管理方面的需求。 参考链接 使用pyenv管理多个Python版本依赖环境 Python版本管理神器-pyenv Simple Python Version Management: pyenv, from github]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@解决 Oracle Net Configuration Assistant Failed 问题]]></title>
    <url>%2Fmanual%2F428b54b1.html</url>
    <content type="text"><![CDATA[问题描述现象1：在安装 oracle 12c 时，出现 Oracle Net Configuration Assistant Failed 下图 现象2：执行 lsnrctl status，出现 TNS-12541无监听，如：12345678[oracle@oem ~]$ lsnrctl status listenerLSNRCTL for Linux: Version 11.1.0.6.0 - Production on 22-NOV-2009 13:18:35Copyright (c) 1991, 2007, Oracle. All rights reserved.Connecting to (ADDRESS=(PROTOCOL=tcp)(HOST=)(PORT=1521))TNS-12541: TNS:no listener TNS-12560: TNS:protocol adapter error TNS-00511: No listener Linux Error: 111: Connection refused 或者出现The listener supports no services，如：1234567891011121314151617181920212223[oracle@oem ~]$ lsnrctl statusLSNRCTL for Linux: Version 12.1.0.2.0 - Production on 13-NOV-2018 04:10:23Copyright (c) 1991, 2014, Oracle. All rights reserved.Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oem.com)(PORT=1521)))STATUS of the LISTENER------------------------Alias LISTENERVersion TNSLSNR for Linux: Version 12.1.0.2.0 - ProductionStart Date 13-NOV-2018 04:06:01Uptime 0 days 0 hr. 4 min. 22 secTrace Level offSecurity ON: Local OS AuthenticationSNMP OFFListener Parameter File /u01/app/oracle/product/12.1.0/dbhome_1/network/admin/listener.oraListener Log File /u01/app/oracle/diag/tnslsnr/oem/listener/alert/log.xmlListening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=oem.com)(PORT=1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))The listener supports no servicesThe command completed successfully 现象3：/u01/app/oracle/product/12.1.0/dbhome_1/network/admin/ 目录下没有 listener.ora 文件 解决方案在 macos 上打开一个新的终端，运行 net configuration assistant 向导程序。执行以下内容：1234ssh -Y oracle@192.168.12.174oracle@192.168.12.174's password:Last login: Tue Nov 13 04:04:24 2018[oracle@oem ~]$ /u01/app/oracle/product/12.1.0/dbhome_1/bin/netca 注：mac 上需要安装 xquartz，否则无法运行 netca GUI 向导界面 然后，按照此文一步一步操作即可。]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@在 centos7 下安装 oracle 12c]]></title>
    <url>%2Fmanual%2Fe2a845a8.html</url>
    <content type="text"><![CDATA[图形界面方式在 centos 7 下安装 oracle 12c R1 环境 VM: VMware Fusion 8.5 hostname: localhost.localdomain ip: 192.168.12.xxx OS: CentOS Linux 7 (Core) Memory: 4G (不小于4G) HDD: 100G /swap: 4G(不小于4G) /: 50G（最好大于40G） DB: Oracle Database 12c Release 1(12.1.0.2.0) - Enterprise Edition for Linux x86-64 （server class） EM: Oracle Enterprise Manager Cloud Control 12c Release 4 (12.1.0.4) for Linux x86-64 安装必须的软件包需要连接外网，从Oracle Public Yum仓库来安装oracle-rdbms-server-12cR1-preinstall 先下载 repo 文件 123456789101112[root@localhost zodas]# cd /etc/yum.repos.d/[root@localhost yum.repos.d]# wget http://public-yum.oracle.com/public-yum-ol7.repo--2018-11-12 20:20:20-- http://public-yum.oracle.com/public-yum-ol7.repoResolving public-yum.oracle.com (public-yum.oracle.com)... 23.35.178.109Connecting to public-yum.oracle.com (public-yum.oracle.com)|23.35.178.109|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 14602 (14K) [text/plain]Saving to: ‘public-yum-ol7.repo’100%[========================================================================================================================================&gt;] 14,602 --.-K/s in 0s2018-11-12 20:20:21 (197 MB/s) - ‘public-yum-ol7.repo’ saved [14602/14602] 测试 yum 是否正常工作12345678910111213141516171819202122[root@localhost yum.repos.d]# yum repolistLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.njupt.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.njupt.edu.cnol7_UEKR4 | 1.2 kB 00:00:00ol7_latest | 1.4 kB 00:00:00(1/5): ol7_UEKR4/x86_64/updateinfo | 82 kB 00:00:00(2/5): ol7_latest/x86_64/group | 659 kB 00:00:00(3/5): ol7_UEKR4/x86_64/primary | 3.5 MB 00:00:01(4/5): ol7_latest/x86_64/primary | 9.5 MB 00:00:04(5/5): ol7_latest/x86_64/updateinfo | 740 kB 00:00:19ol7_UEKR4 124/124ol7_latest 11482/11482repo id repo name statusbase/7/x86_64 CentOS-7 - Base 9,911extras/7/x86_64 CentOS-7 - Extras 434ol7_UEKR4/x86_64 Latest Unbreakable Enterprise Kernel Release 4 for Oracle Linux 7 (x86_64) 124ol7_latest/x86_64 Oracle Linux 7 Latest (x86_64) 11,482updates/7/x86_64 CentOS-7 - Updates 1,614repolist: 23,565 下载 RPM-GPG-KEY-oracle1234567891011[root@localhost yum.repos.d]# wget https://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle--2018-11-12 20:22:51-- https://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7Resolving public-yum.oracle.com (public-yum.oracle.com)... 23.51.208.99Connecting to public-yum.oracle.com (public-yum.oracle.com)|23.51.208.99|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 1011 [text/plain]Saving to: ‘/etc/pki/rpm-gpg/RPM-GPG-KEY-oracle’100%[========================================================================================================================================&gt;] 1,011 --.-K/s in 0s2018-11-12 20:22:53 (127 MB/s) - ‘/etc/pki/rpm-gpg/RPM-GPG-KEY-oracle’ saved [1011/1011] 安装 oracle-rdbms-server-12cR1-preinstall 点击显/隐内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523[root@localhost yum.repos.d]# yum install oracle-rdbms-server-12cR1-preinstallLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.njupt.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.njupt.edu.cnResolving Dependencies--&gt; Running transaction check---&gt; Package oracle-rdbms-server-12cR1-preinstall.x86_64 0:1.0-7.el7 will be installed--&gt; Processing Dependency: bc for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: gcc for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: sysstat for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: xorg-x11-utils for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: bind-utils for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: gcc-c++ for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: kernel-uek for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: compat-libcap1 for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: ksh for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: libaio-devel for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: xorg-x11-xauth for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: psmisc for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: unzip for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: glibc-devel for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: compat-libstdc++-33 for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: libstdc++-devel for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: nfs-utils for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Processing Dependency: smartmontools for package: oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64--&gt; Running transaction check---&gt; Package bc.x86_64 0:1.06.95-13.el7 will be installed---&gt; Package bind-utils.x86_64 32:9.9.4-72.el7 will be installed--&gt; Processing Dependency: bind-libs = 32:9.9.4-72.el7 for package: 32:bind-utils-9.9.4-72.el7.x86_64--&gt; Processing Dependency: libisccc.so.90()(64bit) for package: 32:bind-utils-9.9.4-72.el7.x86_64--&gt; Processing Dependency: liblwres.so.90()(64bit) for package: 32:bind-utils-9.9.4-72.el7.x86_64--&gt; Processing Dependency: libbind9.so.90()(64bit) for package: 32:bind-utils-9.9.4-72.el7.x86_64--&gt; Processing Dependency: libisc.so.95()(64bit) for package: 32:bind-utils-9.9.4-72.el7.x86_64--&gt; Processing Dependency: libdns.so.100()(64bit) for package: 32:bind-utils-9.9.4-72.el7.x86_64--&gt; Processing Dependency: libisccfg.so.90()(64bit) for package: 32:bind-utils-9.9.4-72.el7.x86_64---&gt; Package compat-libcap1.x86_64 0:1.10-7.el7 will be installed---&gt; Package compat-libstdc++-33.x86_64 0:3.2.3-72.el7 will be installed---&gt; Package gcc.x86_64 0:4.8.5-36.0.1.el7 will be installed--&gt; Processing Dependency: libgomp = 4.8.5-36.0.1.el7 for package: gcc-4.8.5-36.0.1.el7.x86_64--&gt; Processing Dependency: cpp = 4.8.5-36.0.1.el7 for package: gcc-4.8.5-36.0.1.el7.x86_64--&gt; Processing Dependency: libgcc &gt;= 4.8.5-36.0.1.el7 for package: gcc-4.8.5-36.0.1.el7.x86_64--&gt; Processing Dependency: libmpfr.so.4()(64bit) for package: gcc-4.8.5-36.0.1.el7.x86_64--&gt; Processing Dependency: libmpc.so.3()(64bit) for package: gcc-4.8.5-36.0.1.el7.x86_64---&gt; Package gcc-c++.x86_64 0:4.8.5-36.0.1.el7 will be installed--&gt; Processing Dependency: libstdc++ = 4.8.5-36.0.1.el7 for package: gcc-c++-4.8.5-36.0.1.el7.x86_64---&gt; Package glibc-devel.x86_64 0:2.17-260.0.9.el7 will be installed--&gt; Processing Dependency: glibc-headers = 2.17-260.0.9.el7 for package: glibc-devel-2.17-260.0.9.el7.x86_64--&gt; Processing Dependency: glibc = 2.17-260.0.9.el7 for package: glibc-devel-2.17-260.0.9.el7.x86_64--&gt; Processing Dependency: glibc-headers for package: glibc-devel-2.17-260.0.9.el7.x86_64---&gt; Package kernel-container.x86_64 0:3.10.0-0.0.0.2.el7 will be installed---&gt; Package ksh.x86_64 0:20120801-139.0.1.el7 will be installed---&gt; Package libaio-devel.x86_64 0:0.3.109-13.el7 will be installed---&gt; Package libstdc++-devel.x86_64 0:4.8.5-36.0.1.el7 will be installed---&gt; Package nfs-utils.x86_64 1:1.3.0-0.61.0.1.el7 will be installed--&gt; Processing Dependency: gssproxy &gt;= 0.7.0-3 for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: libtirpc &gt;= 0.2.4-0.7 for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: rpcbind for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: keyutils for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: quota for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: libevent for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: libnfsidmap for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: libevent-2.0.so.5()(64bit) for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: libtirpc.so.1()(64bit) for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64--&gt; Processing Dependency: libnfsidmap.so.0()(64bit) for package: 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64---&gt; Package psmisc.x86_64 0:22.20-15.el7 will be installed---&gt; Package smartmontools.x86_64 1:6.5-1.el7 will be installed--&gt; Processing Dependency: mailx for package: 1:smartmontools-6.5-1.el7.x86_64---&gt; Package sysstat.x86_64 0:10.1.5-17.el7 will be installed--&gt; Processing Dependency: libsensors.so.4()(64bit) for package: sysstat-10.1.5-17.el7.x86_64---&gt; Package unzip.x86_64 0:6.0-19.el7 will be installed---&gt; Package xorg-x11-utils.x86_64 0:7.5-23.el7 will be installed--&gt; Processing Dependency: libXext.so.6()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXv.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXtst.so.6()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXrender.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXxf86vm.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXxf86misc.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libX11-xcb.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXrandr.so.2()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libdmx.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXinerama.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libX11.so.6()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXxf86dga.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libxcb.so.1()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libxcb-shape.so.0()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64--&gt; Processing Dependency: libXi.so.6()(64bit) for package: xorg-x11-utils-7.5-23.el7.x86_64---&gt; Package xorg-x11-xauth.x86_64 1:1.0.9-1.el7 will be installed--&gt; Processing Dependency: libXmuu.so.1()(64bit) for package: 1:xorg-x11-xauth-1.0.9-1.el7.x86_64--&gt; Processing Dependency: libXau.so.6()(64bit) for package: 1:xorg-x11-xauth-1.0.9-1.el7.x86_64--&gt; Running transaction check---&gt; Package bind-libs.x86_64 32:9.9.4-72.el7 will be installed--&gt; Processing Dependency: bind-license = 32:9.9.4-72.el7 for package: 32:bind-libs-9.9.4-72.el7.x86_64---&gt; Package cpp.x86_64 0:4.8.5-36.0.1.el7 will be installed---&gt; Package glibc.x86_64 0:2.17-222.el7 will be updated--&gt; Processing Dependency: glibc = 2.17-222.el7 for package: glibc-common-2.17-222.el7.x86_64---&gt; Package glibc.x86_64 0:2.17-260.0.9.el7 will be an update---&gt; Package glibc-headers.x86_64 0:2.17-260.0.9.el7 will be installed--&gt; Processing Dependency: kernel-headers &gt;= 2.2.1 for package: glibc-headers-2.17-260.0.9.el7.x86_64--&gt; Processing Dependency: kernel-headers for package: glibc-headers-2.17-260.0.9.el7.x86_64---&gt; Package gssproxy.x86_64 0:0.7.0-21.el7 will be installed--&gt; Processing Dependency: libini_config &gt;= 1.3.1-31 for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libref_array.so.1(REF_ARRAY_0.1.1)(64bit) for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libini_config.so.3(INI_CONFIG_1.1.0)(64bit) for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libini_config.so.3(INI_CONFIG_1.2.0)(64bit) for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libverto-module-base for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libini_config.so.3()(64bit) for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libbasicobjects.so.0()(64bit) for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libref_array.so.1()(64bit) for package: gssproxy-0.7.0-21.el7.x86_64--&gt; Processing Dependency: libcollection.so.2()(64bit) for package: gssproxy-0.7.0-21.el7.x86_64---&gt; Package keyutils.x86_64 0:1.5.8-3.el7 will be installed---&gt; Package libX11.x86_64 0:1.6.5-2.el7 will be installed--&gt; Processing Dependency: libX11-common &gt;= 1.6.5-2.el7 for package: libX11-1.6.5-2.el7.x86_64---&gt; Package libXau.x86_64 0:1.0.8-2.1.el7 will be installed---&gt; Package libXext.x86_64 0:1.3.3-3.el7 will be installed---&gt; Package libXi.x86_64 0:1.7.9-1.el7 will be installed---&gt; Package libXinerama.x86_64 0:1.1.3-2.1.el7 will be installed---&gt; Package libXmu.x86_64 0:1.1.2-2.el7 will be installed--&gt; Processing Dependency: libXt.so.6()(64bit) for package: libXmu-1.1.2-2.el7.x86_64---&gt; Package libXrandr.x86_64 0:1.5.1-2.el7 will be installed---&gt; Package libXrender.x86_64 0:0.9.10-1.el7 will be installed---&gt; Package libXtst.x86_64 0:1.2.3-1.el7 will be installed---&gt; Package libXv.x86_64 0:1.0.11-1.el7 will be installed---&gt; Package libXxf86dga.x86_64 0:1.1.4-2.1.el7 will be installed---&gt; Package libXxf86misc.x86_64 0:1.0.3-7.1.el7 will be installed---&gt; Package libXxf86vm.x86_64 0:1.1.4-1.el7 will be installed---&gt; Package libdmx.x86_64 0:1.1.3-3.el7 will be installed---&gt; Package libevent.x86_64 0:2.0.21-4.el7 will be installed---&gt; Package libgcc.x86_64 0:4.8.5-28.el7_5.1 will be updated---&gt; Package libgcc.x86_64 0:4.8.5-36.0.1.el7 will be an update---&gt; Package libgomp.x86_64 0:4.8.5-28.el7_5.1 will be updated---&gt; Package libgomp.x86_64 0:4.8.5-36.0.1.el7 will be an update---&gt; Package libmpc.x86_64 0:1.0.1-3.el7 will be installed---&gt; Package libnfsidmap.x86_64 0:0.25-19.el7 will be installed---&gt; Package libstdc++.x86_64 0:4.8.5-28.el7_5.1 will be updated---&gt; Package libstdc++.x86_64 0:4.8.5-36.0.1.el7 will be an update---&gt; Package libtirpc.x86_64 0:0.2.4-0.15.el7 will be installed---&gt; Package libxcb.x86_64 0:1.13-1.el7 will be installed---&gt; Package lm_sensors-libs.x86_64 0:3.4.0-6.20160601gitf9185e5.el7 will be installed---&gt; Package mailx.x86_64 0:12.5-19.el7 will be installed---&gt; Package mpfr.x86_64 0:3.1.1-4.el7 will be installed---&gt; Package quota.x86_64 1:4.01-17.el7 will be installed--&gt; Processing Dependency: quota-nls = 1:4.01-17.el7 for package: 1:quota-4.01-17.el7.x86_64--&gt; Processing Dependency: tcp_wrappers for package: 1:quota-4.01-17.el7.x86_64---&gt; Package rpcbind.x86_64 0:0.2.0-47.el7 will be installed--&gt; Running transaction check---&gt; Package bind-license.noarch 32:9.9.4-61.el7_5.1 will be updated--&gt; Processing Dependency: bind-license = 32:9.9.4-61.el7_5.1 for package: 32:bind-libs-lite-9.9.4-61.el7_5.1.x86_64---&gt; Package bind-license.noarch 32:9.9.4-72.el7 will be an update---&gt; Package glibc-common.x86_64 0:2.17-222.el7 will be updated---&gt; Package glibc-common.x86_64 0:2.17-260.0.9.el7 will be an update---&gt; Package kernel-headers.x86_64 0:3.10.0-957.el7 will be installed---&gt; Package libX11-common.noarch 0:1.6.5-2.el7 will be installed---&gt; Package libXt.x86_64 0:1.1.5-3.el7 will be installed--&gt; Processing Dependency: libSM.so.6()(64bit) for package: libXt-1.1.5-3.el7.x86_64--&gt; Processing Dependency: libICE.so.6()(64bit) for package: libXt-1.1.5-3.el7.x86_64---&gt; Package libbasicobjects.x86_64 0:0.1.1-32.el7 will be installed---&gt; Package libcollection.x86_64 0:0.7.0-32.el7 will be installed---&gt; Package libini_config.x86_64 0:1.3.1-32.el7 will be installed--&gt; Processing Dependency: libpath_utils.so.1(PATH_UTILS_0.2.1)(64bit) for package: libini_config-1.3.1-32.el7.x86_64--&gt; Processing Dependency: libpath_utils.so.1()(64bit) for package: libini_config-1.3.1-32.el7.x86_64---&gt; Package libref_array.x86_64 0:0.1.5-32.el7 will be installed---&gt; Package libverto-libevent.x86_64 0:0.2.5-4.el7 will be installed---&gt; Package quota-nls.noarch 1:4.01-17.el7 will be installed---&gt; Package tcp_wrappers.x86_64 0:7.6-77.el7 will be installed--&gt; Running transaction check---&gt; Package bind-libs-lite.x86_64 32:9.9.4-61.el7_5.1 will be updated---&gt; Package bind-libs-lite.x86_64 32:9.9.4-72.el7 will be an update---&gt; Package libICE.x86_64 0:1.0.9-9.el7 will be installed---&gt; Package libSM.x86_64 0:1.2.2-2.el7 will be installed---&gt; Package libpath_utils.x86_64 0:0.2.1-32.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved================================================================================================================================================================================== Package Arch Version Repository Size==================================================================================================================================================================================Installing: oracle-rdbms-server-12cR1-preinstall x86_64 1.0-7.el7 ol7_latest 21 kInstalling for dependencies: bc x86_64 1.06.95-13.el7 base 115 k bind-libs x86_64 32:9.9.4-72.el7 ol7_latest 1.0 M bind-utils x86_64 32:9.9.4-72.el7 ol7_latest 205 k compat-libcap1 x86_64 1.10-7.el7 base 19 k compat-libstdc++-33 x86_64 3.2.3-72.el7 base 191 k cpp x86_64 4.8.5-36.0.1.el7 ol7_latest 5.9 M gcc x86_64 4.8.5-36.0.1.el7 ol7_latest 16 M gcc-c++ x86_64 4.8.5-36.0.1.el7 ol7_latest 7.2 M glibc-devel x86_64 2.17-260.0.9.el7 ol7_latest 1.1 M glibc-headers x86_64 2.17-260.0.9.el7 ol7_latest 684 k gssproxy x86_64 0.7.0-21.el7 ol7_latest 108 k kernel-container x86_64 3.10.0-0.0.0.2.el7 ol7_latest 2.6 k kernel-headers x86_64 3.10.0-957.el7 ol7_latest 8.0 M keyutils x86_64 1.5.8-3.el7 base 54 k ksh x86_64 20120801-139.0.1.el7 ol7_latest 883 k libICE x86_64 1.0.9-9.el7 base 66 k libSM x86_64 1.2.2-2.el7 base 39 k libX11 x86_64 1.6.5-2.el7 ol7_latest 606 k libX11-common noarch 1.6.5-2.el7 ol7_latest 163 k libXau x86_64 1.0.8-2.1.el7 base 29 k libXext x86_64 1.3.3-3.el7 base 39 k libXi x86_64 1.7.9-1.el7 base 40 k libXinerama x86_64 1.1.3-2.1.el7 base 14 k libXmu x86_64 1.1.2-2.el7 base 71 k libXrandr x86_64 1.5.1-2.el7 base 27 k libXrender x86_64 0.9.10-1.el7 base 26 k libXt x86_64 1.1.5-3.el7 base 173 k libXtst x86_64 1.2.3-1.el7 base 20 k libXv x86_64 1.0.11-1.el7 base 18 k libXxf86dga x86_64 1.1.4-2.1.el7 base 19 k libXxf86misc x86_64 1.0.3-7.1.el7 base 19 k libXxf86vm x86_64 1.1.4-1.el7 base 18 k libaio-devel x86_64 0.3.109-13.el7 base 13 k libbasicobjects x86_64 0.1.1-32.el7 ol7_latest 25 k libcollection x86_64 0.7.0-32.el7 ol7_latest 41 k libdmx x86_64 1.1.3-3.el7 base 16 k libevent x86_64 2.0.21-4.el7 base 214 k libini_config x86_64 1.3.1-32.el7 ol7_latest 63 k libmpc x86_64 1.0.1-3.el7 base 51 k libnfsidmap x86_64 0.25-19.el7 base 50 k libpath_utils x86_64 0.2.1-32.el7 ol7_latest 28 k libref_array x86_64 0.1.5-32.el7 ol7_latest 27 k libstdc++-devel x86_64 4.8.5-36.0.1.el7 ol7_latest 1.5 M libtirpc x86_64 0.2.4-0.15.el7 ol7_latest 88 k libverto-libevent x86_64 0.2.5-4.el7 base 8.9 k libxcb x86_64 1.13-1.el7 ol7_latest 213 k lm_sensors-libs x86_64 3.4.0-6.20160601gitf9185e5.el7 ol7_latest 41 k mailx x86_64 12.5-19.el7 base 245 k mpfr x86_64 3.1.1-4.el7 base 203 k nfs-utils x86_64 1:1.3.0-0.61.0.1.el7 ol7_latest 410 k psmisc x86_64 22.20-15.el7 base 141 k quota x86_64 1:4.01-17.el7 base 179 k quota-nls noarch 1:4.01-17.el7 base 90 k rpcbind x86_64 0.2.0-47.el7 ol7_latest 59 k smartmontools x86_64 1:6.5-1.el7 base 460 k sysstat x86_64 10.1.5-17.el7 ol7_latest 314 k tcp_wrappers x86_64 7.6-77.el7 base 78 k unzip x86_64 6.0-19.el7 base 170 k xorg-x11-utils x86_64 7.5-23.el7 ol7_latest 114 k xorg-x11-xauth x86_64 1:1.0.9-1.el7 base 30 kUpdating for dependencies: bind-libs-lite x86_64 32:9.9.4-72.el7 ol7_latest 740 k bind-license noarch 32:9.9.4-72.el7 ol7_latest 86 k glibc x86_64 2.17-260.0.9.el7 ol7_latest 3.6 M glibc-common x86_64 2.17-260.0.9.el7 ol7_latest 11 M libgcc x86_64 4.8.5-36.0.1.el7 ol7_latest 101 k libgomp x86_64 4.8.5-36.0.1.el7 ol7_latest 157 k libstdc++ x86_64 4.8.5-36.0.1.el7 ol7_latest 304 kTransaction Summary==================================================================================================================================================================================Install 1 Package (+60 Dependent packages)Upgrade ( 7 Dependent packages)Total download size: 64 MIs this ok [y/d/N]: yDownloading packages:Delta RPMs disabled because /usr/bin/applydeltarpm not installed.(1/68): bc-1.06.95-13.el7.x86_64.rpm | 115 kB 00:00:00warning: /var/cache/yum/x86_64/7/ol7_latest/packages/bind-libs-lite-9.9.4-72.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID ec551f03: NOKEY57 kB/s | 502 kB 00:02:22 ETAPublic key for bind-libs-lite-9.9.4-72.el7.x86_64.rpm is not installed(2/68): bind-libs-lite-9.9.4-72.el7.x86_64.rpm | 740 kB 00:00:01(3/68): bind-libs-9.9.4-72.el7.x86_64.rpm | 1.0 MB 00:00:01(4/68): compat-libcap1-1.10-7.el7.x86_64.rpm | 19 kB 00:00:00(5/68): bind-utils-9.9.4-72.el7.x86_64.rpm | 205 kB 00:00:00(6/68): bind-license-9.9.4-72.el7.noarch.rpm | 86 kB 00:00:00(7/68): compat-libstdc++-33-3.2.3-72.el7.x86_64.rpm | 191 kB 00:00:00(8/68): cpp-4.8.5-36.0.1.el7.x86_64.rpm | 5.9 MB 00:00:01(9/68): gcc-c++-4.8.5-36.0.1.el7.x86_64.rpm | 7.2 MB 00:00:02(10/68): glibc-2.17-260.0.9.el7.x86_64.rpm | 3.6 MB 00:00:01(11/68): glibc-common-2.17-260.0.9.el7.x86_64.rpm | 11 MB 00:00:02(12/68): glibc-devel-2.17-260.0.9.el7.x86_64.rpm | 1.1 MB 00:00:00(13/68): glibc-headers-2.17-260.0.9.el7.x86_64.rpm | 684 kB 00:00:00(14/68): gssproxy-0.7.0-21.el7.x86_64.rpm | 108 kB 00:00:00(15/68): kernel-container-3.10.0-0.0.0.2.el7.x86_64.rpm | 2.6 kB 00:00:00(16/68): keyutils-1.5.8-3.el7.x86_64.rpm | 54 kB 00:00:00(17/68): kernel-headers-3.10.0-957.el7.x86_64.rpm | 8.0 MB 00:00:01(18/68): libICE-1.0.9-9.el7.x86_64.rpm | 66 kB 00:00:00(19/68): libSM-1.2.2-2.el7.x86_64.rpm | 39 kB 00:00:00(20/68): ksh-20120801-139.0.1.el7.x86_64.rpm | 883 kB 00:00:00(21/68): libX11-1.6.5-2.el7.x86_64.rpm | 606 kB 00:00:00(22/68): libXau-1.0.8-2.1.el7.x86_64.rpm | 29 kB 00:00:00(23/68): libX11-common-1.6.5-2.el7.noarch.rpm | 163 kB 00:00:00(24/68): libXinerama-1.1.3-2.1.el7.x86_64.rpm | 14 kB 00:00:00(25/68): libXext-1.3.3-3.el7.x86_64.rpm | 39 kB 00:00:00(26/68): libXmu-1.1.2-2.el7.x86_64.rpm | 71 kB 00:00:00(27/68): libXi-1.7.9-1.el7.x86_64.rpm | 40 kB 00:00:00(28/68): libXrandr-1.5.1-2.el7.x86_64.rpm | 27 kB 00:00:00(29/68): libXtst-1.2.3-1.el7.x86_64.rpm | 20 kB 00:00:00(30/68): libXrender-0.9.10-1.el7.x86_64.rpm | 26 kB 00:00:00(31/68): libXv-1.0.11-1.el7.x86_64.rpm | 18 kB 00:00:00(32/68): libXxf86dga-1.1.4-2.1.el7.x86_64.rpm | 19 kB 00:00:00(33/68): libXxf86misc-1.0.3-7.1.el7.x86_64.rpm | 19 kB 00:00:00(34/68): libXt-1.1.5-3.el7.x86_64.rpm | 173 kB 00:00:00(35/68): libXxf86vm-1.1.4-1.el7.x86_64.rpm | 18 kB 00:00:00(36/68): libbasicobjects-0.1.1-32.el7.x86_64.rpm | 25 kB 00:00:00(37/68): libaio-devel-0.3.109-13.el7.x86_64.rpm | 13 kB 00:00:00(38/68): libcollection-0.7.0-32.el7.x86_64.rpm | 41 kB 00:00:00(39/68): libevent-2.0.21-4.el7.x86_64.rpm | 214 kB 00:00:00(40/68): libdmx-1.1.3-3.el7.x86_64.rpm | 16 kB 00:00:00(41/68): libgcc-4.8.5-36.0.1.el7.x86_64.rpm | 101 kB 00:00:00(42/68): libgomp-4.8.5-36.0.1.el7.x86_64.rpm | 157 kB 00:00:00(43/68): libmpc-1.0.1-3.el7.x86_64.rpm | 51 kB 00:00:00(44/68): libini_config-1.3.1-32.el7.x86_64.rpm | 63 kB 00:00:00(45/68): libpath_utils-0.2.1-32.el7.x86_64.rpm | 28 kB 00:00:00(46/68): libref_array-0.1.5-32.el7.x86_64.rpm | 27 kB 00:00:00(47/68): libnfsidmap-0.25-19.el7.x86_64.rpm | 50 kB 00:00:00(48/68): libstdc++-4.8.5-36.0.1.el7.x86_64.rpm | 304 kB 00:00:00(49/68): libstdc++-devel-4.8.5-36.0.1.el7.x86_64.rpm | 1.5 MB 00:00:00(50/68): libtirpc-0.2.4-0.15.el7.x86_64.rpm | 88 kB 00:00:00(51/68): libverto-libevent-0.2.5-4.el7.x86_64.rpm | 8.9 kB 00:00:00(52/68): libxcb-1.13-1.el7.x86_64.rpm | 213 kB 00:00:00(53/68): lm_sensors-libs-3.4.0-6.20160601gitf9185e5.el7.x86_64.rpm | 41 kB 00:00:00(54/68): mailx-12.5-19.el7.x86_64.rpm | 245 kB 00:00:00(55/68): nfs-utils-1.3.0-0.61.0.1.el7.x86_64.rpm | 410 kB 00:00:00(56/68): oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64.rpm | 21 kB 00:00:00(57/68): psmisc-22.20-15.el7.x86_64.rpm | 141 kB 00:00:00(58/68): rpcbind-0.2.0-47.el7.x86_64.rpm | 59 kB 00:00:00(59/68): quota-nls-4.01-17.el7.noarch.rpm | 90 kB 00:00:00(60/68): quota-4.01-17.el7.x86_64.rpm | 179 kB 00:00:00(61/68): smartmontools-6.5-1.el7.x86_64.rpm | 460 kB 00:00:00(62/68): mpfr-3.1.1-4.el7.x86_64.rpm | 203 kB 00:00:00(63/68): sysstat-10.1.5-17.el7.x86_64.rpm | 314 kB 00:00:00(64/68): xorg-x11-utils-7.5-23.el7.x86_64.rpm | 114 kB 00:00:00(65/68): unzip-6.0-19.el7.x86_64.rpm | 170 kB 00:00:00(66/68): xorg-x11-xauth-1.0.9-1.el7.x86_64.rpm | 30 kB 00:00:00(67/68): tcp_wrappers-7.6-77.el7.x86_64.rpm | 78 kB 00:00:00(68/68): gcc-4.8.5-36.0.1.el7.x86_64.rpm | 16 MB 00:01:05----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Total 973 kB/s | 64 MB 00:01:07Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracleImporting GPG key 0xEC551F03: Userid : "Oracle OSS group (Open Source Software group) &lt;build@oss.oracle.com&gt;" Fingerprint: 4214 4123 fecf c55b 9086 313d 72f9 7b74 ec55 1f03 From : /etc/pki/rpm-gpg/RPM-GPG-KEY-oracleIs this ok [y/N]: yRunning transaction checkRunning transaction testTransaction test succeededRunning transaction Updating : libgcc-4.8.5-36.0.1.el7.x86_64 1/75 Updating : glibc-common-2.17-260.0.9.el7.x86_64 2/75 Updating : glibc-2.17-260.0.9.el7.x86_64 3/75 Updating : libstdc++-4.8.5-36.0.1.el7.x86_64 4/75 Installing : mpfr-3.1.1-4.el7.x86_64 5/75 Installing : libmpc-1.0.1-3.el7.x86_64 6/75 Installing : libstdc++-devel-4.8.5-36.0.1.el7.x86_64 7/75 Installing : libref_array-0.1.5-32.el7.x86_64 8/75 Installing : libbasicobjects-0.1.1-32.el7.x86_64 9/75 Installing : libevent-2.0.21-4.el7.x86_64 10/75 Installing : libICE-1.0.9-9.el7.x86_64 11/75 Installing : libcollection-0.7.0-32.el7.x86_64 12/75 Installing : libXau-1.0.8-2.1.el7.x86_64 13/75 Installing : libxcb-1.13-1.el7.x86_64 14/75 Installing : libtirpc-0.2.4-0.15.el7.x86_64 15/75 Installing : rpcbind-0.2.0-47.el7.x86_64 16/75 Updating : 32:bind-license-9.9.4-72.el7.noarch 17/75 Installing : 32:bind-libs-9.9.4-72.el7.x86_64 18/75 Installing : 32:bind-utils-9.9.4-72.el7.x86_64 19/75 Installing : libSM-1.2.2-2.el7.x86_64 20/75 Installing : libverto-libevent-0.2.5-4.el7.x86_64 21/75 Installing : cpp-4.8.5-36.0.1.el7.x86_64 22/75 Installing : bc-1.06.95-13.el7.x86_64 23/75 Installing : tcp_wrappers-7.6-77.el7.x86_64 24/75 Installing : psmisc-22.20-15.el7.x86_64 25/75 Updating : libgomp-4.8.5-36.0.1.el7.x86_64 26/75 Installing : libpath_utils-0.2.1-32.el7.x86_64 27/75 Installing : libini_config-1.3.1-32.el7.x86_64 28/75 Installing : gssproxy-0.7.0-21.el7.x86_64 29/75 Installing : lm_sensors-libs-3.4.0-6.20160601gitf9185e5.el7.x86_64 30/75 Installing : sysstat-10.1.5-17.el7.x86_64 31/75 Installing : compat-libcap1-1.10-7.el7.x86_64 32/75 Installing : ksh-20120801-139.0.1.el7.x86_64 33/75 Installing : libnfsidmap-0.25-19.el7.x86_64 34/75 Installing : keyutils-1.5.8-3.el7.x86_64 35/75 Installing : compat-libstdc++-33-3.2.3-72.el7.x86_64 36/75 Installing : unzip-6.0-19.el7.x86_64 37/75 Installing : mailx-12.5-19.el7.x86_64 38/75 Installing : 1:smartmontools-6.5-1.el7.x86_64 39/75 Installing : kernel-headers-3.10.0-957.el7.x86_64 40/75 Installing : glibc-headers-2.17-260.0.9.el7.x86_64 41/75 Installing : glibc-devel-2.17-260.0.9.el7.x86_64 42/75 Installing : gcc-4.8.5-36.0.1.el7.x86_64 43/75 Installing : gcc-c++-4.8.5-36.0.1.el7.x86_64 44/75 Installing : libaio-devel-0.3.109-13.el7.x86_64 45/75 Installing : 1:quota-nls-4.01-17.el7.noarch 46/75 Installing : 1:quota-4.01-17.el7.x86_64 47/75 Installing : 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64 48/75 Installing : libX11-common-1.6.5-2.el7.noarch 49/75 Installing : libX11-1.6.5-2.el7.x86_64 50/75 Installing : libXext-1.3.3-3.el7.x86_64 51/75 Installing : libXi-1.7.9-1.el7.x86_64 52/75 Installing : libXrender-0.9.10-1.el7.x86_64 53/75 Installing : libXrandr-1.5.1-2.el7.x86_64 54/75 Installing : libXtst-1.2.3-1.el7.x86_64 55/75 Installing : libXxf86misc-1.0.3-7.1.el7.x86_64 56/75 Installing : libdmx-1.1.3-3.el7.x86_64 57/75 Installing : libXinerama-1.1.3-2.1.el7.x86_64 58/75 Installing : libXxf86vm-1.1.4-1.el7.x86_64 59/75 Installing : libXv-1.0.11-1.el7.x86_64 60/75 Installing : libXxf86dga-1.1.4-2.1.el7.x86_64 61/75 Installing : xorg-x11-utils-7.5-23.el7.x86_64 62/75 Installing : libXt-1.1.5-3.el7.x86_64 63/75 Installing : libXmu-1.1.2-2.el7.x86_64 64/75 Installing : 1:xorg-x11-xauth-1.0.9-1.el7.x86_64 65/75 Installing : kernel-container-3.10.0-0.0.0.2.el7.x86_64 66/75 Installing : oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64 67/75 Updating : 32:bind-libs-lite-9.9.4-72.el7.x86_64 68/75 Cleanup : 32:bind-libs-lite-9.9.4-61.el7_5.1.x86_64 69/75 Cleanup : libstdc++-4.8.5-28.el7_5.1.x86_64 70/75 Cleanup : libgomp-4.8.5-28.el7_5.1.x86_64 71/75 Cleanup : 32:bind-license-9.9.4-61.el7_5.1.noarch 72/75 Cleanup : glibc-common-2.17-222.el7.x86_64 73/75 Cleanup : glibc-2.17-222.el7.x86_64 74/75 Cleanup : libgcc-4.8.5-28.el7_5.1.x86_64 75/75 Verifying : libXext-1.3.3-3.el7.x86_64 1/75 Verifying : libXxf86misc-1.0.3-7.1.el7.x86_64 2/75 Verifying : libdmx-1.1.3-3.el7.x86_64 3/75 Verifying : libverto-libevent-0.2.5-4.el7.x86_64 4/75 Verifying : libXinerama-1.1.3-2.1.el7.x86_64 5/75 Verifying : libXrender-0.9.10-1.el7.x86_64 6/75 Verifying : libref_array-0.1.5-32.el7.x86_64 7/75 Verifying : glibc-headers-2.17-260.0.9.el7.x86_64 8/75 Verifying : libXi-1.7.9-1.el7.x86_64 9/75 Verifying : libXxf86vm-1.1.4-1.el7.x86_64 10/75 Verifying : glibc-devel-2.17-260.0.9.el7.x86_64 11/75 Verifying : kernel-container-3.10.0-0.0.0.2.el7.x86_64 12/75 Verifying : oracle-rdbms-server-12cR1-preinstall-1.0-7.el7.x86_64 13/75 Verifying : libgcc-4.8.5-36.0.1.el7.x86_64 14/75 Verifying : 32:bind-libs-9.9.4-72.el7.x86_64 15/75 Verifying : libX11-common-1.6.5-2.el7.noarch 16/75 Verifying : sysstat-10.1.5-17.el7.x86_64 17/75 Verifying : bc-1.06.95-13.el7.x86_64 18/75 Verifying : libstdc++-4.8.5-36.0.1.el7.x86_64 19/75 Verifying : libXv-1.0.11-1.el7.x86_64 20/75 Verifying : tcp_wrappers-7.6-77.el7.x86_64 21/75 Verifying : xorg-x11-utils-7.5-23.el7.x86_64 22/75 Verifying : glibc-common-2.17-260.0.9.el7.x86_64 23/75 Verifying : gcc-4.8.5-36.0.1.el7.x86_64 24/75 Verifying : libXt-1.1.5-3.el7.x86_64 25/75 Verifying : 1:nfs-utils-1.3.0-0.61.0.1.el7.x86_64 26/75 Verifying : libstdc++-devel-4.8.5-36.0.1.el7.x86_64 27/75 Verifying : 32:bind-libs-lite-9.9.4-72.el7.x86_64 28/75 Verifying : libbasicobjects-0.1.1-32.el7.x86_64 29/75 Verifying : psmisc-22.20-15.el7.x86_64 30/75 Verifying : libini_config-1.3.1-32.el7.x86_64 31/75 Verifying : libgomp-4.8.5-36.0.1.el7.x86_64 32/75 Verifying : 1:quota-nls-4.01-17.el7.noarch 33/75 Verifying : gcc-c++-4.8.5-36.0.1.el7.x86_64 34/75 Verifying : 32:bind-utils-9.9.4-72.el7.x86_64 35/75 Verifying : libpath_utils-0.2.1-32.el7.x86_64 36/75 Verifying : lm_sensors-libs-3.4.0-6.20160601gitf9185e5.el7.x86_64 37/75 Verifying : libevent-2.0.21-4.el7.x86_64 38/75 Verifying : cpp-4.8.5-36.0.1.el7.x86_64 39/75 Verifying : libX11-1.6.5-2.el7.x86_64 40/75 Verifying : gssproxy-0.7.0-21.el7.x86_64 41/75 Verifying : rpcbind-0.2.0-47.el7.x86_64 42/75 Verifying : libxcb-1.13-1.el7.x86_64 43/75 Verifying : compat-libcap1-1.10-7.el7.x86_64 44/75 Verifying : libXrandr-1.5.1-2.el7.x86_64 45/75 Verifying : libaio-devel-0.3.109-13.el7.x86_64 46/75 Verifying : libmpc-1.0.1-3.el7.x86_64 47/75 Verifying : 1:quota-4.01-17.el7.x86_64 48/75 Verifying : 1:xorg-x11-xauth-1.0.9-1.el7.x86_64 49/75 Verifying : 32:bind-license-9.9.4-72.el7.noarch 50/75 Verifying : ksh-20120801-139.0.1.el7.x86_64 51/75 Verifying : libICE-1.0.9-9.el7.x86_64 52/75 Verifying : glibc-2.17-260.0.9.el7.x86_64 53/75 Verifying : libnfsidmap-0.25-19.el7.x86_64 54/75 Verifying : kernel-headers-3.10.0-957.el7.x86_64 55/75 Verifying : libSM-1.2.2-2.el7.x86_64 56/75 Verifying : 1:smartmontools-6.5-1.el7.x86_64 57/75 Verifying : libXxf86dga-1.1.4-2.1.el7.x86_64 58/75 Verifying : mpfr-3.1.1-4.el7.x86_64 59/75 Verifying : keyutils-1.5.8-3.el7.x86_64 60/75 Verifying : compat-libstdc++-33-3.2.3-72.el7.x86_64 61/75 Verifying : libcollection-0.7.0-32.el7.x86_64 62/75 Verifying : libXau-1.0.8-2.1.el7.x86_64 63/75 Verifying : libXtst-1.2.3-1.el7.x86_64 64/75 Verifying : unzip-6.0-19.el7.x86_64 65/75 Verifying : mailx-12.5-19.el7.x86_64 66/75 Verifying : libXmu-1.1.2-2.el7.x86_64 67/75 Verifying : libtirpc-0.2.4-0.15.el7.x86_64 68/75 Verifying : 32:bind-libs-lite-9.9.4-61.el7_5.1.x86_64 69/75 Verifying : libgomp-4.8.5-28.el7_5.1.x86_64 70/75 Verifying : glibc-2.17-222.el7.x86_64 71/75 Verifying : 32:bind-license-9.9.4-61.el7_5.1.noarch 72/75 Verifying : libgcc-4.8.5-28.el7_5.1.x86_64 73/75 Verifying : glibc-common-2.17-222.el7.x86_64 74/75 Verifying : libstdc++-4.8.5-28.el7_5.1.x86_64 75/75Installed: oracle-rdbms-server-12cR1-preinstall.x86_64 0:1.0-7.el7Dependency Installed: bc.x86_64 0:1.06.95-13.el7 bind-libs.x86_64 32:9.9.4-72.el7 bind-utils.x86_64 32:9.9.4-72.el7 compat-libcap1.x86_64 0:1.10-7.el7 compat-libstdc++-33.x86_64 0:3.2.3-72.el7 cpp.x86_64 0:4.8.5-36.0.1.el7 gcc.x86_64 0:4.8.5-36.0.1.el7 gcc-c++.x86_64 0:4.8.5-36.0.1.el7 glibc-devel.x86_64 0:2.17-260.0.9.el7 glibc-headers.x86_64 0:2.17-260.0.9.el7 gssproxy.x86_64 0:0.7.0-21.el7 kernel-container.x86_64 0:3.10.0-0.0.0.2.el7 kernel-headers.x86_64 0:3.10.0-957.el7 keyutils.x86_64 0:1.5.8-3.el7 ksh.x86_64 0:20120801-139.0.1.el7 libICE.x86_64 0:1.0.9-9.el7 libSM.x86_64 0:1.2.2-2.el7 libX11.x86_64 0:1.6.5-2.el7 libX11-common.noarch 0:1.6.5-2.el7 libXau.x86_64 0:1.0.8-2.1.el7 libXext.x86_64 0:1.3.3-3.el7 libXi.x86_64 0:1.7.9-1.el7 libXinerama.x86_64 0:1.1.3-2.1.el7 libXmu.x86_64 0:1.1.2-2.el7 libXrandr.x86_64 0:1.5.1-2.el7 libXrender.x86_64 0:0.9.10-1.el7 libXt.x86_64 0:1.1.5-3.el7 libXtst.x86_64 0:1.2.3-1.el7 libXv.x86_64 0:1.0.11-1.el7 libXxf86dga.x86_64 0:1.1.4-2.1.el7 libXxf86misc.x86_64 0:1.0.3-7.1.el7 libXxf86vm.x86_64 0:1.1.4-1.el7 libaio-devel.x86_64 0:0.3.109-13.el7 libbasicobjects.x86_64 0:0.1.1-32.el7 libcollection.x86_64 0:0.7.0-32.el7 libdmx.x86_64 0:1.1.3-3.el7 libevent.x86_64 0:2.0.21-4.el7 libini_config.x86_64 0:1.3.1-32.el7 libmpc.x86_64 0:1.0.1-3.el7 libnfsidmap.x86_64 0:0.25-19.el7 libpath_utils.x86_64 0:0.2.1-32.el7 libref_array.x86_64 0:0.1.5-32.el7 libstdc++-devel.x86_64 0:4.8.5-36.0.1.el7 libtirpc.x86_64 0:0.2.4-0.15.el7 libverto-libevent.x86_64 0:0.2.5-4.el7 libxcb.x86_64 0:1.13-1.el7 lm_sensors-libs.x86_64 0:3.4.0-6.20160601gitf9185e5.el7 mailx.x86_64 0:12.5-19.el7 mpfr.x86_64 0:3.1.1-4.el7 nfs-utils.x86_64 1:1.3.0-0.61.0.1.el7 psmisc.x86_64 0:22.20-15.el7 quota.x86_64 1:4.01-17.el7 quota-nls.noarch 1:4.01-17.el7 rpcbind.x86_64 0:0.2.0-47.el7 smartmontools.x86_64 1:6.5-1.el7 sysstat.x86_64 0:10.1.5-17.el7 tcp_wrappers.x86_64 0:7.6-77.el7 unzip.x86_64 0:6.0-19.el7 xorg-x11-utils.x86_64 0:7.5-23.el7 xorg-x11-xauth.x86_64 1:1.0.9-1.el7Dependency Updated: bind-libs-lite.x86_64 32:9.9.4-72.el7 bind-license.noarch 32:9.9.4-72.el7 glibc.x86_64 0:2.17-260.0.9.el7 glibc-common.x86_64 0:2.17-260.0.9.el7 libgcc.x86_64 0:4.8.5-36.0.1.el7 libgomp.x86_64 0:4.8.5-36.0.1.el7 libstdc++.x86_64 0:4.8.5-36.0.1.el7Complete! 安装完之后，会自动创建 oracle 用户和 oinstall 用户组。现在最好给 oracle 用户设置一下密码：123456[root@localhost yum.repos.d]# passwd oracleChanging password for user oracle.New password:BAD PASSWORD: The password is shorter than 8 charactersRetype new password:passwd: all authentication tokens updated successfully. 前期准备修改 hostname修改默认主机名 localhost.localdomain 为 oem.com。若不修改，在后续安装 oracle 12c 的过程中，可能会出现 oracle net configuration failed，为了避免后续安装的复杂性，建议修改主机名。先修改/etc/hosts为以下内容：1234[root@localhost yum.repos.d]# vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.12.xxx oem oem.com 然后修改 /etc/sysconfig/network 为以下内容：12345[root@localhost yum.repos.d]# vi /etc/sysconfig/network# Created by anaconda# oracle-rdbms-server-12cR1-preinstall : Add NOZEROCONF=yesNOZEROCONF=yesHOSTNAME=oem.com 最后重启电脑，并检查 hostname 是否修改成功：12345678910111213[root@localhost yum.repos.d]# reboot[root@oem ~] hostnamectl Static hostname: localhost.localdomainTransient hostname: oem #看这里！！！表示修改成功！！！ Icon name: computer-vm Chassis: vm Machine ID: f8d5c3cadxxxxxxxx3faaee11e76d665 Boot ID: 9f4838b65fbe4dxxxxxxxxcb4ef8afad Virtualization: vmware Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-862.14.4.el7.x86_64 Architecture: x86-64 配置 SSH 和 X11 转发如果是在远程连接的情况下来安装 EM（比如使用VNC服务等），Oracle Universal Installer (OUI) GUI 需要使用X11会话来运行。所以首先需要配置SSH来支持X11转发（默认就是开启的，只需要确认一下即可）：123456[root@oem ~]# vi /etc/ssh/sshd_config#X11Forwarding noX11Forwarding yes#X11DisplayOffset 10#X11UseLocalhost yes[root@localhost ~]# 还需要安装 xauth 和 xorg-x11-apps 包：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140[root@oem ~]# rpm -qa | grep -i xauthxorg-x11-xauth-1.0.2-7.1.el6.x86_64[root@oem ~]# rpm -qa | grep -i xorg-x11-apps[root@oem ~]# yum -y install xorg-x11-apps xauthLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.njupt.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.njupt.edu.cnPackage 1:xorg-x11-xauth-1.0.9-1.el7.x86_64 already installed and latest versionResolving Dependencies--&gt; Running transaction check---&gt; Package xorg-x11-apps.x86_64 0:7.7-7.el7 will be installed--&gt; Processing Dependency: libpng15.so.15(PNG15_0)(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Processing Dependency: libxkbfile.so.1()(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Processing Dependency: libpng15.so.15()(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Processing Dependency: libfontenc.so.1()(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Processing Dependency: libfontconfig.so.1()(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Processing Dependency: libXft.so.2()(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Processing Dependency: libXcursor.so.1()(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Processing Dependency: libXaw.so.7()(64bit) for package: xorg-x11-apps-7.7-7.el7.x86_64--&gt; Running transaction check---&gt; Package fontconfig.x86_64 0:2.13.0-4.3.el7 will be installed--&gt; Processing Dependency: freetype &gt;= 2.8-7 for package: fontconfig-2.13.0-4.3.el7.x86_64--&gt; Processing Dependency: fontpackages-filesystem for package: fontconfig-2.13.0-4.3.el7.x86_64--&gt; Processing Dependency: dejavu-sans-fonts for package: fontconfig-2.13.0-4.3.el7.x86_64---&gt; Package libXaw.x86_64 0:1.0.13-4.el7 will be installed--&gt; Processing Dependency: libXpm.so.4()(64bit) for package: libXaw-1.0.13-4.el7.x86_64---&gt; Package libXcursor.x86_64 0:1.1.15-1.el7 will be installed--&gt; Processing Dependency: libXfixes.so.3()(64bit) for package: libXcursor-1.1.15-1.el7.x86_64---&gt; Package libXft.x86_64 0:2.3.2-2.el7 will be installed---&gt; Package libfontenc.x86_64 0:1.1.3-3.el7 will be installed---&gt; Package libpng.x86_64 2:1.5.13-7.el7_2 will be installed---&gt; Package libxkbfile.x86_64 0:1.0.9-3.el7 will be installed--&gt; Running transaction check---&gt; Package dejavu-sans-fonts.noarch 0:2.33-6.el7 will be installed--&gt; Processing Dependency: dejavu-fonts-common = 2.33-6.el7 for package: dejavu-sans-fonts-2.33-6.el7.noarch---&gt; Package fontpackages-filesystem.noarch 0:1.44-8.el7 will be installed---&gt; Package freetype.x86_64 0:2.4.11-15.el7 will be updated---&gt; Package freetype.x86_64 0:2.8-12.el7 will be an update---&gt; Package libXfixes.x86_64 0:5.0.3-1.el7 will be installed---&gt; Package libXpm.x86_64 0:3.5.12-1.el7 will be installed--&gt; Running transaction check---&gt; Package dejavu-fonts-common.noarch 0:2.33-6.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved================================================================================================================================================================================== Package Arch Version Repository Size==================================================================================================================================================================================Installing: xorg-x11-apps x86_64 7.7-7.el7 base 307 kInstalling for dependencies: dejavu-fonts-common noarch 2.33-6.el7 base 64 k dejavu-sans-fonts noarch 2.33-6.el7 base 1.4 M fontconfig x86_64 2.13.0-4.3.el7 ol7_latest 254 k fontpackages-filesystem noarch 1.44-8.el7 base 9.9 k libXaw x86_64 1.0.13-4.el7 base 192 k libXcursor x86_64 1.1.15-1.el7 ol7_latest 30 k libXfixes x86_64 5.0.3-1.el7 base 18 k libXft x86_64 2.3.2-2.el7 base 58 k libXpm x86_64 3.5.12-1.el7 base 55 k libfontenc x86_64 1.1.3-3.el7 base 31 k libpng x86_64 2:1.5.13-7.el7_2 base 213 k libxkbfile x86_64 1.0.9-3.el7 base 83 kUpdating for dependencies: freetype x86_64 2.8-12.el7 ol7_latest 379 kTransaction Summary==================================================================================================================================================================================Install 1 Package (+12 Dependent packages)Upgrade ( 1 Dependent package)Total download size: 3.1 MDownloading packages:Delta RPMs disabled because /usr/bin/applydeltarpm not installed.(1/14): dejavu-fonts-common-2.33-6.el7.noarch.rpm | 64 kB 00:00:00(2/14): libXaw-1.0.13-4.el7.x86_64.rpm | 192 kB 00:00:00(3/14): fontpackages-filesystem-1.44-8.el7.noarch.rpm | 9.9 kB 00:00:01(4/14): freetype-2.8-12.el7.x86_64.rpm | 379 kB 00:00:01(5/14): fontconfig-2.13.0-4.3.el7.x86_64.rpm | 254 kB 00:00:02(6/14): libXfixes-5.0.3-1.el7.x86_64.rpm | 18 kB 00:00:00(7/14): libXpm-3.5.12-1.el7.x86_64.rpm | 55 kB 00:00:00(8/14): libXft-2.3.2-2.el7.x86_64.rpm | 58 kB 00:00:00(9/14): libfontenc-1.1.3-3.el7.x86_64.rpm | 31 kB 00:00:00(10/14): libpng-1.5.13-7.el7_2.x86_64.rpm | 213 kB 00:00:00(11/14): libxkbfile-1.0.9-3.el7.x86_64.rpm | 83 kB 00:00:00(12/14): libXcursor-1.1.15-1.el7.x86_64.rpm | 30 kB 00:00:00(13/14): dejavu-sans-fonts-2.33-6.el7.noarch.rpm | 1.4 MB 00:00:03(14/14): xorg-x11-apps-7.7-7.el7.x86_64.rpm | 307 kB 00:00:00----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Total 965 kB/s | 3.1 MB 00:00:03Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : fontpackages-filesystem-1.44-8.el7.noarch 1/15 Installing : 2:libpng-1.5.13-7.el7_2.x86_64 2/15 Updating : freetype-2.8-12.el7.x86_64 3/15 Installing : dejavu-fonts-common-2.33-6.el7.noarch 4/15 Installing : dejavu-sans-fonts-2.33-6.el7.noarch 5/15 Installing : fontconfig-2.13.0-4.3.el7.x86_64 6/15 Installing : libXft-2.3.2-2.el7.x86_64 7/15 Installing : libfontenc-1.1.3-3.el7.x86_64 8/15 Installing : libXfixes-5.0.3-1.el7.x86_64 9/15 Installing : libXcursor-1.1.15-1.el7.x86_64 10/15 Installing : libxkbfile-1.0.9-3.el7.x86_64 11/15 Installing : libXpm-3.5.12-1.el7.x86_64 12/15 Installing : libXaw-1.0.13-4.el7.x86_64 13/15 Installing : xorg-x11-apps-7.7-7.el7.x86_64 14/15 Cleanup : freetype-2.4.11-15.el7.x86_64 15/15 Verifying : libXpm-3.5.12-1.el7.x86_64 1/15 Verifying : fontconfig-2.13.0-4.3.el7.x86_64 2/15 Verifying : libxkbfile-1.0.9-3.el7.x86_64 3/15 Verifying : libXaw-1.0.13-4.el7.x86_64 4/15 Verifying : libXfixes-5.0.3-1.el7.x86_64 5/15 Verifying : dejavu-fonts-common-2.33-6.el7.noarch 6/15 Verifying : dejavu-sans-fonts-2.33-6.el7.noarch 7/15 Verifying : libXcursor-1.1.15-1.el7.x86_64 8/15 Verifying : 2:libpng-1.5.13-7.el7_2.x86_64 9/15 Verifying : libXft-2.3.2-2.el7.x86_64 10/15 Verifying : libfontenc-1.1.3-3.el7.x86_64 11/15 Verifying : freetype-2.8-12.el7.x86_64 12/15 Verifying : fontpackages-filesystem-1.44-8.el7.noarch 13/15 Verifying : xorg-x11-apps-7.7-7.el7.x86_64 14/15 Verifying : freetype-2.4.11-15.el7.x86_64 15/15Installed: xorg-x11-apps.x86_64 0:7.7-7.el7Dependency Installed: dejavu-fonts-common.noarch 0:2.33-6.el7 dejavu-sans-fonts.noarch 0:2.33-6.el7 fontconfig.x86_64 0:2.13.0-4.3.el7 fontpackages-filesystem.noarch 0:1.44-8.el7 libXaw.x86_64 0:1.0.13-4.el7 libXcursor.x86_64 0:1.1.15-1.el7 libXfixes.x86_64 0:5.0.3-1.el7 libXft.x86_64 0:2.3.2-2.el7 libXpm.x86_64 0:3.5.12-1.el7 libfontenc.x86_64 0:1.1.3-3.el7 libpng.x86_64 2:1.5.13-7.el7_2 libxkbfile.x86_64 0:1.0.9-3.el7Dependency Updated: freetype.x86_64 0:2.8-12.el7Complete! 为保险起见，此时最好重启系统。 安装 Oracle 12c本章开始在 Centos7 上安装 Oracle Database 12c Release 1（12.1.0.2.0） 创建目录和部署安装文件Oracle 12c 可以从这里下载到。 以 root 用户创建保存安装文件的目录：12[root@oem ~]# mkdir -p /u01/stage[root@oem ~]# chown -R oracle:oinstall /u01/* 切换回 oracle 用户，创建目录：1[oracle@oem ~]$ mkdir /u01/stage/db12c 将下载好的数据库安装文件拷贝到 /u01/stage/db12c 目录，并解压：123456789101112[oracle@oem ~]$ cd /u01/stage/db12c/[oracle@oem db12c]$ lltotal 2625080-rw-r--r--. 1 oracle oinstall 1673544724 Nov 12 15:38 linuxamd64_12102_database_1of2.zip-rw-r--r--. 1 oracle oinstall 1014530602 Nov 12 15:38 linuxamd64_12102_database_2of2.zip[oracle@localhost db12c]$ unzip linuxamd64_12102_database_1of2.zip[oracle@localhost db12c]$ unzip linuxamd64_12102_database_2of2.zip[oracle@localhost db12c]$ lltotal 2625080drwxr-xr-x. 7 oracle oinstall 117 Jul 7 2014 database-rw-r--r--. 1 oracle oinstall 1673544724 Nov 12 15:38 linuxamd64_12102_database_1of2.zip-rw-r--r--. 1 oracle oinstall 1014530602 Nov 12 15:38 linuxamd64_12102_database_2of2.zip 创建安装用目录（按照OFA标准）Optimal Flexible Architecture (OFA) 标准是为管理Oracle安装而定义的一套目录推荐命名标准。OFA提供了与Oracle Universal Installer相一致的挂载点，目录，文件名的命名规范。 以root用户执行以下命令来创建所需的各个目录：123[root@oem ~]# mkdir -p /u01/app/oracle/product/12.1.0/dbhome_1[root@oem ~]# chown -R oracle:oinstall /u01/*[root@oem ~]# chmod -R 775 /u01/* 注意： /u01这个目录的拥有者应该是 root。 修改 ulimit 值：最大文件描述符数为4096安装完 oracle-rdbms-server-12cR1-preinstall 之后，会在 /etc/security/limits.d 自动生成配置文件 oracle-rdbms-server-12cR1-preinstall.conf。以root用户修改里面的值如下：1234[root@oem zodas]# cd /etc/security/limits.d[root@oem limits.d]# vi oracle-rdbms-server-12cR1-preinstall.conf #oracle soft nofile 1024oracle soft nofile 4096 修改完之后，切换到oracle用户，查看ulimit值是否生效：1234[root@oem limits.d]# su - oracle[oracle@oem ~]$ ulimit -n4096[oracle@oem ~]$ 修改 ulimit 值：最大用户进程数为16384安装完 oracle-rdbms-server-12cR1-preinstall之后，会在/etc/security/limits.d自动生成配置文件20-nproc.conf。以root用户修改里面的值如下：123456789[root@oem oracle]# cd /etc/security/limits.d[root@oem limits.d]# vi 20-nproc.conf# Default limit for number of user's processes to prevent# accidental fork bombs.# See rhbz #432903 for reasoning.#* soft nproc 4096* - nproc 16384root soft nproc unlimited 切换为 oracle 用户，查看修改结果：1234567891011121314151617[oracle@oem ~]$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7191max locked memory (kbytes, -l) 134217728max memory size (kbytes, -m) unlimitedopen files (-n) 4096 ##看这里！！！pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 10240cpu time (seconds, -t) unlimitedmax user processes (-u) 16384 ##看这里！！！virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 增大 tmpfs 到4GB默认的 tmpfs 的值过小，Oracle数据库启动时可能会报错（ORA-00838，ORA-00845）。为了防止这种错误，先增大 tmpfs 的值到4GB。123456789101112131415161718192021[root@oem zodas]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 35G 9.2G 26G 27% /devtmpfs 1.9G 0 1.9G 0% /devtmpfs 1.9G 0 1.9G 0% /dev/shmtmpfs 1.9G 12M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/sda2 1014M 184M 831M 19% /boot/dev/mapper/centos-home 30G 33M 30G 1% /hometmpfs 378M 0 378M 0% /run/user/1000[root@oem oracle]# mount -t tmpfs shmfs -o size=4000m /dev/shm[root@oem oracle]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 35G 9.2G 26G 27% /devtmpfs 1.9G 0 1.9G 0% /devshmfs 4.0G 0 4.0G 0% /dev/shmtmpfs 1.9G 12M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/sda2 1014M 184M 831M 19% /boot/dev/mapper/centos-home 30G 33M 30G 1% /hometmpfs 378M 0 378M 0% /run/user/1000 同时修改 /etc/fstab 文件，使配置永久生效：123456789101112[root@oem zodas]# vi /etc/fstab## /etc/fstab# Created by anaconda on Mon Nov 12 00:31:16 2018## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/centos-root / xfs defaults 0 0UUID=9ffb8583-88fa-4fbe-8cb5-9c21c8fbfa9c /boot xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0tmpfs /dev/shm tmpfs size=4000m 0 0 ##看这里！！！ 重启系统后，应该能看到如下的内容：12345678910[zodas@oem ~]$ df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 35G 9.3G 26G 27% /devtmpfs 1.9G 0 1.9G 0% /devtmpfs 4.0G 0 4.0G 0% /dev/shmtmpfs 1.9G 12M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/mapper/centos-home 30G 33M 30G 1% /home/dev/sda2 1014M 172M 843M 17% /boottmpfs 378M 0 378M 0% /run/user/1000 若 swap space &lt; 4G，则需要扩充 swap space使用如下命令查看 swap space: 123[root@oem ~]# swapon -sFilename Type Size Used Priority/dev/dm-1 partition 2097148 0 -1 执行以下命令，增加 swap space12345678910111213[root@oem ~]# dd if=/dev/zero of=/swapfile bs=1M count=40964096+0 records in4096+0 records out4294967296 bytes (4.3 GB) copied, 25.9202 s, 166 MB/s[root@oem ~]# mkswap /swapfileSetting up swapspace version 1, size = 4194300 KiBno label, UUID=fcdf3cfe-9352-4d77-b4dc-3517b41cb18a[root@localhost ~]# swapon /swapfileswapon: /swapfile: insecure permissions 0644, 0600 suggested.[root@localhost db12c]# swapon -sFilename Type Size Used Priority/dev/dm-1 partition 2097148 0 -1/swapfile file 4194300 0 -2 配置环境变量 /home/oracle/.bashrc以 oracle 用户，在 ~/.bashrc 的末尾加入如下配置内容：1234567891011# Oracle variablesORACLE_HOSTNAME=oem.com; export ORACLE_HOSTNAMEORACLE_BASE=/u01/app/oracle; export ORACLE_BASEORACLE_HOME=$ORACLE_BASE/product/12.1.0/dbhome_1; export ORACLE_HOMEAGENT_HOME=$ORACLE_BASE/product/agentr4/agent_inst; export AGENT_HOMEOMS_HOME=$ORACLE_BASE/product/MiddlewareR4/oms; export OMS_HOMEORACLE_INSTANCE=/u01/app/oracle/product/gc_inst/WebTierIH1; export ORACLE_INSTANCEORACLE_SID=omr; export ORACLE_SIDORACLE_UNQNAME=omr; export ORACLE_UNQNAMEPATH=$ORACLE_HOME/bin:$PATH; export PATHLD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib; export LD_LIBRARY_PATH 并使之生效：1[oracle@oem ~]$ source .bashrc 开始安装 oracle 数据库打开一个新的终端，远程连接服务器GUI界面安装 oracle：1234567891011[mac]ssh -Y oracle@192.168.12.xxxoracle@192.168.12.xxx's password:Last login: Mon Nov 12 16:30:05 2018/usr/bin/xauth: file /home/oracle/.Xauthority does not exist[oracle@oem ~]$ /u01/stage/db12c/database/runInstallerStarting Oracle Universal Installer...Checking Temp space: must be greater than 500 MB. Actual 5597 MB PassedChecking swap space: must be greater than 150 MB. Actual 2047 MB PassedChecking monitor: must be configured to display at least 256 colors. Actual 16777216 PassedPreparing to launch Oracle Universal Installer from /tmp/OraInstall2018-11-12_04-35-35PM. Please wait ...[oracle@localhost database]$ 在运行 runInstaller 时，可能会出现 Checking monitor: must be configured to display at least 256 colors. Failed。对于 macOS，安装 xquartz方可解决；或者让服务器(你所要安装 oracle 的那台机器）以图形化模式运行而不是命令行模式，然后直接在服务器上（而不是ssh 远程连接服务器的行驶）执行/u01/stage/db12c/database/runInstaller即可。 打开 mac 的 terminal，用 homebrew 安装 xquartz：1[mac]$ brew cask install xquartz 说明： 参考我的另一篇博文，了解 homebrew 的安装与使用 参考此文，了解如何能在 macos 上显示 x11 apps 参考此文，了解什么是 X Window System及其工作原理 Configure Security Updates不选择 I wish to receive security updates via My Oracle Support，点击Next。 Select Installation Option勾选 Create and configure a database，点击 Next。 Server Class勾选 Server Class，点击 Next。 Grid Installation Options勾选 Single instance database installation，点击Next。 Select Install Type勾选 Advanced install，点击 Nex。 Select Product Languages如果要支持多语言的话，勾选对应的语言，本文加入了 Simplified Chinese 支持，点击 Next。 Select Database Edition保持默认选择（Enterprise Edition (6.4GB)），直接点击 Next。 Specify Installation Location保持默认选择: Oracle base: /u01/app/oracle Software location: /u01/app/oracle/product/12.1.0/dbhome_1直接点击 Next。 Create Inventory保持默认选择: Inventory Directory: /u01/app/oraInventory oraInventory Group Name: oinstall直接点击 Next。 Select Configuration Type保持默认选择（General Purpose / Transaction Processing），直接点击 Next。 Specify Database Identifiers设置： Global database name: omr.com Oracle system identifier (SID): omr同时一定不要勾选 Create as Container database。点击 Next。 Specify Configuration Options由于是测试环境的内存容量有限，所以将内存先设置为 1024。 字符集选择可以支持任何语言的Use Unicode (AL32UTF8)。点击 Next Specify Database Storage Options保持默认选择（File System）。点击 Next。 Specify Management Options保持默认选择（先不注册到EM中）。点击 Next。 Specify Recovery Options保持默认选择（先不启用数据库恢复）。点击 Next Specify Schema Passwords选择 Use the same password for all accounts，并设置密码，点击 Next。 Specify Operating System groups全部都选择 dba，点击 Next。 Summary最后检查一遍配置，没有问题的话，点击 Install。 Install Product开始漫长的安装过程，请耐心等待。。。 Execute Configuration scripts这时需要以root用户执行两个脚本：打开一个终端，切换到root用户，执行以下命令：123456789101112131415161718192021222324252627[oracle@oem ~]$ su -Password: [root@oem zodas]# /u01/app/oraInventory/orainstRoot.shChanging permissions of /u01/app/oraInventory.Adding read,write permissions for group.Removing read,write,execute permissions for world.Changing groupname of /u01/app/oraInventory to oinstall.The execution of the script is complete.[root@oem zodas]# /u01/app/oracle/product/12.1.0/dbhome_1/root.shPerforming root user operation.The following environment variables are set as: ORACLE_OWNER= oracle ORACLE_HOME= /u01/app/oracle/product/12.1.0/dbhome_1Enter the full pathname of the local bin directory: [/usr/local/bin]: Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ...Creating /etc/oratab file...Entries will be added to the /etc/oratab file as needed byDatabase Configuration Assistant when a database is createdFinished running generic part of root script.Now product-specific root actions will be performed. 可能出现的问题若完全按照本文一步一步操作，一般来说是不会有问题的。如果，在前期准备时，没有修改 hostname，只是简单的修改了 /etc/hosts文件，如按照该文，执行完脚本后，可能会出现 Oracle Net Configuration Assistant failed: 先选择 Skip，以让安装能够继续进行（后续如果修复这个问题，请参考我的另一篇博文“@解决 Oracle Net Configuration Assistant Failed 问题”），安装完成后，得到的结果如下图： Database Configuration Assistant看到下面的画面时，说明数据库已经安装完成。 Finish这时可以关闭安装向导。 顺便说一下，此时如果想删除数据库的话，可以执行$ORACLE_HOME/deinstall/deinstall脚本，简单一个命令就可以搞定了。 数据库安装后设置数据库参数修改和监听服务查看以root用户修改/etc/oratab文件，将restart标志位设置为Y:123456789101112131415161718192021[root@oem zodas]# vi /etc/oratab# This file is used by ORACLE utilities. It is created by root.sh# and updated by either Database Configuration Assistant while creating# a database or ASM Configuration Assistant while creating ASM instance.# A colon, ':', is used as the field terminator. A new line terminates# the entry. Lines beginning with a pound sign, '#', are comments.## Entries are of the form:# $ORACLE_SID:$ORACLE_HOME:&lt;N|Y&gt;:## The first and second fields are the system identifier and home# directory of the database respectively. The third field indicates# to the dbstart utility that the database should , "Y", or should not,# "N", be brought up at system boot time.## Multiple entries with the same $ORACLE_SID are not allowed.###omr:/u01/app/oracle/product/12.1.0/dbhome_1:Nomr:/u01/app/oracle/product/12.1.0/dbhome_1:Y 以oracle用户，创建Oracle数据库的redo日志文件夹：1[oracle@oem ~]$ mkdir /u01/app/oracle/product/redo_logs/ 接着，登录到数据库中，先从spfile创建一个pfile：1234567891011121314[oracle@oem ~]$ sqlplus / as sysdbaSQL*Plus: Release 12.1.0.2.0 Production on Tue Nov 13 01:22:41 2018Copyright (c) 1982, 2014, Oracle. All rights reserved.Connected to:Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit ProductionWith the Partitioning, OLAP, Advanced Analytics and Real Application Testing optionsSQL&gt; create pfile from spfile;File created. 然后，修改数据库参数并创建redo文件：1234567891011121314151617181920212223SQL&gt; ALTER SYSTEM SET processes=300 SCOPE=SPFILE;System altered.SQL&gt; ALTER SYSTEM SET session_cached_cursors=200 SCOPE=SPFILE;System altered.SQL&gt; ALTER SYSTEM SET db_securefile=PERMITTED SCOPE=BOTH;System altered.SQL&gt; ALTER DATABASE ADD LOGFILE GROUP 4 ('/u01/app/oracle/product/redo_logs/log1a.rdo') SIZE 300M REUSE;Database altered.SQL&gt; ALTER DATABASE ADD LOGFILE GROUP 5 ('/u01/app/oracle/product/redo_logs/log2a.rdo') SIZE 300M REUSE;Database altered.SQL&gt; ALTER DATABASE ADD LOGFILE GROUP 6 ('/u01/app/oracle/product/redo_logs/log3a.rdo') SIZE 300M REUSE;Database altered. 重启数据库，使配置生效：1234567891011121314SQL&gt; SHUTDOWN IMMEDIATE;Database closed.Database dismounted.ORACLE instance shut down.SQL&gt; STARTUP;ORACLE instance started.Total System Global Area 1073741824 bytesFixed Size 2932632 bytesVariable Size 713031784 bytesDatabase Buffers 352321536 bytesRedo Buffers 5455872 bytesDatabase mounted.Database opened. 确认一下HTTPS的端口是否是5500，并退出sqlplus：12345678SQL&gt; SELECT dbms_xdb_config.gethttpsport FROM dual;GETHTTPSPORT------------ 5500SQL&gt; EXITDisconnected from Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit ProductionWith the Partitioning, OLAP, Advanced Analytics and Real Application Testing options 最后确认LISTNER的状态，看看监听服务是否正常：12345678910111213141516171819202122232425262728[oracle@oem ~]$ lsnrctl statusLSNRCTL for Linux: Version 12.1.0.2.0 - Production on 13-NOV-2018 04:54:19Copyright (c) 1991, 2014, Oracle. All rights reserved.Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oem.com)(PORT=1521)))STATUS of the LISTENER------------------------Alias LISTENERVersion TNSLSNR for Linux: Version 12.1.0.2.0 - ProductionStart Date 13-NOV-2018 04:26:03Uptime 0 days 0 hr. 28 min. 16 secTrace Level offSecurity ON: Local OS AuthenticationSNMP OFFListener Parameter File /u01/app/oracle/product/12.1.0/dbhome_1/network/admin/listener.oraListener Log File /u01/app/oracle/diag/tnslsnr/oem/listener/alert/log.xmlListening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=oem)(PORT=1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcps)(HOST=oem)(PORT=5500))(Security=(my_wallet_directory=/u01/app/oracle/admin/omr/xdb_wallet))(Presentation=HTTP)(Session=RAW))Services Summary...Service "omr.com" has 1 instance(s). Instance "omr", status READY, has 1 handler(s) for this service...Service "omrXDB.com" has 1 instance(s). Instance "omr", status READY, has 1 handler(s) for this service...The command completed successfully 可以看到数据库服务omr.example.com已经就绪。 开机自动启动数据库（可选）其实到上一步骤为止，Oracle的数据库安装已经完成。如果还需要在开机时自动启动数据服务的话，可以按照下面的步骤实现。 首先以root用户创建一个自启动脚本：123456789101112131415161718192021222324252627282930313233[root@oem ~]# vim /etc/init.d/dbora#!/bin/sh# chkconfig: 345 99 10# description: Oracle auto start-stop script.## Set ORA_HOME to be equivalent to the $ORACLE_HOME# from which you wish to execute dbstart and dbshut;## Set ORA_OWNER to the user id of the owner of the# Oracle database in ORA_HOME.ORA_HOME=/u01/app/oracle/product/12.1.0/dbhome_1ORA_OWNER=oracleif [ ! -f $&#123;ORA_HOME&#125;/bin/dbstart ]then echo "Oracle startup: cannot start" exitficase "$1" in'start') # Start the Oracle databases: # The following command assumes that the oracle login # will not prompt the user for any values su - $&#123;ORA_OWNER&#125; -c "$&#123;ORA_HOME&#125;/bin/dbstart $ORA_HOME" touch /var/lock/subsys/dbora ;;'stop') # Stop the Oracle databases: # The following command assumes that the oracle login # will not prompt the user for any values su - $&#123;ORA_OWNER&#125; -c "$&#123;ORA_HOME&#125;/bin/dbshut $ORA_HOME" rm -f /var/lock/subsys/dbora ;;esac 以root用户修改脚本权限，并加入到开机启动服务列表中：1234[root@oem ~]# chmod 750 /etc/init.d/dbora [root@oem ~]# chkconfig dbora on[root@oem ~]# chkconfig --list|grep dboradbora 0:off 1:off 2:on 3:on 4:on 5:on 6:off 最后，以root用户创建一些软链接，将自启动脚本加入到Oracle Linux 的启动进程中：123[root@oem ~]# ln -s /etc/init.d/dbora /etc/rc.d/rc0.d/K01dbora[root@oem ~]# ln -s /etc/init.d/dbora /etc/rc.d/rc3.d/S96dbora[root@oem ~]# ln -s /etc/init.d/dbora /etc/rc.d/rc5.d/S96dbora 这时可以重启一下系统，验证一下数据库服务有没有随系统自动启动。 安装Oracle Enterprise Manager 12c R4本章开始利用Oracle Universal Installer (OUI)在 centos 7上安装如下组件： Oracle Enterprise Manager 12c Release 4 (12.1.0.4) Oracle Management Service Oracle Management Agent安装文件可以从这里下载到。 安装前检查以root用户先查看一下必须的软件包是否已经安装完成：123456789101112131415161718192021222324[oracle@oem ~]$ yum list make binutils gcc libaio glib-common libstdc++ libXtst systat glibc-devel glibc libaio glibc-devel.i686Loaded plugins: fastestmirrorDetermining fastest mirrors * base: ftp.sjtu.edu.cn * extras: ftp.sjtu.edu.cn * updates: ftp.sjtu.edu.cnol7_UEKR4 124/124ol7_latest 11482/11482Installed Packagesbinutils.x86_64 2.27-28.base.el7_5.1 @updatesgcc.x86_64 4.8.5-36.0.1.el7 @ol7_latestglibc.x86_64 2.17-260.0.9.el7 @ol7_latestglibc-devel.x86_64 2.17-260.0.9.el7 @ol7_latestlibXtst.x86_64 1.2.3-1.el7 @baselibaio.x86_64 0.3.109-13.el7 @anacondalibstdc++.x86_64 4.8.5-36.0.1.el7 @ol7_latestmake.x86_64 1:3.82-23.el7 @anacondaAvailable Packagesbinutils.x86_64 2.27-34.base.0.1.el7 ol7_latestglibc.i686 2.17-260.0.9.el7 ol7_latestglibc-devel.i686 2.17-260.0.9.el7 ol7_latestlibXtst.i686 1.2.3-1.el7 baselibaio.i686 0.3.109-13.el7 baselibstdc++.i686 4.8.5-36.0.1.el7 ol7_latest 安装上面 Available Packages 中列出的所有必须软件包：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150[root@oem oracle]# yum install binutils.x86_64 glibc.i686 glibc-devel.i686 libXtst.i686 libaio.i686 libstdc++.i686Loaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.njupt.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.njupt.edu.cnbase | 3.6 kB 00:00:00extras | 3.4 kB 00:00:00ol7_UEKR4 | 1.2 kB 00:00:00ol7_latest | 1.4 kB 00:00:00updates | 3.4 kB 00:00:00Resolving Dependencies--&gt; Running transaction check---&gt; Package binutils.x86_64 0:2.27-28.base.el7_5.1 will be updated---&gt; Package binutils.x86_64 0:2.27-34.base.0.1.el7 will be an update---&gt; Package glibc.i686 0:2.17-260.0.9.el7 will be installed--&gt; Processing Dependency: libfreebl3.so for package: glibc-2.17-260.0.9.el7.i686--&gt; Processing Dependency: libfreebl3.so(NSSRAWHASH_3.12.3) for package: glibc-2.17-260.0.9.el7.i686---&gt; Package glibc-devel.i686 0:2.17-260.0.9.el7 will be installed---&gt; Package libXtst.i686 0:1.2.3-1.el7 will be installed--&gt; Processing Dependency: libXi.so.6 for package: libXtst-1.2.3-1.el7.i686--&gt; Processing Dependency: libXext.so.6 for package: libXtst-1.2.3-1.el7.i686--&gt; Processing Dependency: libX11.so.6 for package: libXtst-1.2.3-1.el7.i686---&gt; Package libaio.i686 0:0.3.109-13.el7 will be installed---&gt; Package libstdc++.i686 0:4.8.5-36.0.1.el7 will be installed--&gt; Processing Dependency: libgcc_s.so.1(GCC_3.3) for package: libstdc++-4.8.5-36.0.1.el7.i686--&gt; Processing Dependency: libgcc_s.so.1(GCC_3.0) for package: libstdc++-4.8.5-36.0.1.el7.i686--&gt; Processing Dependency: libgcc_s.so.1(GCC_4.2.0) for package: libstdc++-4.8.5-36.0.1.el7.i686--&gt; Processing Dependency: libgcc_s.so.1 for package: libstdc++-4.8.5-36.0.1.el7.i686--&gt; Processing Dependency: libgcc_s.so.1(GLIBC_2.0) for package: libstdc++-4.8.5-36.0.1.el7.i686--&gt; Running transaction check---&gt; Package libX11.i686 0:1.6.5-2.el7 will be installed--&gt; Processing Dependency: libxcb.so.1 for package: libX11-1.6.5-2.el7.i686---&gt; Package libXext.i686 0:1.3.3-3.el7 will be installed---&gt; Package libXi.i686 0:1.7.9-1.el7 will be installed---&gt; Package libgcc.i686 0:4.8.5-36.0.1.el7 will be installed---&gt; Package nss-softokn-freebl.x86_64 0:3.36.0-5.el7_5 will be updated---&gt; Package nss-softokn-freebl.i686 0:3.36.0-5.0.1.el7_5 will be installed---&gt; Package nss-softokn-freebl.x86_64 0:3.36.0-5.0.1.el7_5 will be an update--&gt; Running transaction check---&gt; Package libxcb.i686 0:1.13-1.el7 will be installed--&gt; Processing Dependency: libXau.so.6 for package: libxcb-1.13-1.el7.i686--&gt; Running transaction check---&gt; Package libXau.i686 0:1.0.8-2.1.el7 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved======================================================================================== Package Arch Version Repository Size========================================================================================Installing: glibc i686 2.17-260.0.9.el7 ol7_latest 4.3 M glibc-devel i686 2.17-260.0.9.el7 ol7_latest 1.1 M libXtst i686 1.2.3-1.el7 base 20 k libaio i686 0.3.109-13.el7 base 24 k libstdc++ i686 4.8.5-36.0.1.el7 ol7_latest 317 kUpdating: binutils x86_64 2.27-34.base.0.1.el7 ol7_latest 5.9 MInstalling for dependencies: libX11 i686 1.6.5-2.el7 ol7_latest 610 k libXau i686 1.0.8-2.1.el7 base 29 k libXext i686 1.3.3-3.el7 base 39 k libXi i686 1.7.9-1.el7 base 40 k libgcc i686 4.8.5-36.0.1.el7 ol7_latest 109 k libxcb i686 1.13-1.el7 ol7_latest 229 k nss-softokn-freebl i686 3.36.0-5.0.1.el7_5 ol7_latest 212 kUpdating for dependencies: nss-softokn-freebl x86_64 3.36.0-5.0.1.el7_5 ol7_latest 222 kTransaction Summary========================================================================================Install 5 Packages (+7 Dependent packages)Upgrade 1 Package (+1 Dependent package)Total download size: 13 MIs this ok [y/d/N]: yDownloading packages:Delta RPMs disabled because /usr/bin/applydeltarpm not installed.(1/14): glibc-2.17-260.0.9.el7.i686.rpm | 4.3 MB 00:00:02(2/14): glibc-devel-2.17-260.0.9.el7.i686.rpm | 1.1 MB 00:00:00(3/14): binutils-2.27-34.base.0.1.el7.x86_64.rpm | 5.9 MB 00:00:03(4/14): libX11-1.6.5-2.el7.i686.rpm | 610 kB 00:00:00(5/14): libXau-1.0.8-2.1.el7.i686.rpm | 29 kB 00:00:00(6/14): libgcc-4.8.5-36.0.1.el7.i686.rpm | 109 kB 00:00:00(7/14): libXi-1.7.9-1.el7.i686.rpm | 40 kB 00:00:00(8/14): libstdc++-4.8.5-36.0.1.el7.i686.rpm | 317 kB 00:00:00(9/14): libXext-1.3.3-3.el7.i686.rpm | 39 kB 00:00:00(10/14): nss-softokn-freebl-3.36.0-5.0.1.el7_5.i686.rpm | 212 kB 00:00:00(11/14): nss-softokn-freebl-3.36.0-5.0.1.el7_5.x86_64.rpm | 222 kB 00:00:00(12/14): libxcb-1.13-1.el7.i686.rpm | 229 kB 00:00:00(13/14): libXtst-1.2.3-1.el7.i686.rpm | 20 kB 00:00:02(14/14): libaio-0.3.109-13.el7.i686.rpm | 24 kB 00:00:02----------------------------------------------------------------------------------------Total 2.0 MB/s | 13 MB 00:06Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : libgcc-4.8.5-36.0.1.el7.i686 1/16 Installing : nss-softokn-freebl-3.36.0-5.0.1.el7_5.i686 2/16 Installing : glibc-2.17-260.0.9.el7.i686 3/16 Updating : nss-softokn-freebl-3.36.0-5.0.1.el7_5.x86_64 4/16 Updating : binutils-2.27-34.base.0.1.el7.x86_64 5/16 Installing : glibc-devel-2.17-260.0.9.el7.i686 6/16 Installing : libXau-1.0.8-2.1.el7.i686 7/16 Installing : libxcb-1.13-1.el7.i686 8/16 Installing : libX11-1.6.5-2.el7.i686 9/16 Installing : libXext-1.3.3-3.el7.i686 10/16 Installing : libXi-1.7.9-1.el7.i686 11/16 Installing : libXtst-1.2.3-1.el7.i686 12/16 Installing : libstdc++-4.8.5-36.0.1.el7.i686 13/16 Installing : libaio-0.3.109-13.el7.i686 14/16 Cleanup : binutils-2.27-28.base.el7_5.1.x86_64 15/16 Cleanup : nss-softokn-freebl-3.36.0-5.el7_5.x86_64 16/16 Verifying : libXtst-1.2.3-1.el7.i686 1/16 Verifying : libXext-1.3.3-3.el7.i686 2/16 Verifying : libstdc++-4.8.5-36.0.1.el7.i686 3/16 Verifying : libgcc-4.8.5-36.0.1.el7.i686 4/16 Verifying : libXi-1.7.9-1.el7.i686 5/16 Verifying : libxcb-1.13-1.el7.i686 6/16 Verifying : nss-softokn-freebl-3.36.0-5.0.1.el7_5.x86_64 7/16 Verifying : libXau-1.0.8-2.1.el7.i686 8/16 Verifying : libaio-0.3.109-13.el7.i686 9/16 Verifying : binutils-2.27-34.base.0.1.el7.x86_64 10/16 Verifying : glibc-devel-2.17-260.0.9.el7.i686 11/16 Verifying : glibc-2.17-260.0.9.el7.i686 12/16 Verifying : libX11-1.6.5-2.el7.i686 13/16 Verifying : nss-softokn-freebl-3.36.0-5.0.1.el7_5.i686 14/16 Verifying : nss-softokn-freebl-3.36.0-5.el7_5.x86_64 15/16 Verifying : binutils-2.27-28.base.el7_5.1.x86_64 16/16Installed: glibc.i686 0:2.17-260.0.9.el7 glibc-devel.i686 0:2.17-260.0.9.el7 libXtst.i686 0:1.2.3-1.el7 libaio.i686 0:0.3.109-13.el7 libstdc++.i686 0:4.8.5-36.0.1.el7Dependency Installed: libX11.i686 0:1.6.5-2.el7 libXau.i686 0:1.0.8-2.1.el7 libXext.i686 0:1.3.3-3.el7 libXi.i686 0:1.7.9-1.el7 libgcc.i686 0:4.8.5-36.0.1.el7 libxcb.i686 0:1.13-1.el7 nss-softokn-freebl.i686 0:3.36.0-5.0.1.el7_5Updated: binutils.x86_64 0:2.27-34.base.0.1.el7Dependency Updated: nss-softokn-freebl.x86_64 0:3.36.0-5.0.1.el7_5Complete! 创建目录和部署安装文件以oracle用户，创建EM安装文件保存目录，并将安装文件拷贝到该目录中：12345678[oracle@oem ~]$ mkdir -p /u01/stage/em12104[oracle@oem ~]$ cd /u01/stage/em12104/[oracle@oem em12104]$ ll[oracle@oem em12104]$ lltotal 6640888-rw-r--r--. 1 oracle oinstall 2195693096 Nov 13 11:32 em12104_linux64_disk1.zip-rw-r--r--. 1 oracle oinstall 1877449643 Nov 13 11:33 em12104_linux64_disk2.zip-rw-r--r--. 1 oracle oinstall 2727123784 Nov 13 11:33 em12104_linux64_disk3.zip 依次解压缩安装文件：1234567891011121314151617[oracle@oem em12104]$ unzip em12104_linux64_disk1.zip [oracle@oem em12104]$ unzip em12104_linux64_disk2.zip [oracle@oem em12104]$ unzip em12104_linux64_disk3.zip [oracle@oem em12104]$ lltotal 1494528drwxr-xr-x. 4 oracle oinstall 58 Jan 15 2014 bipruntimedrwxr-xr-x. 7 oracle oinstall 4096 May 24 2014 installdrwxr-xr-x. 4 oracle oinstall 39 May 24 2014 jdkdrwxrwxr-x. 4 oracle oinstall 30 May 24 2014 libskgxndrwxr-xr-x. 4 oracle oinstall 39 May 24 2014 omsdrwxr-xr-x. 2 oracle oinstall 4096 Nov 13 11:36 plugins-rw-r--r--. 1 oracle oinstall 42623 May 26 2014 release_notes.pdfdrwxrwxr-x. 2 oracle oinstall 96 May 24 2014 response-rwxr-xr-x. 1 oracle oinstall 5375 Dec 26 2013 runInstallerdrwxr-xr-x. 9 oracle oinstall 232 May 24 2014 stagedrwxrwxr-x. 2 oracle oinstall 33 Nov 13 11:36 wls-rwxr-xr-x. 1 oracle oinstall 1530333315 May 24 2014 WT.zip 以oracle用户创建oms和agent的安装目录:12345678[oracle@oem em12104]$ mkdir -p /u01/app/oracle/product/MiddlewareR4[oracle@oem em12104]$ mkdir -p /u01/app/oracle/product/agentr4Starting Oracle Universal Installer...Checking Temp space: must be greater than 400 MB. Actual 4963 MB PassedChecking swap space: must be greater than 150 MB. Actual 4064 MB PassedChecking monitor: must be configured to display at least 256 colors. Actual 16777216 PassedPreparing to launch Oracle Universal Installer from /tmp/OraInstall2018-11-13_11-39-20AM. Please wait ... 开始安装EMmac 打开一个新的终端，远程连接服务器GUI界面安装 EM：12345[mac]ssh -Y oracle@192.168.12.xxxoracle@192.168.12.xxx's password:Last login: Mon Nov 12 16:30:05 2018/usr/bin/xauth: file /home/oracle/.Xauthority does not exist[oracle@oem ~]$ /u01/stage/em12104/runInstaller My Oracle Support Details不选择I wish to receive security updates via My Oracle Support，点击Next。 Software Updates选择Skip，点击Next。 Prerequisite Checks等待所有检查通过，点击 Next。 注：若检查结果为Not Executed，直接点击Next。 Installation Types在 Create a new Enterprise Manager System 下，选择 Advanced，点击Next。 Installation Details设置如下： Middleware Home Location: /u01/app/oracle/product/MiddlewareR4 Agent Base directory: /u01/app/oracle/product/agentr4 Host Name: oem.com (注意，必须是FQDN) 点击 Next。 Select Plug-ins除了默认的选择之外，选择如下三个插件： Oracle Cloud Application Oracle Consolidation Planning and Chargeback Oracle Virtualization 然后点击 Next。 WebLogic Server Configuration Details输入WebLogic GCDomain的密码，以及Node Manager密码。其他保持默认选择，点击Next。 注意：密码不能以数字开头！ Database Connection Details输入数据库的连接信息： Database Host Name: oem.com Port: 1521 Service/SID: omr SYS Password: yourpassword Deployment Size选择SMALL。关于Deployment Size各个选项的含义，可以参考以下说明： Small &lt; 100 agents &lt; 1000 targets Medium &lt; 1000 agents &lt; 10,000 targets Large &gt; 1000 agents &gt; 10,000 targets 点击Next。 安装向导可能还会检查出一些错误的数据库设置，这时按照向导中的提示选择自动修复即可： 可能还会有一些警告出现。这是一些可能会影响EM的运行性能的警告，不会对EM的正常启动造成影响，所以可以暂时忽略，可以在安装完之后再修改数据库配置文件。 Enterprise Manager Configuration Details输入SYSMAN和OMA Agent Registration的密码。其他的选项保持默认值，点击Next。 注意：密码不能以数字开始，而且在安装完成后登陆EM的用户名就是sysman（不区分大小写）。 Port Configuration Details保持默认值，点击 Next。 Review检查所有设置，确认无误的话，点击Install。 Installation Progress Details开始漫长的安装过程，请耐心等待。 一定要确保根目录磁盘空间够用，建议大于40G，否则在安装过程可能会报错，比如start oralce management service failed。当出现这个错误时，我在网上找了各种解决方案都无法解决，最后发现是根目录磁盘空间不足造成的。 最后需要以root用户运行一个脚本：12345678910111213141516171819202122232425262728293031323334353637[root@oem lib]# /u01/app/oracle/product/MiddlewareR4/oms/allroot.shStarting to execute allroot.sh .........Starting to execute /u01/app/oracle/product/MiddlewareR4/oms/root.sh ......Running Oracle 11g root.sh script...The following environment variables are set as: ORACLE_OWNER= oracle ORACLE_HOME= /u01/app/oracle/product/MiddlewareR4/omsEnter the full pathname of the local bin directory: [/usr/local/bin]:The file "dbhome" already exists in /usr/local/bin. Overwrite it? (y/n)[n]: y Copying dbhome to /usr/local/bin ...The file "oraenv" already exists in /usr/local/bin. Overwrite it? (y/n)[n]: y Copying oraenv to /usr/local/bin ...The file "coraenv" already exists in /usr/local/bin. Overwrite it? (y/n)[n]: y Copying coraenv to /usr/local/bin ...Entries will be added to the /etc/oratab file as needed byDatabase Configuration Assistant when a database is createdFinished running generic part of root.sh script.Now product-specific root actions will be performed./etc existCreating /etc/oragchomelist file.../u01/app/oracle/product/MiddlewareR4/omsFinished execution of /u01/app/oracle/product/MiddlewareR4/oms/root.sh ......Starting to execute /u01/app/oracle/product/agentr4/core/12.1.0.4.0/root.sh ......Finished product-specific root actions./etc existFinished execution of /u01/app/oracle/product/agentr4/core/12.1.0.4.0/root.sh ...... 可能出现的问题在 Installation Progress Details 这一步，可能会出现： 1Error in invoking target &apos;install&apos; of makefile &apos;/u01/app/oracle/product/MiddlewareR4/Oracle_WT/webcache/lib/ins_calypso.mk&apos;. See &apos;/u01/app/oraInventory/logs/cloneActions2018-11-13_03-14-34-PM.log&apos; for details. 解决方案（参考了此文）增加 -ldms2 到 /u01/app/oracle/product/MiddlewareR4/Oracle_WT/lib/sysliblist 中。即将文件sysliblist的内容修改为：1234[root@oem ~]# cd /u01/app/oracle/product/MiddlewareR4/Oracle_WT/lib[root@oem lib]# cp -p ./sysliblist ./sysliblist.orig[root@oem lib]# vi ./sysliblist-ldl -lm -lpthread -lnsl -lirc -lipgo -ldms2 Finish安装结束。 在安装结束画面中会显示下面的信息： 123456789101112131415161718192021222324252627This information is also available at: /u01/app/oracle/product/MiddlewareR4/oms/install/setupinfo.txtSee below for information pertaining to your Enterprise Manager installation:Use the following URL to access: 1. Enterprise Manager Cloud Control URL: https://oem.com:7803/em 2. Admin Server URL: https://oem.com:7102/consoleThe following details need to be provided during the additional OMS install: 1. Admin Server Hostname: oem.com 2. Admin Server Port: 7102You can find the details on ports used by this deployment at : /u01/app/oracle/product/MiddlewareR4/oms/install/portlist.ini NOTE: An encryption key has been generated to encrypt sensitive data in the Management Repository. If this key is lost, all encrypted data in the Repository becomes unusable. A backup of the OMS configuration is available in /u01/app/oracle/product/gc_inst/em/EMGC_OMS1/sysman/backup on host oem.com. See Cloud Control Administrators Guide for details on how to back up and recover an OMS. NOTE: This backup is valid only for the initial OMS configuration. For example, it will not reflect plug-ins installed later, topology changes like the addition of a load balancer, or changes to other properties made using emctl or emcli. Backups should be created on a regular basis to ensure they capture the current OMS configuration. Use the following command to backup the OMS configuration:/u01/app/oracle/product/MiddlewareR4/oms/bin/emctl exportconfig oms -dir &lt;backup dir&gt; 也就是说，可以从下面的URL访问到EM了：1https://oem.com:7803/em 至此，EM的全部安装过程结束。 可能出现的问题若经过上述步骤后，仍旧无法访问https://oem.com:7803/em，可能是因为没有关闭防火墙，导致该端口无法被访问。可通过如下方式验证：1234[mac]telnet 192.168.12.xxx 7803Trying 192.168.12.xxx...telnet: connect to address 192.168.12.xxx: Connection refusedtelnet: Unable to connect to remote host 关闭防火墙：123[root@oem lib]# systemctl stop firewalld.service[root@oem lib]# firewall-cmd --statenot running 此时再次验证7803，则可以被访问了，且页面https://oem.com:7803/em也能访问了。1234[mac]telnet 192.168.12.XXX 7803Trying 192.168.12.xxx...Connected to localhost.Escape character is '^]'. (END) 参考文献 Oracle Enterprise Manager 12c 安装过程，by 夕阳下的奔跑 Oracle Database 12c Installation Procedure Oracle Database 12c Installation on CentOS 7, by centos.org How to Install Oracle Database 12c on CentOS 7, by howtoforge How to Install Oracle Database 12c on RHEL/CentOS 7 深入理解Linux修改hostname, by 潇湘隐者]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@linux 命令与权限间的关系]]></title>
    <url>%2Flanguages%2F41d4900b.html</url>
    <content type="text"><![CDATA[我们知道权限对于使用者帐号来说是非常重要的，因为他可以限制使用者能不能读取/创建/删除/修改文件或目录！ 本文将说明什么命令在什么样的权限下w才能够运行！ 让使用者能进入某目录成为 可工作目录 的基本权限为何？ 可使用的命令：例如 cd 等变换工作目录的命令；目录所需权限：使用者对这个目录至少需要具有 x 的权限额外需求：如果使用者想要在这个目录内利用 ls 查阅档名，则使用者对此目录还需要 r 的权限。 使用者在某个目录内读取一个文件的基本权限为何？ 可使用的命令：例如本章谈到的 cat, more, less等等目录所需权限：使用者对这个目录至少需要具有 x 权限；文件所需权限：使用者对文件至少需要具有 r 的权限才行！ 让使用者可以修改一个文件的基本权限为何？ 可使用的命令：例如 vi 编辑器等；目录所需权限：使用者在该文件所在的目录至少要有 x 权限；文件所需权限：使用者对该文件至少要有 r, w 权限 让一个使用者可以创建一个文件的基本权限为何？ 目录所需权限：使用者在该目录要具有 w,x 的权限，重点在 w 啦！ 让使用者进入某目录并运行该目录下的某个命令之基本权限为何？ 目录所需权限：使用者在该目录至少要有 x 的权限；文件所需权限：使用者在该文件至少需要有 x 的权限 参看文献 第七章、Linux 文件与目录管理, by 鸟哥的 linux 私房菜]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Shell 的启动方式及环境变量的配置]]></title>
    <url>%2Foperaing-system%2F896e6903.html</url>
    <content type="text"><![CDATA[本文内容：Shell 的3钟启动方式；不同启动方式下环境变量的加载文件及其顺序。 Shell 是什么？ Shell 是指操作系统中，提供访问内核服务的程序，与之相对的是操作系统的内核(linux kernel)。—维基百科 我们平常使用的命令行界面的 Shell，只是众多的 Shell 的一种。通常，根据使用方式的不同 Shell 可以分成两类：命令行界面(CLI)和图形界面(GUI)。本文介绍的是命令行界面(CLI)。 命令行界面 Shell(以下简称 CLI-Shell)，也是有很多种，通过运行cat /etc/shells命令，可以查看本机可以使用哪些 Shell。以下是 macOS 下可以使用的Shell： 12345678# List of acceptable shells for chpass(1)./bin/bash/bin/csh/bin/ksh/bin/sh/bin/tcsh/bin/zsh 在 Linux 发行版中，默认的 Shell 就是 Bash，接下来的内容都会以 Bash 为例来进行说明。在日常的工作中，经常会接触到环境变量、命令别名等概念。这些东西如何配置？如何生效？这就涉及到 Shell 的启动脚本了，在介绍启动脚本前，先一起来认识下 Shell 的不同启动方式。 Shell 不同的启动方式在你登入 Linux 系统启动一个 bash shell 时，默认情况下，bash 会在几个文件中查找命令，这些文件叫做启动文件或环境文件。而，bash 检查的启动文件取决于你启动 bash shell 的方式。启动 bash shell 有三种方式： 登录时作为默认登录 shell（login interactive shell) 作为非登录shell 的交互式shell (non-login interactive shell) 作为运行脚本的非交互式 shell(non-login non-interactive shell) 在具体说明各种启动方式前，先了解几个基本概念： 交互式 shell 和 非交互式 Shell ( interactive shell and non-interactive shell ) 交互式模式： 就是在终端上执行，shell等待你的输入，并且立即执行你提交的命令。这种模式被称作交互式是因为shell与用户进行交互。这种模式也是大多数用户非常熟悉的：登录、执行一些命令、退出。当你退出后，shell也终止了。 非交互式模式： 以shell script(非交互)方式执行。在这种模式下，shell不与你进行交互，而是读取存放在文件中的命令,并且执行它们。当它读到文件的结尾EOF，shell也就终止了。 可以通过打印$-变量的值(代表当前 Shell 的选项标志)，查看其中的i选项(表示 interactive shell)来区分交互式与非交互式 shell 1234zodas@localhost:~$ echo $-himBH #这是返回的内容zodas@localhost:~$ ./tesh.sh echo $-hb #这是返回的内容 登录 Shell 和非登录 Shell ( login shell and non-login shell ) 登录shell： 是需要用户名、密码登录后才能进入的shell（或者通过”–login”选项生成的shell）。 非登录shell： 不需要输入用户名和密码即可打开的Shell，例如：直接命令“bash”就是打开一个新的非登录shell，在Gnome或KDE中(带图形界面的 linux 中)打开一个“终端”（terminal）窗口程序也是一个非登录shell。 执行exit命令，退出一个shell（登录或非登录shell）；执行logout命令，退出登录shell（ 不能 退出非登录shell）。 1234567891011zodas@localhost:~$ bash --loginzodas@localhost:~$ logoutzodas@localhost:~$ bash --loginzodas@localhost:~$ exitlogoutzodas@localhost:~$ bashzodas@localhost:~$ logoutbash: logout: not login shell: use ‘exit’zodas@localhost:~$ exitexit 那么，如何判断一个已经打开的 Shell 是 login shell 还是 non-login shell？ A login shell is one whose first character of argument zero is ‘-’, or one invoked with the —login option. from bash reference manual bash 是 login shell 时，其进程名为”-bash“ 而不是”bash”。 比如下面的命令行演示： 123456789101112# 在 login shell 中：[zodas@localhost ~]$ echo $0-bash[zodas@localhost ~]$ ps -ef | grep '\-bash' | grep -v greproot 16823 16821 0 May06 pts/0 00:00:00 -bashzodas 21135 21134 0 May07 pts/1 00:00:00 -bash #在一个非登陆shell中：zodas@localhost:~$ echo $0/bin/bashzodas@localhost:~$ ps -ef | grep '\-bash' | grep -v grepzodas@localhost:~$ 登录 shell（login interactive shell）当你登录Linux系统时，bash shell 会作为登录shell启动。登录shell会从5个不同的启动文件里读取命令:12345/etc/profile &lt;==主启动文件，系统上每个用户登录时都会执行该启动文件；另外，该文件还配置了对于/etc/profile.d 目录下的所有文件也会在用户登录时被启动/$HOME/.bash_profile /$HOME/.bashrc/$HOME/.bash_login/$HOME/.profile 另外，当你 cat /etc/profile 时，会发现该文件中包含下面这段脚本，它用来迭代/etc/profile.d目录下的所有文件，一般，我们会将特定应用程序的启动文件放置在该目录下，当用户登录时，shell 会执行这些文件。123456789for i in /etc/profile.d/*.sh ; do if [ -r &quot;$i&quot; ]; then if [ &quot;$&#123;-#*i&#125;&quot; != &quot;$-&quot; ]; then . &quot;$i&quot; else . &quot;$i&quot; &gt;/dev/null fi fidone TIPS：对全局环境变量来说(Linux系统中所有用户都需要使用的变量)，可能更倾向于将新的或修改过的变量设置放在/etc/profile文件中，但这可不是什么好主意。如果你升级了所用的发行版，这个文件也会跟着更新，那你所有定制过的变量设置可就都没有了。最好是在/etc/profile.d目录中创建一个以.sh结尾的文件。把所有新的或修改过的全局环境变量设置放在这个文件中。在大多数发行版中，存储个人用户永久性 bash shell 变量的地方是 $HOME/.bashrc 文件。 交互式 Shell 进程（non-login interactive shell）若你的 bash shell 不是登录时启动的，如通过在命令行提示符下乔茹 bash 命令时启动，那么，此时启动的就是非登录下的交互式 shell。以这种方式启动的 shell，其启动文件为：1/$HOME/.bashrc 即该不会访问/etc/profile文件，只会检查用户目录下的 .bashrc文件。另外，当你 cat .bashrc文件后，会发现该文件中包含下面这段脚本，即该启动方式登录的 shell 还会加载 /etc/bashrc 文件。123if [ -f /etc/bashrc ]; then . /etc/bashrcfi 非交互式 Shell（non-login non-interactive shell）系统执行 shell 脚本时使用的就是这种shell。对于这种启动方式，bash shell提供了BASH_ENV环境变量。当shell启动一个非交互式shell进程时，它会检查这个环境变量来查看要执行的启动文件。如果有指定的文件，shell会执行该文件里的命令，这通常包括shell脚本变量设置。 那如果BASH_ENV变量没有设置，shell脚本到哪里去获得它们的环境变量呢? 对于启动子shell的脚本，如果父 shell 是登录 shell，在/etc/profile、/etc/profile.d/*.sh和$HOME/.bashrc文件中设置并导出了变量，用于执行脚本的子shell就能够继承这些变量。对于那些不启动子shell的脚本，变量已经存在于当前shell中了。所以就算没有设置BASH_ENV，也可以使用当前shell的局部变量和全局变量。 环境变量持久化如何设置局部用户定义变量？1234567[zodas@localhost ~]$ my_variable=&quot;hello world&quot; &lt;==定义用户变量，注意格式。[zodas@localhost ~]$ echo $my_variablehello world[zodas@localhost ~]$ bash &lt;==启动一个子 shell[zodas@localhost ~]$ echo $my_variable &lt;== 发现输出的是空行[zodas@localhost ~]$ exit tips: 所有的环境变量名均使用大写字母，这是bash shell的标准惯例。如果是你自己创建的局 部变量或是shell脚本，请使用小写字母。变量名区分大小写。在涉及用户定义的局部变量 时坚持使用小写字母，这能够避免重新定义系统环境变量可能带来的灾难。 如何设置全局环境变量？从上面的例子可以看到，可以通过等号该变量赋值，那么该变量就是局部用户定义变量，但若启动子 shell，子 shell 并不能继承父 shell 刚创建的局部用户定义变量，如上例，输出的是空行。那么，若要让子 shell 也能拿到父 shell 刚创建的用户变量，则需要将其变为全局环境变量。 123456[zodas@localhost ~]$ my_variable=&quot;hello world&quot; &lt;==首先创建局部用户变量[zodas@localhost ~]$ export my_variable &lt;==然后导出到全局环境中[zodas@localhost ~]$ bash &lt;==启动子 shell[zodas@localhost ~]$ echo my_varialbe &lt;==发现子 shell 已继承了在父 shell 中定义的用户变量hello world[zodas@localhost ~]$ exit 如何将环境变量永久化？分析 shell 的三种启动方式后，我们发现比较关键的是几个启动文件为：1234/etc/profile &lt;==该文件会被加载，是因为在 /etc/profile 中有相应的脚本/etc/profile.d/*.sh/$HOME/.bashrc/etc/bashrc &lt;==该文件会被加载，是因为在 .bashrc 中有相应的脚本 所以，对于系统环境变量，在 /etc/profile 中定义用户变量，并导出为全局环境变量，则该变量便会被持久化了。（注：由于系统更新时，该文件会被覆盖，导致配置过的变量丢失，所以，建议在 /etc/profile.d目录下添加响应的 .sh脚本文件的形式，添加系统环境变量，而不是以修改/etc/profile文件的形式添加系统环境变量。） 对于用户环境变量，在 /$HOME/.bashrc中定义用户变量，并导出为全局环境变量，则该变量便会被持久化了。当然，以上只是一些最简单的持久化方法。关键在于理解每个启动文件的加载时机，并将变量添加到合适的启动文件中，便能达到自己想要的效果。 参考 Bash Reference Manual Shell 启动详解和配置实践 理解 bashrc 和 profile Linux 安装软件时，/etc/profile,/etc/bash.bashrc, ~/.profile, ~/.bashrc 的用途 linux 下 su 与 su - 命令的本质区别 su ，su - ，sudo区别—pianzif login shell 与 non-login shell 的区别 linux 下的 source 命令 /etc/bashrc,用户目录下.bashrc有什么区别？—会编程的卡卡西 交互式 Shell 和非交互式 Shell，登录 Shell 和非登录 Shell 的区别—笑遍世界]]></content>
      <categories>
        <category>operaing-system</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@linux man page 使用指南]]></title>
    <url>%2Flanguages%2F3c9b26ea.html</url>
    <content type="text"><![CDATA[linux 命令那么多，且每个命令又有很多选项，难道要都背下来吗？笔者忘性大，可能当下还记得命令的各种详细用法，对于一些不常使用的命令，过段时间就忘记了具体用法了。所以，笔者选择只记住“在什么场景，使用哪类命令”，然后结合 man page，这种方式不仅快捷而且不易出错。接下来，本文将会对 man page 的页面结构做简单说明。 TIPS: 进入man指令的功能后，你可以按下 空格鍵 往下翻頁，可以按下 q 按键來离开man的环境。 更多在man指令下的功能，将在本文的后续部分介绍！ 以 man date 为例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[zodas@localhost ~]$ man dateDATE(1) User Commands DATE(1) # 请注意上面这个括号内的数字 NAME &lt;==这个命令的完整全名，如下所示为date且说明简单用途为配置与显示日期/时间 date - print or set the system date and time SYNOPSIS &lt;==这个命令的基本语法如下所示 date [OPTION]... [+FORMAT] date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]] DESCRIPTION &lt;==详细说明刚刚语法谈到的选项与参数的用法 Display the current time in the given FORMAT, or set the system date. -d, --date=STRING &lt;==左边-d为短选项名称，右边--date为完整选项名称 display time described by STRING, not &apos;now&apos; -f, --file=DATEFILE like --date once for each line of DATEFILE -r, --reference=FILE display the last modification time of FILE ....(中间省略).... # 找到了！底下就是格式化输出的详细数据！ FORMAT controls the output. The only valid option for the second form specifies Coordinated Universal Time. Interpreted sequences are: %% a literal % %a locale&apos;s abbreviated weekday name (e.g., Sun) %A locale&apos;s full weekday name (e.g., Sunday) ....(中间省略).... ENVIRONMENT &lt;==与这个命令相关的环境参数有如下的说明 TZ Specifies the timezone, unless overridden by command line parameters. If neither is specified, the setting from /etc/localtime is used. AUTHOR &lt;==这个命令的作者啦！ Written by David MacKenzie. REPORTING BUGS &lt;==有问题请留言给底下的email的意思！ Report bugs to &lt;bug-coreutils@gnu.org&gt;. COPYRIGHT &lt;==受到著作权法的保护！用的就是 GPL 了！ Copyright ? 2006 Free Software Foundation, Inc. This is free software. You may redistribute copies of it under the terms of the GNU General Public License &lt;http://www.gnu.org/licenses/gpl.html&gt;. There is NO WARRANTY, to the extent permitted by law. SEE ALSO &lt;==这个重要，你还可以从哪里查到与date相关的说明文件之意 The full documentation for date is maintained as a Texinfo manual. If the info and date programs are properly installed at your site, the command info date should give you access to the complete manual. date 5.97 May 2006 DATE(1) man page 页面结构基本上 man page 有好几个部分组成，如下表所示： 对于 DATE(1) 括号中的数字1，表示一般使用者可以使用的命令，括号中的数字可以帮着我们快速的了解到所查询内容的属性。 举例来说，如果你下达了 man null 时，会出现的第一行是：NULL(4)，对照一下上面的数字意义， 嘿嘿！原来 null 这个玩意儿竟然是一个 装置文件 呢！很容易了解了吧！ 上表中的1, 5, 8这三个号码特别重要，也请读者要将这三个数字所代表的意义背下来喔！ 阅读 man page 的心得 先察看NAME的项目，约略看一下这个数据的意思； 再详看一下DESCRIPTION，这个部分会提到很多相关的数据与使用时机，从这个地方可以学到很多小细节呢； 而如果这个命令其实很熟悉了(例如上面的date)，那么主要就是查询关于OPTIONS的部分了！ 可以知道每个选项的意义，这样就可以下达比较细部的命令内容呢！ 最后，会再看一下，跟这个数据有关的还有哪些东西可以使用的？举例来说，上面的SEE ALSO就告知我们还可以利用 info coreutils date 来进一步查阅数据； 某些说明内容还会列举有关的文件(FILES 部分)来提供我们参考！这些都是很有帮助的！ 另外，加入忘记了指令的完整名称，只记得该命令的部分关键词，该如何去查到所需要的 man page 呢？ 12[zodas@localhost ~]$ man -f keyword &lt;== 列出命令名中含有 keyword 的所有命令[zodas@localhost ~]$ man -k keyword &lt;== 列出 man page 中包含 keyword 的所有命令 参考文献 Linux系統的線上求助man page與info page，by 鸟叔]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@初始 Linux]]></title>
    <url>%2Foperaing-system%2F53de7a0b.html</url>
    <content type="text"><![CDATA[在深入研究如何使用Linux命令行和shell之前，最好先了解一下什么是Linux、它的历史及运作方式。本文将带你逐步了解什么是Linux，并介绍命令行和shell在Linux整体架构中的位置。 Linux 可以划分为：Linux 内核、GNU 工具、图形化桌面环境、应用软件四个部分，每部分在 Linux 系统中各司其职，通过协作构成一个完整的 Linux 系统。 Linux内核是系统的核心，控制着内存、程序和硬件之间的交互。内核主要负责以下四种功能： 系统内存管理 软件程序管理 硬件设备管理 文件系统管理 内核创建的第一个进程，即 PID=1 的进程为 systemd（之前为 initd 进程）。任何 Linux 系统需要与之通信的设备，都需要在内核代码中加入其驱动程序代码，Linux 系统将硬件设备当成特殊的文件——即设备文件，分为： 字符型设备文件：指处理数据时每次只能处理一个字符的设备，如调制解调器等 块设备文件：每次能处理大块数据的设备，如硬盘等 网络设备文件：指采用数据包发送和接收数据的设备，如网卡、回环设备等 Linux 内核采用虚拟文件系统 VFS 作为和每个文件系统交互的接口，当每个文件系统被挂载和使用时，VFS 将信息缓存在内存中。 GNU(GNU’S Not Unix)工具是Linux系统中的一个重要部分，如 shell 就是 GNU 核心工具集中的一部分。 我们将完整的 Linux 系统包称为发行版，一般分为3种： 完整的核心 Linux 发行版 特定用途的发行版 LiveCD 测试发行版 参考文献 Richard Blum.Linux命令行与shell脚本编程大全（第3版）[M].人民邮电出版社]]></content>
      <categories>
        <category>operaing-system</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@linux 下 cx_Oracle 模块的安装]]></title>
    <url>%2Fmanual%2F6b43c0d2.html</url>
    <content type="text"><![CDATA[python 想远程访问 Oracle 数据库，需要 cx_Oralce 模块，安装该模块前需要预安装： oracle instantclient python-devel install oracle instantclient安装 Oracle instantclient，需要下载以下文件： instantclient-basic-linux.x64-11.2.0.4.0.zip instantclient-sdk-linux.x64-11.2.0.4.0.zip instantclient-sqlplus-linux.x64-11.2.0.4.0.zip（可选，该包为命令行工具，类似于 mysql 的交互式命令行界面） step1: 下载安装包下载链接：http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html根据 linux 系统版本，以及 Oracle 的版本，选择对应版本的安装包，可以使用如下命令，查看系统信息以及版本信息，若服务器上使用的 Oracle 版本较老，建议安装低版本的 instantclient，否则建议使用最新版本。12[zodas@localhost ~]$ uname -a[zodas@localhost ~]$ cat /etc/redhat-release step2: 解压并配置环境变量 首先，本文使用 zip 包方式安装 instantclient，将所有zip 包都解压到 /opt/目录下1234[root@localhost ~]# cd /opt/[root@localhost opt]# unzip instantclient-basic-linux.x64-18.3.0.0.0dbru.zip[root@localhost opt]# unzip instantclient-sdk-linux.x64-18.3.0.0.0dbru.zip[root@localhost opt]# unzip instantclient-sqlplus-linux.x64-18.3.0.0.0dbru.zip 其次，增加环境变量，在~/.bashrc文件中新增：12export ORACLE_HOME=/opt/instantclient_18_3export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ORACLE_HOME 然后，增加软链接123[root@localhost opt]# cd instantclient_18_3[root@localhost instantclient_18_3]# ln -s libocci.so.18.1 libocci.so[root@localhost instantclient_18_3]# ln -s libclntsh.so.18.1 libclntsh.so install python-devel下载链接：https://rpmfind.net/linux/rpm2html/search.php?query=python-devel 123[root@localhost ~]# yum install python-devel# 或者使用 rpm 方式[root@localhost ~]# rpm -ivh python-devel-2.7.5-68.el7.x86_64.rpm install cx_Oracle下载链接：https://pypi.org/project/cx_Oracle/#files 首先，下载安装123[root@localhost opt]# tar -xvf cx_Oracle-6.4.1.tar.gz[root@localhost opt]# cd cx_Oracle-6.4.1[root@localhost opt]# python setup.py install 参考链接 Python使用cx_Oracle的几个小坑,by bluexiii]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@centos7下安装ipython（python2与python3共存)]]></title>
    <url>%2Fmanual%2Fb8430542.html</url>
    <content type="text"><![CDATA[安装 ipython 前，你需要预安装： epel-release python pip linux 发行版默认是已安装 python2.7的，所以我们只需安装 python3. step1: install epel-release1[root@localhost ~]# yum install epel-release step2: install python31[root@localhost ~]# yum install python34 step3: 验证 python 是否安装成功 step4: install pip and pip312[root@localhost ~]# yum install python2-pip[root@localhost ~]# yum install python34-pip step5: 验证 pip 是否安装成功 step6: install ipython12[root@localhost ~]# pip install ipython[root@localhost ~]# pip3 install ipython step7: 验证 ipython 是否安装成功]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@mac 常用快捷键]]></title>
    <url>%2Fmanual%2Fdea8e8d6.html</url>
    <content type="text"><![CDATA[自定义的全局快捷键一般为 command + option + control + key的组合形式，其中 key 一般为软件英文名的首字母，以便于记忆。 mac 自带快捷键截屏 command + shift + 4 截屏到粘贴板 command + shift + control + 4 截屏到文件并保存到桌面 切换输入法 command + control + 空格 spotlight search command + 空格 打开 Preference command + , 光标控制 command + shift + → 选中光标右侧所有内容 command + shift + ← 选中光标左侧所有内容 删除 command + delete 删除选中文件，删除光标所在行所有内容 软件快捷键iTerm2open iterm2 option + space 以默认 profile 打开iterm2 option + = 以 hotkey windows 模式打开 iterm2 打开 profile 选择界面 command + o 窗口和标签页操作 command + d 垂直分割 shift + command + d 水平分割 command + t 新建标签页 command + w 关闭标签页 command + 回车 进入/退出全屏 光标控制 control + u 删除光标所在行 control + k 删除光标右侧所有内容 option + ← 光标移到上一个单词 option + → 光标移到下一个单词 control + a 到行首 control + e 到行末 command + / 高亮当前光标所在的位置 命令补全 command + ; command + shift + h 弹出历史粘贴记录窗口 IntelliJ查询/替换 shift + shift 搜索class、文件名、变量等 command + shift + f 搜索代码中内容 command + o 搜索class command + shift + o 搜索 class 和文件名 command + shift + r replace，功能类似于 window 中的 control+h 编译和运行 command + F9 编译Project Command + Shift + F9 编译选择的文件、包或模块 Control + Option + R 弹出 Run 的可选择菜单 Control + Option + D 弹出 Debug 的可选择菜单 Control + R 运行 Control + D 调试 重构 F6 重构 rename command+F6 重构 修改方法签名 导航 command + 0 快速定位到 messages command + 1 快速定位到 project，即打开/关闭左侧的项目树 command + 3 快速定位到 find command + 5 快速定位到 debug command + 6 快速定位到 TODO command + 9 快速定位到 version control option + F12 open terminal F3 在光标所在行打 bookmark option + F3 在光标所在行打 bookmark 并标记为1/2/3…. control + 1 jump to bookmark1 control + 2 jump to bookmark2 Mweb快速笔记 command + control + option + n 全文搜索 command + o mweb在打开状态下调出mweb全文搜索引擎 command + control + o 全局状态下调出 mweb 全文搜索引擎 切换模式 command + l 文档库模式 command + e 外部模式 Omnifocus2新建一条 action command + shift + control + o 搜索 command + o evernoteopen evernote command+option+control+e new note in evernote command+shift+e Sublime Text打开 Sublime Text command + shift + control + s 调出command palette command+ + shift + p eudic查找字典 control + 空格 sequel pro执行选中的 sql 语句 control + y 选中可执行 sql 语句 执行 sql command + 回车 刷新数据表 command + r Dashsearch in dash command + control + option + d chromeopen chrome command + option + control + g moom激活 moom command + shift+ m 将当前窗口最大化 command + shift+ m + m 先激活 moom，在敲入 m 将当前窗口布局调整为半屏 command + shift+ m + command + ← 左半屏 command + shift+ m + command + → 右半屏 command + shift+ m + command + ↑ 上半屏 command + shift+ m + command + ↓ 下半屏 将当前窗口调整到另外一个显示器 command + shift+ m + option + 方向键 将当前窗口调整到另一个显示屏]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@数据脱敏的方法]]></title>
    <url>%2Finfomation-security%2Ff50560d1.html</url>
    <content type="text"><![CDATA[数据脱敏模式静态数据脱敏(SDM) 通过对源数 据库的克隆来进行脱敏操作，形成目标数据库，脱敏操作面对的是生产数据的镜像。SDM 通常维持两份数据，一份为原始数据，另一份为脱敏后数据。 优点： 可以根据需要调整脱敏规则，灵活性更高 脱敏工具的选择范围更大; 相对动态架构，静态架构对生产系统的压力更小。 缺点： 实时性低 敏感数据落地，安全风险增加 动态数据脱敏(DDM) 系统并不存储脱敏后数据，数据脱敏规则应用于在将数据从源数据库(生产库)导出到目标数据库(脱敏后数据库)的过程中进行脱敏处理，或者在生产系统产生实际数据的同时，也同步产生用于其他环境的脱敏数据。 优点： 敏感数据不落地 实时性高 对生产系统 缺点： 对生产系统产生一定的压力 脱敏策略可定制性不强，一旦投入持续生产就不能调整，否则会影响现有业务 脱敏应用会对源数据库到目标数据库链路安全和稳定性有较高要求 该架构一般都要求脱敏工具和生产库管理软件紧密耦合，限制可用工具的选择范围。 脱敏方法传统脱敏方法传统脱敏算法包括：替换、混洗、加密、变换、删除、遮掩等，下图为脱敏算法选择决策树。 其中，Level 表示敏感级值，ZSX、KYX、KPZ、GLX、SXX、KCX 分别为真实 性、可用性、可配置、关联性、时效性、可重现等 6 个 脱敏算法选择因素。 替换(Replacement，RP) 是指利用伪装数据对源数据中的敏感数据进行完全替换。为保证安全，一般替换用的数据都不具可逆性。 如： 常数替代：所有敏感数据都替换为唯一的常数值 查表替代：从中间表中随机或按照特定算法选择数据进 行替代 参数化替代：以敏感数据作为输入，通过特定函数形成新的替代数据 替换方法能够彻底的脱敏单类数据，但往往也会使相关字段失 去业务含义，对于查表替代而言，中间表的设计非常关键。 加密(Encryption，EC) 是指对待脱敏 的数据进行加密处理，使外部用户或系统只能够接 触无意义的加密数据。在特定场景下，系统可以提 供解密能力，分发密钥给相关方以恢复原始数据。 遮掩(Masking，MK) 指对敏感数据的部分内容用掩饰符号(如“X、*”)进行统一替换，从而使得敏感数据保持部分内容公开。 这种方法可以在很大程度上脱敏的同时，保持原有数据感观，也是一种广泛使用的方法。 删除(Deletion，DL) 直接删除敏感数据或将其置为空。 变换(Change，CG) 指对数值和日期类型的源数据，通过随机函数进行可控的调整(例如对于数值类型数据随机增减20%;对于日期数据，随机增减200天)，以便在保持原始数据相关统计特征的同时，完成对具体数值的伪装。 数值变化通过调整变动幅度可以有效控制目标数据的统计特征和真实度，是常用的脱敏方法。 混洗(Shuffle，SF) 主要通过对敏感数据进行跨行随机互 换来打破其与本行其他数据的关联关系，从而实现脱敏。 混洗可以在相当大范围内保证部分业务数据信息 (如有效数据范围、数据统计特征等)，使脱敏后数据看起来跟源数据更一致，与此同时也牺牲了一定的安全性。一般混洗方法用于大数据集合、且需要保留待脱敏数据特定特征的场景;对于小数据集，混洗形成的目标数据有可能通过其他信息被还原，在使用的时候需要特别慎重。 脱敏算法选择因素 可用性(KYX)。即脱敏后的数据应能满足分析应用 需求，若脱敏后的数据无法用于目标分析及应用，就 不具备使用价值。在特定应用场景中，可能需要保 留部分非关键信息(如身份证号码、手机号码的部分 字段等)才能满足分析需求。 关联性(GLX)。对于结构化和半结构化数据，在同 一数据表中某字段与另外字段有对应关系，如果脱 敏算法破坏了这种关系，该字段的使用价值将不复 存在。通常在进行数据统计需要参考量的情况下， 对数据的关联性要求较高。 真实性(ZSX)。脱敏后的数据对原始数据逻辑特征 和统计分布特征的保留程度。为满足这种特性，数 据的原始值需要尽可能地被保留。 时效性(SXX)。数据提供需要有一定的及时性，超 过一定时间后脱敏数据可能就不再具有进一步分析 挖掘的意义。因此，应尽量避免使用耗时的脱敏算 法，比如加密算法。 可重现(KCX)。即相同源数据在配置相同算法和参 数的情况下，脱敏后的数据应保持一致，随机类的算 法应避免使用。 可配置(KPZ)。主要是指可以灵活配置、组合脱敏 算法，可以结合不同需求生成个性化的脱敏数据。 数据匿名化 数据匿名化主张在不泄露用户隐私的前提下，对数据进行尽可能少的、不可逆的匿名化操作，降低攻击者获取用户敏感信息的概率，同时尽可能地保证数据的可用性和真实性。 匿名化问题的原始数据通常表示如下： D（显示标识符 EID，准标识符 QID，敏感数据 SA，非敏感数据 NSA） 显示标识符：指可以直接识别个人身份的属性，如姓名、身份证号码、社保号等 准标识符：单个准标识符并不能唯一的确定一个用户，但是多个准标识符的组合可以确定用户的身份。如地区、年龄、性别和血型等。 匿名化操作的目标是发布如下形式的匿名化数据： T（匿名化数据 QID，经过处理的敏感属性 SA’,非敏感数据 NSA） 常用方法略 匿名化发布原则如果只是简单的对显示标识符 EID，准标识符QID进行模糊化处理，但数据仍然容易受到背景知识攻击和同质攻击，基于此业界提出了以下几种匿名化发布原则。 K-anonymityK-anonymity，要求对于任意一行纪录，其所属的相等集内纪录数量不小于k，即至少有k-1条纪录准标识列属性值与该条纪录相同，目标是让企图识别数据身份的攻击者难以区分具有相同数值的 k 项记录。K-anonymity 虽然对数据进行匿名化操作，但是由于没有对敏感属性数据做任何的约束，导致数据容易遭受同质攻击和背景知识攻击。 L-diversityL-diversity，在 K-anonymity 的基础上进行了一定的改进，能够防止一致性攻击和背景知识攻击，与 K-匿名不同的是，K-anonymity 要求每个准标识符组合具有 k 个条目，L-diversity 要求每个 QID 的组合中需要有 $l$ 个不同的取值，增加了攻击者的攻击难度，使得恶意攻击者最多以 $ \frac {1}{l} $ 的概率成功猜测某元组个体的敏感属性值。 T-closenessT-closeness 对 L-diversity 进行了改进，增加了对敏感属性值分布的改善，它规定所有等价类中的敏感属性值的分布应该尽量接近该属性的全局分布，更大的增加了安全性，但信息损失较大，算法时间复杂度也高。 M-invarianceM-invariance，针对动态递增数据集的一种匿名化原则，此原则保证了在任意时刻发布的等价类都包含 M 个不同取值的记录，并且需要保证相同的记录在不同时刻的取值相同，从而保证在动态数据发布环境下的数据一致性。 数据脱敏工具国外，Oracle 的 Data Masking 组件，IBM 的 InfoSphere OptIMData Privacy 产品，Informatica 的Tnformatica Data Masking 产品等，其中 Informatica 的产品可以实现对异构数据的脱敏处理，也可以自己创建脱敏平台或系统进行脱敏处理；国内，网智天元研发的“金蜂巢”数据脱敏系统、网御星云的脱敏系统、比特信安的大数据脱敏系统等。 参考文献 龚奇源. 面向数据发布的数据匿名技术研究[D]. 东南大学, 2016. 乔宏明, 梁奂. 运营商面向大数据应用的数据脱敏方法探讨[J]. 移动通信, 2015(13):17-20. 吴行飞. 中小城市商业银行数据脱敏研究——以东营银行为例[D]. 山东大学, 2016. 王鑫, 王电钢, 母继元,等. 基于机器学习的数据脱敏系统研究与设计[J]. 电力信息与通信技术, 2018(1). 江堂碧. 支持挖掘的流式数据脱敏关键技术研究[D].电子科技大学,2017. 数据脱敏(Data Masking)与大数据脱敏平台设计 美团数据仓库-数据脱敏 浅析数据安全脱敏工具 GOOGLE 如何对数据进行匿名化处理 利用数据匿名化（Data Anonymization）技术增强云的信息安全-Intel白皮书 大数据与数据脱敏-知乎专栏 常见数据脱敏算法示例]]></content>
      <categories>
        <category>infomation-security</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[@CentOS7下MySQL 的安装]]></title>
    <url>%2Fmanual%2F5e99fb6d.html</url>
    <content type="text"><![CDATA[123456789101112131415# 下载链接可从官网获得[root@localhost ~]# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm[root@localhost ~]# yum install mysql57-community-release-el7-10.noarch.rpm# 激活与 mysql-community 相关的 yum 源[root@localhost ~]# yum repolist enabled | grep "mysql.*-community.*"[root@localhost ~]# yum -y install mysql-community-server# 启动 MySQL 服务[root@localhost ~]# systemctl start mysqld.service# 检查 MySQL 服务是否已正常启动[root@localhost ~]# systemctl status mysqld.service# 找到 MySQL 安装时给的默认密码[root@localhost ~]# grep 'temporary password' /var/log/mysqld.log[root@localhost ~]# mysql -uroot -p# 修改密码，密码得包含大小写数字和符号，不然可能过不了[root@localhost ~]# ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!' 参考链接 Installing MySQL on Linux Using the MySQL Yum Repository CentOS7安装MySQL7详解]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: 断言]]></title>
    <url>%2Flanguages%2Fb07edd.html</url>
    <content type="text"><![CDATA[一种错误处理机制，在程序开发与测试阶段使用；可以理解为代替 if-else 或 try-catch，这些东西对程序性能是有一定影响的，完成调试后你还要一个个把他删除掉，如果用断言，则是最低代价。 为什么使用断言？假设确信某个属性符合要求，并且代码的执行依赖于这个属性。例如，需要计算1double y= Math.sqrt(x); 我们确信，这里的 x 是一个非负数值。原因是：x 是另外一个计算的结果，而这个结果不可能是负值；或者 x 是一个方法的参数，而这个方法要求它的调用者只能提供一个正整数。但在开发阶段，希望对该变量进行进行检查，以避免加入传入一个不合法的参数 x 参与计算操作。可以这么做： 123if(x&lt;0) &#123; throw new I1legalArgumentException(&quot;x&lt;0&quot;);&#125; 但是这段代码会一直保留在程序中，即使测试完毕也不会自动地删除。如果在程序中含有大量的这种检查，程序运行起来会相当慢。 断言机制允许在测试期间向代码中插入一些检查语句。当代码发布时，这些插人的检测语句将会被自动地移走。 语法Java2在1.4中新增了一个关键字：assert。在程序开发过程中使用它创建一个断言(assertion)，它的语法形式有如下所示的两种形式： assert expression;这里expression 必须是一个布尔值。如果表达式的结果为true，那么断言为真，并且无任何行动如果表达式为false，则断言失败，则会抛出一个AssertionError对象。这个AssertionError继承于Error对象 asser expression:str;这里expression 必须是一个布尔值，str 是断言失败时输出的失败消息的字符串。 启用和禁用断言在默认情况下，断言被禁用。可以在运行程序时用 -enableassertions 或 -ea 选项启用;断言的关闭：使用 disableassertions 或 -da 来关闭断言功能 1234567891011public class AssertDemo &#123; static void test(int num) &#123; //如果num &lt;= 0的话,抛出AssertError,显示错误信息 assert(num &gt;=0):"传入参数需要大于0"; System.out.println("参数为正数！"); &#125; public static void main(String[] args) &#123; test(-7); &#125; &#125; 运行截图：]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: 访问控制]]></title>
    <url>%2Flanguages%2Fa82340c6.html</url>
    <content type="text"><![CDATA[Java中的控制符，用来控制其他类能否访问Java中的某一方法、变量，即控制java类、方法、变量的可见性、可访问性，从而实现数据封装。Java中有两个级别的访问控制符： 类级别：控制其他类能否使用该类。有2中类型： public 和 default 成员级别：控制某一方法、变量的访问权限。有4种类型： public , protected, default，private。 首先解释一下“使用”一词到底是什么意思？对于方法，很显然就是调用；对于变量，则是指访问或者修改；而对于类，则是指继承、实例化等，也就是能否在import中导入。 对本类可见：private 对所有类可见：public 对本包和所有子类可见：protected 对本包可见：default 实质上，protected 方法的调用是否合法(编译是否通过)关键是要看被调用的 protected 方法从根源上看所在的类对应的包与调用代码所在的类对应的包是否相同，若相同，则合法；否则，不合法。当然，无论如何，子类是可以访问继承而来的属于它自己的受保护方法的。]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Postman 如何使用(mac)]]></title>
    <url>%2Fmanual%2Ff7bab520.html</url>
    <content type="text"><![CDATA[Postman 可以做什么？ 创建 + 测试: 创建和发送任何的HTTP请求，请求可以保存到历史中再次执行 Organize: 使用Postman Collections 为更有效的测试及集成工作流管理和组织APIs document: 依据你创建的 Clollections 自动生成API文档,并将其发布成规范的格式 collarorate: 通过同步连接你的team和你的api，以及权限控制，API库 安装 Postman方式一：安装独立APP（推荐）：https://www.getpostman.com/ 方式二：安装 chrome 浏览器版： 首先安装 postman 浏览器版 download 然后安装 postman-interceptor extension download 使用方法（以独立APP举例，chrome 插件类似）设置正确的 COOKIE GET POST(json) POST(formdata) 其他的请求类型，例如 DELETE 也是同样的用法。 历史记录Postman 默认会记录所有的执行历史，如果你注册帐号并登录，历史记录还会同步。 同时，Postman还提供Collections功能，对请求进行分类整理。 环境变量Postman 提供一个 Environments 功能，类似与系统变量，可以一键切换测试环境。 其它Postman 还可以提供接口批量测试 等功能，有兴趣的话可以自己多玩玩。 Hosts修改工具：iHost 参考链接 基于Postman的API自动化测试 Postman 使用详解—掘金]]></content>
      <categories>
        <category>manual</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: 包装类和原始数据类型]]></title>
    <url>%2Flanguages%2Fae5c91d4.html</url>
    <content type="text"><![CDATA[所有原始数据类型都有一个与之对应的类，即包装类(wrapper)。包装类的特性： 包装类是不可变类，在构造了包装对象后，不允许更改包装在其中的值； 包装类是 final 的，不能定义他们的子类。 下图为 Integer 类的定义： 下图为 Number 类的定义： 包装类的常用方法如下： 自动装箱和自动拆箱自动装箱：Java 将原始数据类型值转换成对应的对象，比如将 int 的变量转换成Integer 对象。自动拆箱：自动将Integer对象转换成int类型值 12Integer i = 3; // 自动装箱。实际上执行了 Integer i = Integer.valueOf(3);int j = i; // 自动拆箱。实际上执行了 int j = Integer.intValue(); 包装类和原始数据类型的区别 包装类的默认值为 null，原始数据类型的默认值为 0 或 false 集合类中只能使用包装类 泛型中使用包装类 数据库查询的结果为 null 时，不能赋给原始数据类型，得使用包装类。（这也是为什么 PO 中建议只用包装类，而不是使用原始数据类型） 使用 &gt; 或 &lt; 比较大小时会自动拆箱，使用 == 比较时不会 Java常量池中数值范围为[-128,127]，使用字面值为一个包装类初始化，如果字面值在[-128,127]之间，jvm会在常量池中寻找该常量，那么该包装类的引用指向的是常量池中的一片区域，如果字面值超过这个范围，会创建包装类对象（即分配一个新的内存地址） 123456789101112public class Test &#123; public static void main(String[] args) &#123; Integer i1 = 127;//指向常量池中的127 Integer i2 = 127;//指向常量池中的127 System.err.println(i1 == i2);//指向同一内存区域，输出true i1 = 128; //创建对象 i2 = 128; //创建对象 System.err.println(i1 == i2); //指向不同区域，输出false &#125;&#125; 注意：包装类的 == 比较的是地址是否相等，原始数据类型的 == 比较的是值是否相等 使用场景举例Integer 的默认值为 null，即 Integer 可以区分出未赋值和值为 0 的区别，int 则无法表达出未赋值的情况。例如，要想表达出没有参加考试和考试成绩为 0 的区别。 在 JSP 开发中，Integer 的默认值为 null，所以用 EL 表达式在文本框中显示时，值为空白字符串，而 int 的默认值为 0，所以用 EL 表达式在文本框中显示时为 0。 参考链接 Java基本类型包装类]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: equals 与 ==]]></title>
    <url>%2Flanguages%2F9edb0a2.html</url>
    <content type="text"><![CDATA[== 是一个二元操作符，用于比较原生类型和对象。 就原生类型（如：boolean, int, float等），使用 == 比较两者的值是否相等 就对象而言，使用 == 比较两个对象的引用是否相等，即比较的是对象的地址是否相等 对于对象之间比较是否相等，不能单纯的通过比较其地址相等。最常见的就是判断字符串相等的情形，两个相同的字符串，其对象引用可能是不同的，这时你若使用 == 去判断两对象是否相等，就不能达到我们预期的目标，因为，对于内容相同的字符串我们认为它们是相同的字符串，即使它们的地址不等。 Java 中的 equals 方法其实是交给开发者去覆写的，让开发者根据具体的业务逻辑去定义满足什么条件的两个对象是相等的。所以不能单纯的说 equals 到底比较的是什么，想知道一个类的 equals 方法是什么意思就要去看定义。 JAVA 库中的 Object.equals 方法实现如下： 123public boolean equals(Object obj)&#123; return (this == obj);&#125;]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: JAR 包]]></title>
    <url>%2Flanguages%2FInfinity.html</url>
    <content type="text"><![CDATA[JAR(Java Archive File)，是一种压缩文件，与常见的 ZIP 压缩文件兼容，不同的是 JAR 文件默认包含了一个名为 META-INF/MANIFEST.MF 的清单文件，这个清单文件是在生成 JAR 文件时由系统自动创建的。 当开发了一个应用程序后，这个应用程序包含了很多类，如果需要把这个应用程序提供给别人，通常会把这些类文件打包成一个 JAR 文件，则 Java 虚拟机就可以自动在内存中解压这个 JAR 包，把这个 JAR 文件当成一个 路径。 当一个应用程序开发成功后，大致有以下三种发布方式： 使用平台相关的编译器将整个应用编译成平台相关的可执行文件。这种方式丧失了跨平台性质 为应用编辑一个批处理文件。 将应用程序制作成 可执行的 JAR 包 创建可执行的 JAR 包的关键在于：让 javaw 命令知道程序入口的主类的类名（制作一个可执行的 jar 包只需要增加 -e 选项即可）。下面命令把 test 目录下的所有文件都压缩到 test.jar 中，并制定使用 test.Main 类作为程序的入口。jar cvfe test.jar test.Main test，然后执行java -jar test.jar 即可运行 JAR 包。]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@查看本机默认使用的 shell]]></title>
    <url>%2Fmanual%2Ff0b74c9.html</url>
    <content type="text"><![CDATA[查看本机系统支持的 shell 1cat /etc/shells 查看现在正在使用的 shell 1echo $SHELL 修改默认 shell，如将 zsh 改成 bash 1chsh -s /bin/bash]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@mac 触摸板右键与智能缩放手势冲突]]></title>
    <url>%2Fmanual%2Fea866544.html</url>
    <content type="text"><![CDATA[Mac 触摸板的右键与智能缩放的手势都是 双指轻点触摸板，所以当你同时开启了这两个手势功能时，你用双指点击触摸板，往往默认触发的是智能缩放功能 ，很难触发 右键 功能。 解决方案：用双指 快速 轻点触摸板两下，触发智能缩放功能；用双指 慢速 轻点触摸板两下，触发右键功能，且在你点完两下后，会有个 delay 时间。]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: 泛型]]></title>
    <url>%2Flanguages%2F714686dc.html</url>
    <content type="text"><![CDATA[本文包括：引入泛型的目的，泛型代码如何编写，JVM 如何处理泛型类型，类型擦除的利弊，通配符等。 为什么要使用泛型？表面上看来，Java 的泛型很像 C++ 中的模版， 在 Java 增加泛型支持之前： 1234567public class ArrayList&#123; private Object[] elementData; ... public Object get(int i)&#123;...&#125; public void add(Object o)&#123;...&#125; ...&#125; 会存在问题：当获取一个类时需要进行强制类型转换 123ArrayList lists = new ArrayList();lists.add(new String("hello world"));String str = (String)files.get(0); 对于这个调用和运行，编译和运行都不会出错，然而在其它地方，如果将 get 的结果强制类型转换为 String 类型，可能会产生错误。 但引入泛型支持后： 编译器可以预先检查，避免插入错误类型的对象。当 add 错误类型，是会出现变异错误的，这比类在运行时出现类的强制类型转换异常要好得多。使得程序具有更好的可读性和安全性。 1234ArrayList&lt;String&gt; strList = new ArrayList&lt;&gt;();strList.add("hello");String str = strList.get(0);strList.add(new File("...")); //can only add String objects to an ArrayList&lt;String&gt; Java 泛型设计的原则是，只要代码在编译时没有出现警告，就不会遇到运行时 ClassCastException。 JDK1.5 增加泛型支持在很大程度上都是为了让集合能记住其元素的数据类型。在没有泛型（Generic）之前，一旦把一个对象“丢进”Java 集合中，集合就会忘记对象的类型，把所有的对象当成 Object 类型处理。当程序从集合中取出对象后，就需要进行强制类型转换，这种强制类型转换不仅使代码臃肿，而且容易引起 ClassCastException 异常。 Java 5 改写了集合框架中的全部接口和类，为这些接口、类增加了泛型支持，从而可以在声明集合变量、创建集合对象时传入类型实参。 可以为任何类、接口增加泛型声明，并不是只有集合类才可以使用泛型声明，虽然集合类是泛型的重要使用场所。 注：当创建了带泛型声明的接口、父类之后，可以为该接口创建实现类，或从该父类派生子类，需要指出的是，当使用（或者说调用）这些泛型接口、泛型类时不能再包含类型形参，而是必须为类型形参传入实际的类型。 并不存在泛型类，不管为泛型的类型形参传入哪一种类型实参，对于 Java 来说，它们依然被当成同一个类处理（即为同一个 class 文件，并不会生成新的 class 文件），在内存中也只占用一块内存空间，因此在静态方法、静态初始化块或者静态变量的声明和初始化中不允许使用类型形参。 如何定义泛型泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型。 定义简单泛型类12345678910111213public class Pair&lt;T&gt;&#123; private T first; private T second; public Pair()&#123;first = null; second = null&#125; public Pair(T first, T second)&#123;this.first = first; this.second=second;&#125; public T getFirst()&#123;return first;&#125; public T getSecond()&#123;return second;&#125; public void setFirst(T first)&#123;this.first = first;&#125; public void setSecond(T second)&#123;this.second = second;&#125;&#125; Pair 类引入了一个类型变量 T， 用尖括号 &lt;&gt; 括起来放在类名的后面。泛型类可以使用多个类型变量，例如：public class Pair&lt;T,U&gt;{...}。 用具体的类型替换类型变量就可以实例化泛型类型，如：Pair&lt;String&gt;，换句话说，泛型类可看做是普通类的工厂。 注：类型变量使用大写形式，在 Java 库中，一般使用类型变量 E 表示集合的元素类型，K 和 V 分别表示表的关键字与值的类型，使用 T, U, S 表示任意的类型。 定义泛型方法泛型方法可以定义在泛型类中，也可定义在普通类中。定义泛型方法时，必须在返回值之前加一个 &lt;T&gt;，来声明这是一个泛型方法，以告知该方法持有一个类型变量 T。 123456public class ArrayAlg&#123; public static &lt;T&gt; T getObject(Class&lt;T&gt; c)&#123; T t = c.newInstance(); return t; &#125;&#125; 为什么要使用泛型方法呢？因为泛型类要在实例化的时候就指明类型，如果想换一种类型，不得不重新 new 一次，可能不够灵活；而泛型方法可以在调用的时候指明类型，更加灵活。 类型变量有时，类或方法需要对类型变量加以约束。 如：我们要计算数组中的最小元素： 1234567891011class ArrayAlg&#123; public static &lt;T&gt; T min(T[] a)&#123; if(a==null || a.length == 0) return null; T smallest = a[0]; for(int i=0; i &lt; a.length; i++)&#123; if(smallest.compareTo(a[i])&gt;0) smallest = a[i]; &#125; return smallest; &#125;&#125; 但是，上述代码有个问题，变量 smallest 的类型是 T，这意味着它可以是一个任意类的对象，怎么才能保证 T 所属的类一定有 compareTo 方法呢？解决这个问题的方式是将 T 限制为实现了 compareTo 方法的类，将上述代码的方法签名改写为：public static &lt;T extends Compareable T min(T[] a){…}`。 一个类型变量可以有多个限定，如： 1T extends Comparable &amp; Seriable 限定类型用 &amp; 分隔，而逗号用来分隔类型变量。在 Java 的继承中，可以根据需要拥有多个接口超类型，但限定中至多有一个类。如果用一个类作为限定，它必须是限定列表中的第一个。 通配符类型带有超类型限定的通配符可以向泛型对象写入，带有子类型限定的通配符可以从泛型对象读取。Pair&lt;?&gt; 与 Pair 本质的不同在于，可以用任意 Object 对象调用原始 Pair 类的 setObject 方法。 JVM 如何处理泛型代码JVM本身并没有泛型对象这样的一个特殊概念。所有的泛型类对象在编译器会全部变成普通类对象。总之， JVM 中没有泛型，只有普通的类和方法 在编译阶段，所有泛型类的类型参数都会被Object或者它们的限定边界来替换。(类型擦除) 在继承泛型类型的时候，桥方法的合成是为了避免类型变量擦除所带来的多态灾难。 为保持类型安全性，必要时插入强制类型转换 类型擦除事实上，JVM 并不知道泛型，所有的泛型在编译阶段就已经被处理成了普通类和方法。处理方法很简单，我们叫做类型变量 T 的擦除(erased) 。 无论我们如何定义一个泛型类型，相应的都会有一个原始类型被自动提供。原始类型的名字就是擦除类型参数的泛型类型的名字。 如果泛型类型的类型变量没有限定(&lt;T&gt;) ，那么我们就用Object作为原始类型； 如果有限定(&lt;T extends XClass&gt;)，我们就XClass作为原始类型； 如果有多个限定(&lt;T extends XClass1&amp;XClass2&gt;)，我们就用限定列表的第一个限定类/接口XClass1 作为原始类型 如下： 对于类型变量没有指定限定类型的泛型类，擦除前： 12345678910111213public class Pair&lt;T&gt;&#123; private T first; private T second; public Pair()&#123;first = null; second = null&#125; public Pair(T first, T second)&#123;this.first = first; this.second=second;&#125; public T getFirst()&#123;return first;&#125; public T getSecond()&#123;return second;&#125; public void setFirst(T first)&#123;this.first = first;&#125; public void setSecond(T second)&#123;this.second = second;&#125;&#125; 擦除后，原始类型如下： 12345678910111213public class Pair&#123; private Object first; private Object second; public Pair()&#123;first = null; second = null&#125; public Pair(Object first, Object second)&#123;this.first = first; this.second=second;&#125; public Object getFirst()&#123;return first;&#125; public Object getSecond()&#123;return second;&#125; public void setFirst(Object first)&#123;this.first = first;&#125; public void setSecond(Object second)&#123;this.second = second;&#125;&#125; 对于类型变量有多个限定的泛型类，擦除前： 1234567891011public class Interval&lt;T extends Comparable &amp; Serializable&gt; implements Serializable&#123; private T lower; private T upper; ... public Interval(T first, T second)&#123; if(first.compareTo(second) &lt;= 0)&#123; lower = first; upper = second; &#125; &#125;&#125; 擦除后，原始类型如下： 1234567891011public class Interval implements Serializable&#123; private Comparable lower; private Comparable upper; ... public Interval(Comparable first, Comparable second)&#123; if(first.compareTo(second) &lt;= 0)&#123; lower = first; upper = second; &#125; &#125;&#125; 思考？如何将上述代码改写成 public class Interval&lt;T extends Serializable &amp; Comparable&gt; implements Serializable 会发生什么？如果这样做，原始类型用 Serializable 代替 T，而编译器在必要时要向 Comparable 插入强制类型转换。 所以，为了提高效率，应该将标签接口（即没有方法的接口）放在限定列表的末尾。 翻译泛型表达式当程序调用泛型方法时，如果擦除返回类型，编译器插入强制类型转换。如： 12Pair&lt;Employee&gt; buddies = ...;Employee buddy = buddies.getFirst(); 编译器会把上面这个方法调用翻译为两条虚拟机指令： 擦除 getFirst 的返回类型后将返回 Object 类型 编译器自动插入 Employee 的强制类型转换 约束与局限性（类型擦除的引入需要考虑的问题） 不能用基本类型（八大基本数据类型）实例化类型参数。如 Pair&lt;double&gt; 是错误的，Pair&lt;Double&gt; 是正确的方式。 不能构造泛型数组 Varargs 警告 不能在静态域或方法中引用类型变量 不能抛出或捕获泛型类的实例 没有泛型数组12Pair&lt;String&gt;[] stringPairs = new Pair&lt;String&gt;[10];Pair&lt;Integer&gt;[] intPairs = new Pair&lt;Integer&gt;[10]; 这种写法编译器会指定一个 Cannot create a generic array of Pair 的错误。 我们说过泛型擦除之后，Pair&lt;String&gt;[] 会变成 Pair[]，进而又可以转换为 Object[];假设泛型数组存在，那么 12Object[0]=stringPairs[0]; OkObject[1]=intPairs[0]; Ok 这就麻烦了，理论上 Object[] 可以存储所有 Pair 对象，但这些 Pair 对象是泛型对象，他们的类型变量都不一样，那么调用每一个 Object[] 数组元素的对象方法可能都会得到不同的内容，也许是个字符串，也许是整型，这对于 JVM 可是无法预料的。 由于数组内的每个元素必须是同一类型，泛型类型恰恰做不到这一点。即使Pair&lt;String&gt;, Pair&lt;Integer&gt;… 都是 Pair 类型的，但他们还是不一样。 需要说明的是，只是不允许创建这些数组，而声明类型为 Pair&lt;String&gt;[] 的变量仍是合法的，不过不能用 new Pair&lt;String&gt;[10] 初始化这个变量。 Varargs 警告上一节中已经了解到，Java 不支持泛型类型的数组。这一节中我们再来讨论一个相关的问题：向参数个数可变的方法传递一个泛型类型的实例。 考虑下面这个简单的方法，它的参数个数是可变的： 12345public static &lt;T&gt; voi daddA11 (Co1 lection &lt;T&gt; co11, T... Ts)&#123; for(t:ts)&#123; co11. Add (t); &#125;&#125; 应该记得，实际上参数 ts 是一个数组，包含提供的所有实参。 现在考虑以下调用： 1234Co11ection&lt;Pair&lt;String&gt;&gt; table = ...;Pair&lt;String&gt; pair1 = ...;Pair&lt;String&gt; pair2 = ...;addA11(table, pair1, pair2); 为了调用这个方法，Java 虚拟机必须建立一个 Pair &lt;String&gt;数组，这就违反了前面的规则。不过，对于这种情况，规则有所放松，你只会得到一个警告，而不是错误。 可以采用两种方法来抑制这个警告。 一种方法是为包含 addAll 调用的方法增加注解 @SuppressWarnings(&quot;unchecked“）。 或者在 Java SE 7 中，还可以用 @SafeVarargs 直接标注 addAll 方法： 12@SafeVarargspublic static &lt;T&gt; void addA11 (Co11ection&lt;T&gt; co11, T... Ts) 现在就可以提供泛型类型来调用这个方法了。对于只需要读取参数数组元素的所有方法，都可以使用这个注解，这仅限于最常见的用例。 继承泛型类型的多态麻烦（子类没有覆盖住父类的方法）看一个例子： 123class SonPair extends Pair&lt;String&gt;&#123; public void setFirst(String fir)&#123;....&#125; &#125; 程序员的本意是想在 SonPair 类中覆盖父类 Pair&lt;String&gt; 的 setFirst(T fir) 这个方法。但事实上，SonPair 中的 setFirst(String fir) 方法根本没有覆盖住 Pair&lt;String&gt; 中的这个方法。原因很简单，Pair&lt;String&gt; 在编译阶段已经被类型擦除为 Pair 了，它的 setFirst 方法变成了 setFirst(Object fir) 。 那么SonPair中 setFirst(String fir) 当然无法覆盖住父类的 setFirst(Object fir) 了。 这对于多态来说确实是个不小的麻烦，我们看看编译器是如何解决这个问题的。编译器会 自动 在 SonPair 中生成一个 桥方法 (bridge method )： 123public void setFirst(Object fir)&#123; setFirst((String) fir)&#125; 这样，SonPair 的桥方法确实能够覆盖泛型父类的 setFirst(Object fir) 了。而且桥方法内部其实调用的是 SonPari 的 setFirst(String fir) 方法。 现在，假设我们还想在 SonPair 中覆盖 getFirst() 方法呢？ 123class SonPair extends Pair&lt;String&gt;&#123; public String getFirst()&#123;....&#125; &#125; 由于需要桥方法来覆盖父类中的 getFirst，编译器会自动在 SonPair 中生成一个 public Object getFirst() 桥方法。但是，疑问来了，SonPair 中出现了两个方法签名一样的方法(只是返回类型不同)： 12String getFirst() // 自己定义的方法Object getFirst() // 编译器生成的桥方法 编译器允许出现方法签名相同的多个方法存在于一个类中吗？（程序员不能定义方法签名一样的方法，但编译器可以自动创建） 明确几点： 方法签名 确实只有方法名+参数列表 。 我们绝对不能编写出方法签名一样的多个方法。如果这样写程序，编译器是会报错的 最重要的一点是：JVM 会用参数类型和返回类型来确定一个方法。 一旦编译器通过某种方式自己编译出方法签名一样的两个方法(只能编译器自己来创造这种奇迹，我们程序员却不能人为的编写这种代码)。JVM还是能够分清楚这些方法的，前提是需要返回类型不一样。 泛型类型的继承准则泛型类与普通类一样都可以继承或实现接口，不同的是 ArrayList&lt;Manager&gt; 是 List&lt;Manager&gt; 的实现，而 ArrayList&lt;Manager&gt; 与 ArrayList&lt;Employee&gt; 之间没有关系（即使 Manager 是 Employee 的父类） 反射和泛型反射允许你在运行时分析任意的对象。如果对象是泛型类的实例，关于泛型类型参数则得不到太多信息，因为它们会被擦除。那通过反射可以获得泛型类的什么信息？ Java 泛型的卓越特性之一是在虚拟机中泛型类型的擦除，但擦出的类仍旧保留一些泛型祖先的微弱记忆，可以使用反射 API 来确定： 这个泛型方法有一个叫做 T 的类型参数。 这个类型参数有一个子类型限定，其自身又是一个泛型类型。 这个限定类型有一个通配符参数。 这个通配符参数有一个超类型限定。 这个泛型方法有一个泛型数组参数。]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Git 命令详解: checkout reset 与 revert]]></title>
    <url>%2Flanguages%2F10b5a0f5.html</url>
    <content type="text"><![CDATA[checkout 和 reset 均有两个作用域：commit 粒度、文件粒度，而 revert 只有 commit 粒度的作用域；Revert 撤销一个提交的同时会创建一个新的提交。checkout 操作的是 全局HEAD 指针，reset 操作的是 分支的HEAD 指针。 git reset git reset —soft HEAD~1 只修改指针的指向，不改变暂存区和工作目录的内容git reset —mixed HEAD~1 修改指针的指向，同时更新暂存区的内容与指针指向的版本同步，即使暂存区中有未 commit 的内容，也会被覆盖git reset —hard HEAD~1 修改指针的指向，同时更新暂存区的内容，并丢弃工作目录为提交的更改 commit 粒度 撤销本地仓库 hotfix 最近一次的提交，然后将当前工作目录的内容作为新的提交覆盖那两次提交。 1234567# 切换到 hotfix 分支git checkout hotfix# 将 分支的指针 指向前一次提交，并将这个新指向的版本，同步到暂存区git reset HEAD~1（即 git reset --mixed HEAD~1）# 将工作目录新的内容添加到本地仓库git add .git commit -m '作废上一次的提交，使用新的内容' 撤销本地仓库的 hotfix 最近一次的提交，并不保留本地工作目录未提交的内容 12git checkout hotfixgit reset --hard HEAD~1 撤销本地仓库的 hotfix 最近一次提交，但保留暂存区和工作目录中的内容 12git checkout hotfixgit reset --soft HEAD~1 file 粒度场景： 我在当前分支，修改了文件 test.txt，不小心将该文件 add 到了暂存区，怎样将该文件从暂存区中移除？ 本地仓库对于文件 A 有三个版本 version1, version2, version3，我想在第四次提交时，使用文件 A 的 version2，如何解决？ 通过 git reset filename 将文件加载到暂存区，然后重新 commit 即可。 123456789# 使用该命令，找到 `second` 那次提交的 SHA-1，比如是：3d825fgit log# 然后使用 git cat-file 等底层命令 找到 test.txt 的 SHA-1，比如是：6b42be# 将该文件的这个版本，加载到暂存区git reset 6b42be# 或者将上一次提交的那个版本加载到暂存区git reset HEAD~1 test.txt# 然后重新提交git commit git checkoutcommit 粒度git checkout 会切换 全局HEAD 到不同的分支/指定的 commit id，并且更新当前的 working directory 去匹配。因为会覆盖当前的本地更改，所以更换分支前git强制你彻底放弃或者提交存储当前的更改。不同于 git reset, git checkout 不会废弃任何分支或提交，且改粒度的 checkout，git 会提示你去解决冲突。 123456# 切换到分支 branch1git checkout branch1# 从当前分支切出并创建一个新的分支 newbranchgit checkout -b new branch# 切换到指定 commit id， 比如你想切换到 e14529 那次提交git checkout e14529 file 粒度git checkout filename 与 git reset 类似，只是前者会直接覆盖 working directroy 的相同文件，而后者只会同步到暂存区不会改变工作目录的内容。 比如：你想丢弃本地工作目录的 test.txt，然后使用本地仓库上一次提交的那个版本？ 1git checkout HEAD~1 test.txt git revertgit revert 撤销一个提交的同时会创建一个新的提交。这是一个安全的方法，因为它不会重写提交历史。比如，下面的命令会找出倒数第二个提交，然后创建一个新的提交来撤销这些更改，然后把这个提交加入项目中。 12git checkout hotfixgit revert HEAD~2 总结git reset 和 git checkout 一般针对个人分支，git revert 一般针对公共分支，因为后者的撤销操作是会保留之前的提交历史的。 command 作用域 应用场景 git reset commit 粒度 在私有分支上撤销一些已经 commit 的内容 git reset file 粒度 将文件的制定版本加载到暂存区，如暂存区中存在该文件，则将会被覆盖 git checkout commit 粒度 切换分支或查看旧版本 git checkout file 粒度 舍弃工作目录中的更改（直接覆盖本地的更改） git revert commit 粒度 在公共分支上回滚更改 git revert 无 无 参考链接 Resetting, Checking Out &amp; Reverting git reset, git checkout, git revert 区别 (译) Git-工具-重置揭密 附图 tips: Checkout and reset are generally used for making local or private ‘undos’.Revert is considered a safe operation for ‘public undos’.]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Git 内部原理]]></title>
    <url>%2Flanguages%2F37bfc11a.html</url>
    <content type="text"><![CDATA[git 三棵树：working directory（工作区）、staged snapshot（暂存区）、commit historygit 三个指针：全局HEAD、本地分支 HEAD（即本地分支名）、远程跟踪分支 HEAD(即远程分支名 默认为 origin/remoteBranchName) 其中，第一棵树是工作目录（包含隐藏 .git 文件夹的 OS 目录）中的文件和文件夹集合；第二棵树通常存储在.git 文件夹根目录中一个名为 index 的二进制文件中；第三棵树由代表 DAG 的 Git 对象组成，位于 .git\objects 中，也可以存储在 .git\objects\pack 的“包”文件中。 全局 HEAD 指针指向本地当前分支，可以通过 git checkout 修改 全局HEAD 的指向；本地分支HEAD 默认指向本地分支的最后一次提交，可以通过 git reset 命令修改 分支 HEAD 指向；另外 远程分支HEAD，是将远程仓库的分支 HEAD 下载到了本地，并以“远程跟踪分支”的形式存在。 Git 是内容可寻址文件系统，因此它管理的是名为 SHA-1 的 blob 对象，而不是文件。每个 blob 对象通常是由至少一个树对象引用，反过来树对象通常是由提交对象引用。最终，Git 树对象表示暂存的文件的文件夹结构。 四张图，理解 git 如何做版本管理。 .git 目录结构如下图： config: description: info: hooks: 剩下的四个条目很重要：HEAD 文件、（尚为生成的）index 文件，和 objects 目录、refs 目录。 objects: 目录存储所有数据内容 refs: 目录存储指向数据（分支）的提交对象的指针； HEAD: 文件指示目前被检出的分支； index: 文件保存暂存区信息 git 版本管理的基本流程Git 所做的实质工作：将被改写的文件保存为 数据对象 blob，更新暂存区，记录 树对象 tree，最后创建一个指明了顶层树对象和父提交的提交对象 commit。 这三种主要的 Git 对象——数据对象、树对象、提交对象——最初均以单独文件的形式保存在 .git/objects 目录下。 随着 git 对象的增多，git 会用 zlib库将对象打包到 ./git/objects/pack 目录下的 *.pack 和 *.idx 两个文件，Git 打包对象时，会查找命名及大小相近的文件，并只保存文件不同版本之间的差异内容，以节省存储空间。 当在一个新目录或已有目录执行 git init 时，Git 会创建一个 .git 目录。 这个目录包含了几乎所有 Git 存储和操作的对象。 如若想备份或复制一个版本库，只需把这个目录拷贝至另一处即可。该目录的结构如下所示： 假设对于下图的工作目录 supply-core，git 是如何对其进行版本库管理的，是如何记录它的每次提交？ 该工作目录的一级目录下有一个 文件夹、多个文件。 首先 git 会忽视路径，计算出所有文件的哈希值（一串40位的校验和），作为文件的key，并将文件转换为 blob 对象，存储在 .git/objects/ 目录下； 然后，会根据文件的目录结构，write-tree 转换成 tree 对象，也保存在 .git/objects/ 目录下； 然后，git 会将本次提交的所有信息生成一个 commit 对象，也保存在.git/objects/ 目录下，该 commit 对象包含了本次提交涉及的所有 blob 对象、tree 对象、提交信息等； 然后，git 会将最后一次提交的 commit 对象作为当前分支的指向，并用一个分支名，如：master，来指向该commit 对象，以方便记忆和 checkout； 同时，git 会将 HEAD 指向当前分支。 以上就是 git 版本管理一次提交的流程，所有的文件内容均保存在 blob 对象中，tree 对象的继承关系表征了文件的路径结构，commit 对象记录了本次提交的所有内容的引用。即用 blob 保存了文件、后两种对象只是引用。 几个问题下面通过几个问题，帮助理解 git 是如何通过 .git/ 目录下各个文件进行版本管理的。所有的数据内容均保存在 .git/objects/ 目录下，其它地方保存的只是引用。 克隆到本地的git项目是如何知道远程都有哪些分支？且远程的当前分支是哪个？ .git/refs/remotes/origin/ git 会在该目录下记录远程都有哪些分支，如下图：其中的 HEAD 文件，记录远程分支的当前分支。其文件内容如下：另外，当该项目若在服务器端被打包过，其远程分支的信息会被记录在 .git/packed-refs 文件中，其内容如下： 同样地，本地是如何知道都有哪些本地分支？且本地的当前分时又是哪个？ remotes 目录下记录远程分支的分支引用，heads 目录下记录本地分支的分支引用，如下：然后会在 .git/HEAD 文件中记录本地分支的当前分支 本地项目修改的文件是 add 到哪里？ 执行完 git add . 后，修改的内容会被放入 git 的暂存区，即.git/index 文件，该文件保存了所有add 到暂存区但尚未 commit 的文件。如下： git是如何保存本地项目的那些文件内容的？所有数据内容，均保存在了 .git/objects/ 目录下了，所以只要你commit 了代码，即使你不小心删除了分支，只要该目录下文件没有丢失，还是能够将数据恢复的，因为这里保存了文件的所有历史版本。 假设有个文件 A，被修改了3次，每次修改只是在修改了其中的一行代码，且分别做了3次提交，我们知道，git 会将3个版本的快照都保存到仓库中，那如何这个文件有20M，那岂不是会仅仅一个文件 A，由于历史版本过多，占用了很多存储空间？ 事实上，git 在项目还很小的时候，的确是按照快照完整保存的，但随着项目项目越来越大，git 会将这些数据文件（也就是 objects 目录下的文件进行用 zlib 库进行压缩打包，并且每个文件的每个版本并不再是保存完整版本，而是基于差异进行保存）。可以查看包文件，观察它是如何节省空间的。 git verify-pack 这个底层命令可以让你查看已打包的内容：此处，033b4 这个数据对象（即某个文件的第一个版本，如果你还记得的话）引用了数据对象 b042a，即该文件的第二个版本。 命令输出内容的 第三列 显示的是各个对象在包文件中的 大小，可以看到 b042a 占用了 22K 空间，而 033b4 仅占用 9 字节。 指的注意的是，第二个版本完整保存了文件内容，而原始的版本反而是以差异方式保存的——这是因为大部分情况下需要快速访问文件的最新版本。 另外，你可以随时重新打包。 Git 时常会自动对仓库进行重新打包以节省空间。当然你也可以随时手动执行 git gc 命令来这么做。（gc 是垃圾回收的意思） 底层命令1234567891011121314# hash-object 用于生成指定内容的 key(一个长度为40位的校验和)$ git hash-object -w test.txt# cat-file 读取出 object 里的内容，并返回内容的类型 blob/tree/commit$ git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4# update-index 将指定文件添加到暂存区$ git update-index --add --cacheinfo 100644 83baae61804e65cc73a7201a7252750c76066a30 test.txt# write-tree 将暂存区中的内容写入到一个树对象上$ git write-tree# read-tree 指定 --prefix 选项，将一个已有的树对象作为子树读入暂存区。即会创建一个该数的父树$ git read-tree --prefix=bak d8329fc1cc938780ffdd9f94e0d364e0ea74f579# commit-tree 创建一个提交对象$ git commit-tree d8329f# verify-pack 查看 objects 目录下的包文件$ git verify-pack 这个底层命令可以让你查看已打包的内容 参考链接 文件如何写入索引：参考 GIT科普系列5：index in git DevOps - Git 内部结构：体系结构和索引文件 git 版本管理的整体认识，参考该系列 10.1 Git 内部原理 - 底层命令和高层命令 10.2 Git 内部原理 - Git 对象 10.3 Git 内部原理 - Git 引用 10.4 Git 内部原理 - 包文件 10.5 Git 内部原理 - 引用规格 10.6 Git 内部原理 - 传输协议 10.7 Git 内部原理 - 维护与数据恢复 深入理解Git (五) － commit链的形成]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Linux 命令: 查看文件内容]]></title>
    <url>%2Flanguages%2F64d451f1.html</url>
    <content type="text"><![CDATA[Linux 查看文件内容的命令：cat, tac, more, less, head, tail, nl cat: 一次性显示整个文件的内容，从文件的第一行至最后一行 tac: 一次性显示整个文件的内容，从文件的最后一行至第一行 more: 分页显示文件内容，只支持向后翻页。当文件内容超过一屏的内容时，more 会将文件内容分页显示 less: 分页显示文件内容，支持向前/向后翻页。less 比 more 功能更强大。 head: 显示文件的前几行内容 tail: 显示文件最后几行的内容 nl: 等价于 cat -n cat 与 tac123456789[root @test /root ]# cat [-nAE] 参数说明： -n: 显示时，连行号印出屏幕上。 -A: 将 DOS 下的 &lt;tab&gt; 与断行字符都列出来！ -E: 将 DOS 编辑的文件中，仅列出 断行字符出来！ 范例： [root @test /root]# cat ~/.bashrc &lt;==显示 .bashrc 这个档案 [root @test /root]# cat ~/.bashrc -n &lt;==显示 .bashrc 内容并且加上行号！ tac 的使用与 cat 一样，只是显示的方式是文档从后向前的顺序展示。 more 与 less123范例： [root @test /root]# more ~/.bashrc &lt;==一页一页的显示档案内容 [root @test /]# ls -al | more &lt;==一页一页的将 ls 的内容显示出来 less 的使用与 more 一样，但less 的用法比起 more 又更加的有弹性。more 只支持向下翻页，less 支持向上/向下翻页，按键如下： less 向下翻页 向上翻页 一页 space（空格键） b（back） 半页 d u 一行 j k head 与 tail123456789[root @test /root ]# head [-n number] [檔名] 参数说明： -n ：显示 number 行 范例： [root @test /root]# head ~/.bashrc &lt;==预设情况下，显示头十行 [root @test /root]# head -n 20 ~/.bashrc &lt;==显示头二十行！范例：假如我想要显示 ~/.bashrc 的第 11 到第 20 行呢？[root @test /root]# head –n 20 ~/.bashrc | tail –n 10 &lt;==那么我取前 20 行，再取后十行，里面涉及到管线命令。 nl1[root @test /root]# nl ~/.bashrc &lt;==可以印出行号，等价于 cat -n 参考链接 linux 查看文件内容的命令]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@用 GitHub 托管本地代码（MAC）]]></title>
    <url>%2Fmanual%2F7a97ce34.html</url>
    <content type="text"><![CDATA[本文包括以下内容： 如何在本地安装 git 如何实现本机与 github 的 SSH 认证登录（即代码提交时，无需输入 github 密码） Git 的常用命令 install git step1: install Xcode command-line tools 1xcode-select --install 另外，也可以直接安装 Xcode 软件。 step2: install homebrew 如何安装请参考该文：@HomeBrew 的安装与使用 step3: install git with homebrew 1brew install git 设置 SSH Keystep1: 注册Github 账号 step2: 创建公私钥，参考这篇文章(@SSH远程登录的实现) step3: 设置 SSH Key(在GitHub中添加公钥） 在本机连接 Github 上已有的仓库，是通过使用 SSH 方式认证的(不了解SSH的，可参考“SSH原理与运用—阮一峰”)。 执行下面的命令将公钥中的内容复制到剪贴板 1$ pbcopy &lt; ~/.ssh/id_rsa.pub 进入 Github 账号设置页，添加 SSH Key 至此，你便可以将项目提交到 github 上了。 git 常用命令下面列出了日常经常会用到的一些 git 指令。另外，可参考(“@git 命令详解”)，了解git的更多操作。 12345678910111213141516171819# 将项目克隆岛本地git clone 远程仓库的地址# 在本地创建新的分支git checkout -b YourBranchName# 将本地代码同步到远程仓库同名分支（）git add .git commit -m '对本次更改的内容做个备注'git push --set-upstream origin 远程分支名 # 第一次 push 时，可以指定本地分支绑定远程的某个分支git push # 之后只需直接 push，就会默认同步到远程同名分支# 更新本地仓库，使本地仓库保持最新（与远程仓库除本分支外保持一致）git fetch origin # 默认取回远程所有分支的更新git fetch origin branchname #取回远程指定分支的更新# 将远程分支与本地分支合并git pull origin remoteBranchName:localBranchName # 将远程分支与本地分支合并git pull origin remoteBranchName # 远程分支与当前分支合并 参考链接 Git远程操作详解—阮一峰]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@HomeBrew 的安装与使用]]></title>
    <url>%2Fmanual%2F36d45381.html</url>
    <content type="text"><![CDATA[介绍Homebrew官网 Homebrew 是 Mac OSX上的软件包管理工具，能在Mac中方便的安装软件或者卸载软件，相当于linux下的apt-get、yum神器；Homebrew 可以在 Mac上安装一些OS X没有的UNIX工具，Homebrew 将这些工具统统安装到了 /usr/local/Cellar 目录中，并在 /usr/local/bin 中创建符号链接。 安装Homebrew 的安装非常简单，只需在 terminal 输入一串指令即可完成安装。 step1: 安装 homebrew1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Homebrew安装成功后，会自动创建目录 /usr/local/Cellar 来存放Homebrew安装的程序。 这时你在命令行状态下面就可以使用 brew 命令了. 注意：如果在安装过程中返回400，可以在几分钟后尝试重新安装。 检查homebrew 是否安装成功 1brew doctor 日常使用 显示通过 homebrew 已安装的软件：brew list 查看软件信息：brew info／home 软件名 。如： 1234# 在 terminal 显示该软件的安装位置、来源、依赖的包等软件信息brew info git# 在 浏览器 中打开该软件的官网，brew home git 查看哪些已安装的程序需要更新： brew outdated 更新具体软件：brew upgrade 软件名 。例：brew upgrade git 显示包依赖：brew deps]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@JavaWeb: 从零开始写 Java Web 框架]]></title>
    <url>%2Fmanual%2Ffa02af02.html</url>
    <content type="text"><![CDATA[目标： 搭建一个轻量级的 MVC 框架。 如何快速搭建开发框架 如何加载并读取配置文件 如何实现一个简单的 IOC 容器 如何加载指定的类 如何初始化框架 Controller 是 MVC 的核心，一个Controller类包含了多个Action 方法，可返回 View 对象或 Data 对象，分别对应 JSP 页面和 JSON 数据。在普通请求的情况下，可返回 JSP 页面，在 Ajax 请求的情况下，可返回 JSON 数据。 搭建开发环境 既然是一款 JavaWeb 框架，需要添加依赖 Servlet、JSP、JSTL 在框架中会大量使用日志输出，需要添加SLF4J的日志框架 由于涉及到mysql数据库，需要添加一个 mysql 的 Java驱动程序所对应的依赖 由于在 Controller 的 Action方法返回值中是可以返回 JSON 数据的，需要选择一款JSON 序列化工具 还需要添加一些常用的工具类，诸如数据类型转换、集合类判空等 每次对数据库的操作，都需要面对PreparedStatement 和ResultSet，为了减少这部分代码的编写，需要添加一个 DBUTILS 每次对数据库的操作，都需要创建一个connection，并在操作完成后，关闭数据库连接，频繁的这种操作，必定会造成大量的系统开销，而且数据库的连接数是有限的，需要添加数据库连接池框架 DBCP Service 编写好后，要进行单元测试，需要添加 JUNIT 依赖 上面提到的所有依赖，见下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;dependencies&gt; &lt;!-- Servlet --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;$&#123;servlet.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- JSP --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- JSTL --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--SLF4J--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;!--MySQL--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.33&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Apache Commons Lang--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Apache Commons Collections--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-collections4&lt;/artifactId&gt; &lt;version&gt;4.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--Apache Commons DbUtils--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbutils&lt;/groupId&gt; &lt;artifactId&gt;commons-dbutils&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;/dependency&gt; &lt;!--Apache Commons Dbcp2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp2&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 如何加载并读取配置文件？如何加载并读取在/src/main/resources 目录下的诸如*.properties的配置文件，配置文件中的内容一般如下： 12345678rt.framework.jdbc.driver=com.mysql.jdbc.Driversmart.framework.jdbc.url=jdbc:mysql://localhost:3306/demosmart.framework.jdbc.username=rootsmart.framework.jdbc.password=30131234smart.framework.app.base_package=com.seyvoue.demo.chapter3smart.framework.app.jsp_path=/WEB-INF/view/smart.framework.app.asset_path=/asset/ 注：`.properties` 文件中的内容是 key=value 的形式* step1：首先创建一个 ConfigConstant 的常量类，用来维护*.properties文件中相关配置项的名称（即 key） step2：然后创建一个 PropsUtil 工具类用来读取该配置文件（这个工具类依赖 java.util.Properties） step3：创建 ConfigHelper 通过 PropsUtil 工具类加载配置文件 如何开发一个类加载器如何开发一个“类加载器”加载某基础包下的所有类，比如使用了某注解的类、或者实现了某接口的类等。故需要创建一个 ClassUtil 工具类，提供与类操作相关的方法。 step1: 获取类加载器step2：加载类step3：获取指定包名下的所有类]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: 类型转换]]></title>
    <url>%2Flanguages%2F720c153b.html</url>
    <content type="text"><![CDATA[Java中数据类型主要分为两大类：基本数据类型和引用数据类型： 基本数据类型：布尔型 boolean、字符型 char、数值型 byte/short/int/long/float/double 引用数据类型：数组、类、接口 Java两种类型转换方式： 自动类型转换 强制类型转换 基本数据类型的类型转换基本数据类型转换原则类型转换 主要发生在 赋值、方法调用、算术运算 三种情况下发生。 赋值和方法调用 转换规则：从低位类型到高位类型自动转换；从高位类型到低位类型需要强制类型转换。 算术运算 中的类型转换：基本就是先转换为高位数据类型，再参加运算，结果也是最高位的数据类型；byte short char运算会转换为Int。 在Java中，整数类型（byte/short/int/long）中，对于未声明数据类型的整型，其默认类型为int型。在浮点类型（float/double）中，对于未声明数据类型的浮点型，默认为double型。 boolean类型与其他基本类型不能进行类型的转换（既不能进行自动类型的提升，也不能强制类型转换）， 否则，将编译出错。 123byte a = 1000; // 编译出错 Type mismatch: cannot convert from int to bytefloat b = 1.5; // 编译出错 Type mismatch: cannot convert from double to floatbyte c = 3; // 编译正确 3虽然是 int 型，但由于数值很小，JVM 会自动对其进行隐式的类型转换，将其从 int-&gt;byte 自动类型转换 当将一个数值范围小的类型赋给一个数值范围大的数值型变量，JVM 在编译过程中会将此数值的类型进行自动提升。在数值类型的自动类型提升过程中，数值精度至少不应该降低（整型保持不变，float-&gt;double精度将变高）。 下图所示箭头左边的数值类型可以自动类型转换为箭头右边的数值类型。 12long a = 10000000000; //编译出错: 10000000000 默认为 int 型，超过了 int 的最大值，故报错long b = 10000000000L; 当把任何基本类型的值和字符串进行连接运算时，基本类型的值将自动转换为字符串类型。 因此，如果希望把基本类型的值转换为对应的字符串时，可以把一个基本类型的值和一个空字符串进行连接。 1234567// 这行代码是错的，因为5是一个整数，不能直接赋值给一个字符串String str1 = 5;// 将输出 7HelloSystem.out.println(3+4+"Hello");// 将输出 Hello34System.out.println("Hello"+3+4); 强制类型转换 当我们需要将数值范围较大的数值类型赋给数值范围较小的数值类型变量时，由于此时可能会丢失精度，因此，需要人为进行转换。我们称之为强制类型转换，即“缩小转换”。 1234567891011121314151617byte p =3; //编译正确:int到byte编译过程中发生隐式类型转换int a = 3;byte b = a; //编译出错：cannot convert from int to byte。区别在于前者3是直接量，编译期间可以直接进行判定，后者a为一变量，需要到运行期间才能确定，也就是说，编译期间为以防万一，当然不可能编译通过了。此时，需要进行强制类型转换。byte c = (byte)a; //编译正确int iValue = 233;// 强制把一个 int 转换为 bytebyte bValue = (byte)iValue;System.out.println(bValue); // 将输出 -23double dValue = 3.98;// 强制将一个 double 转换为 intint dol = (int)dValue;System.out.println(dol); // 将输出 3// 直接将5.6复制给一个float类型变量时将会报错。以为5.6默认是 double 类型。float a = 5.6; 在上面程序中，把一个浮点数强制类型转换为整数时，Java 将直接截断浮点数的小数部分。除此之外，上面程序还把 233 强制类型转换为 byte 类型的整数，从而变成了 -23, 这就是典型的溢出。下图示范了这个转换过程。 进行数学运算时，整个算数表达式的数据类型将发生自动提升。 12345678byte a = 3 + 5; // 编译正常 编译成 3+5直接变为8，8 为 int 型，JVM 隐式转换 int-&gt;byteint b = 3, c = 5;byte d = b + c; // 编译错误：b+c 不是直接量，b+c 为 int，JVM 不会进行隐式转换，故需要人为强转byte dd = (byte)(b+c); //编译正确byte e = 10, f = 11;byte g = e + f; // 编译错误 e+f 后，类型自动从 byte 提升到了 int，需要强转byte h = (byte) (e + f); //编译正确 引用数据类型的类型转换引用数据类型 转换原则 基本类型 与 对应包装类 可自动转换，这是自动装箱和折箱的原理； 两个引用类型间转换：子类能直接转换为父类 或 接口类型；父类转换为子类要 强制类型转换；且在运行时若实际不是对应的对象，会抛出ClassCastException运行时异常； 向上转型（自动类型转换）向下转型（强制类型转换）Java数据类型在内存中的存储 基本数据类型的存储原理d所有的简单数据类型不存在“引用”的概念，基本数据类型 都是直接存储在内存中的内存栈上的，数据本身的值就是存储在栈空间里面，而Java语言里面八种数据类型是这种存储模型； 引用类型的存储原理 引用数据类型 继承于Object类（也是引用类型）都是按照Java里面存储对象的内存模型来进行数据存储的，使用Java内存堆和内存栈来进行这种类型的数据存储，简单地讲，“引用”是存储在有序的内存栈上的，而对象本身的值存储在内存堆上的； 区别:基本数据类型和引用类型的区别主要在于基本数据类型是分配在栈上的，而引用类型是分配在堆上的（需要java中的栈、堆概念） 参考链接 java提高篇(十一)——-强制类型转换 Java总结篇系列：类型转换/造型 Java数据类型 及 转换原则 @Java 基础扫盲——直接量]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@JAVA基础: 类加载机制与反射]]></title>
    <url>%2Flanguages%2F377ffef3.html</url>
    <content type="text"><![CDATA[当调用 Java 命令运行某个 Java 程序时，该命令会启动一个 Java 虚拟机进程，不管该 Java 程序有多么复杂，该 Java 程序启动了多少个线程，它们都处于该 Java 虚拟机进程里，同一个 JVM 的所有线程、所有变量都在都处于同一个进程，它们都是用该 JVM 进程的内存区。两个 JVM 之间并不会共享数据。 当系统出现以下情况时，JVM 进程将被终止： 程序运行到最后正常结束 程序运行到使用 System.exit() 或 Runtime.getRuntime().exit()代码处结束进程 程序执行过程中遇到未捕获的异常或错误而结束 程序所在平台强制结束了 JVM 进程 类的加载、连接和初始化当程序主动使用某个类时，如果该类还未被加载到内存中，则系统会通过 加载、连接、初始 三个步骤来dUI 该类进行初始化，若不出意外，JVM 会连续完成这三个步骤，这三个步骤统称为 “类加载/类初始化”。 JVM 初始化一个类包含以下步骤： 若这个类没有被加载和连接，则程序先加载并连接该类 若该类的直接父类没有被初始化，则先初始化其直接父类 若类中又初始化语句，则系统依次执行这些初始化语句 （所以 JVM 最先初始化的总是 java.lang.Object 类） 类的加载类加载指的是将类的 class 文件读入内存，并为之创建一个 java.lang.Class 对象。 类的加载由类加载器完成，类加载器通常由 JVM 提供，JVM 提供的这些类加载器 —— 即 系统类加载器。开发者可通过继承 java.lang.ClassLoader 基类来创建自己的类加载器。 通过使用不同的类加载器，可以从不同来源加载类的二进制数据，通常有如下几种来源： 从本地文件系统加载 *.class 文件 从 JAR 包加载 class 文件 通过网络加载 class 文件 把一个 Java 源文件（即 *.java文件）动态编译，并执行加载 类加载器通常无需等到“首次使用”该类时才会加载该类，JVM规范允许虚拟机预先加载某些类。 类的连接连接阶段负责把“加载阶段”生成的二进制数据合并到 JRE 中，类连接又分为如下三个阶段： 验证：校验被加载的类是否有正确的内部结构 准备：为类的类变量分配内存，并设置默认初始值 解析：将类的二进制数据中的符号引用转化为直接引用 类的初始化在类的初始化阶段，主要是负责对类变量进行初始化。 类变量的初始化有两种方式： 声明类变量时指定初始值 使用静态初始化块指定初始值 宏变量和静态变量的区别？当某个类变量（也叫静态变量）使用了 final 修饰，而且他的值可以在编译时被确定下来（这样的类变量即 宏变量），那么程序其它地方使用该类变量时，实际上并没有使用该类变量，而是相当于使用常量，编译器会在编译时，在用到该变量的地方直接替换成该变量的值，故，不需要进行类的初始化即可访问其类变量。 类加载器如何定位一个类？在 Java 中，一个类用其全限定类名（包名和类名）作为标识；在 JVM 中，一个类用 全限定类名+类加载器 作为其唯一标识。 当 JVM 启动时，会形成由三个类加载器组成的初始类加载器层次结构： Bootstrap ClassLoader: 根类加载器。负责加载 Java 的核心库(如$JAVA_HOME/jdk1.8.0_05/jre/lib/rt.jar) Extension ClassLoader: 扩展类加载器。负责加载 JRE 的扩展类库(如$JAVA_HOME/jdk1.8.0_05/jre/lib/ext/...) System ClassLoader: 系统类加载器。负责在 JVM 启动时加载来自 Java 命令的 -classpath… 类加载器之间的父子关系并不是继承上的父子关系，这里的父子关系是类加载器实例之间的关系。如下： JVM 的根类加载器并不是 JAVA 实现的，JVM 中除根类加载器之外的所有类加载器都是 ClassLoader 子类的实例，开发者可通过继承 ClassLoader 类，并重写其中的 loadClass(String name, boolean resolve) 或 findClass(String name)来自定义类加载器。 反射通过反射查看类信息Java 程序的许多对象在运行时都会出现两种类型：编译时类型和运行时类型，例如：Person p = new Student();,这行代码的 p 变量，在编译时类型为 Person，运行时类型为 Student，为了解决这个问题，程序需要在运行时发现对象和类的真实信息。 step1: 获得 Class 对象step2: 从 Class 中获取信息 获得构造器 获得方法 获得成员变量 获得注解 获得内部类 该 Class 对象所对应类的修饰符、所在包、类名等信息 判断该类是否为借口、枚举、注解类型等 使用反射生成并操作对象通过反射创建对象有两种方式： 使用 Class 对象的 newInstance() 方法来创建该 Class 对象所对应类的实例。该方式要求该 Class 对象的对应类有默认构造器。 先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance() 方法 来创建该 Class 对象所对应类的实例。该方式可以自己选择使用哪个构造器创建实例。 java.lang.reflect 包下还提供了 Array 类，Array 对象可以代表所有的数组，程序可以通过s 会用 Array 来动态地创建数组，操作数组元素。 参考 李刚.疯狂Java讲义 第3版.北京：电子工业出版社,2014.07.]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Java 基础: Lambda 表达式]]></title>
    <url>%2Flanguages%2F73ff6742.html</url>
    <content type="text"><![CDATA[虽然看着很先进，其实 Lambda 表达式的本质只是一个“语法糖”,由编译器推断并帮你转换包装为&gt;规的代码,因此你可以使用更少的代码来实现同样的功能。 Lambda 表达式是 Java8 中一个重要的新特性。Lambda 表达式允许你通过表达式来代替功能接口。 Lambda 表达式就和方法一样,它提供了一个正常的参数列表和一个使用这些参数的主体(body,可以是一个表达式或一个代码块)。 Lambda 表达式还增强了集合库。 Java8 添加了2个对集合数据进行批量操作的包：java.util.function 包以及 java.util.stream 包。 流(stream)就如同迭代器 iterator，但附加了许多额外的功能。 总的来说，lambda 表达式和 stream 是自 Java 语言添加泛型(Generics)和注解(annotation)以来最大的变化。 Lambda 基础为什么使用 Lambda 表达式？Lambda 是一个匿名函数，我们可以把 Lambda表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，使Java的语言表达能力得到了提升。 从匿名内部类到 Lambda 表达式的转换: 12345678910// 匿名内部类Runnable r1 = new Runnlable()&#123; @Override public void run()&#123; System.out.println("Hello World!"); &#125;&#125;;// Lambda 表达式Runnable r1 = () -&gt; System.out.println("Hello World!"); Lambda 表达式作为参数传递:为了将 Lambda 表达式作为参数传递，接收 Lambda 表达式的参数类型必须是与该 Lambda 表达式兼容的函数式接口的类型。 12String newStr = toUpperString(str -&gt; str.toUpperString(), "abcdefg");System.out.println(newStr); 函数式接口 只包含一个抽象方法的接口，称为函数式接口。 可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda表达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。 可以在任意函数式接口上使用 @FunctionalInterface 注解，这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口。 1234@FunctionalInterfacepublic interface MyFun&lt;T&gt;&#123; public T getValue(T t);&#125; Labmda 的语法Lambda 表达式在 Java 语言中引入了一个新的语法元素和操作符。这个操作符为 -&gt; ， 该操作符被称为Lambda 操作符或箭头操作符。它将 Lambda 分为两个部分： 左侧：指定了 Lambda 表达式需要的所有操作符 右侧：指定了 Lambda 体，即 Labmda 表达式要执行的功能。 Lambda 表达式返回的是一个对象(所以实现Lambda表达式就是实现了匿名内部类)，他们必须依附于一类特别的对象类型——函数式接口。 基本语法： (parameters) -&gt; expression (parameters) -&gt; { statements; } 语法格式一：无参，无返回值，Lambda 只有一条语句，花括号可以省略 1Runnable r1 = () -&gt; System.out.println("Hello Lambda!"); 语法格式二：一个形参，无返回值 1Consumer&lt;String&gt; fun = (args) -&gt; System.out.println(args); 语法格式三：一个形参，无返回值，参数的小括号可以省略 1Consumer&lt;String&gt; fun = args -&gt; System.out.println(args); 语法格式四：两个形参，有返回值 1234BinaryOperator&lt;Long&gt; bo = (Long x, Long y) -&gt; &#123; System.out.println("实现函数接口方法。"); return x+y;&#125;; 语法格式五：形参数据类型可以省略，由编译器根据上下文进行“类型推断” 1234BinaryOperator&lt;Long&gt; bo = (x,y) -&gt; &#123; System.out.println("实现函数接口方法。"); return x+y;&#125;; 语法格式六：两个形参，有返回值，Lambda 体只有一条语句，花括号可以省略，return 可以省略 1BinaryOperator&lt;Long&gt; bo = (x,y) -&gt; return x+y; 总结 一个参数，括号可以省 一条语句{}可以省 一条语句，return可以省 参数类型可以省略 实战lambda表达式可以将我们的代码缩减到一行。 实战一：遍历 List 1234567891011121314151617String[] atp = &#123;"Rafael Nadal", "Novak Djokovic", "Stanislas Wawrinka", "David Ferrer","Roger Federer", "Andy Murray","Tomas Berdych", "Juan Martin Del Potro"&#125;; List&lt;String&gt; players = Arrays.asList(atp); // 以前的循环方式 for (String player : players) &#123; System.out.print(player + "; "); &#125; // 使用 lambda 表达式以及函数操作(functional operation) players.forEach((player) -&gt; System.out.print(player + "; ")); // 在 Java 8 中使用双冒号操作符(double colon operator) players.forEach(System.out::println); 实战二：使用 Lambda 表达式来实现 Runnable接口 12345678910111213141516171819202122232425// 使用匿名内部类实现new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("Hello world !"); &#125; &#125;).start(); // 使用 Lambda 表达式new Thread(() -&gt; System.out.println("Hello world !")).start(); // 使用匿名内部类 Runnable race1 = new Runnable() &#123; @Override public void run() &#123; System.out.println("Hello world !"); &#125; &#125;; // 使用 lambda 表达式 Runnable race2 = () -&gt; System.out.println("Hello world !"); // 直接调用 run 方法(没开新线程哦!) race1.run(); race2.run(); 实战三：使用 Lambda 表达式 和 Stream Stream是对集合的包装,通常和lambda一起使用。 使用lambdas可以支持许多操作,如 map, filter, limit, sorted, count, min, max, sum, collect 等等。 同样,Stream使用懒运算,他们并不会真正地读取所有数据,遇到像getFirst() 这样的方法就会结束链式语法。 下面这个例子中：我们创建了一个Person类并使用这个类来添加一些数据到 list 中,将用于进一步流操作。 创建一个 Person 类 1234567891011121314151617public class Person &#123; private String firstName, lastName, job, gender; private int salary, age; public Person(String firstName, String lastName, String job, String gender, int age, int salary) &#123; this.firstName = firstName; this.lastName = lastName; this.gender = gender; this.age = age; this.job = job; this.salary = salary; &#125; // Getter and Setter // . . . . . &#125; 创建两个list,都用来存放Person对象 1234567891011121314151617181920212223242526272829List&lt;Person&gt; javaProgrammers = new ArrayList&lt;Person&gt;() &#123; &#123; add(new Person("Elsdon", "Jaycob", "Java programmer", "male", 43, 2000)); add(new Person("Tamsen", "Brittany", "Java programmer", "female", 23, 1500)); add(new Person("Floyd", "Donny", "Java programmer", "male", 33, 1800)); add(new Person("Sindy", "Jonie", "Java programmer", "female", 32, 1600)); add(new Person("Vere", "Hervey", "Java programmer", "male", 22, 1200)); add(new Person("Maude", "Jaimie", "Java programmer", "female", 27, 1900)); add(new Person("Shawn", "Randall", "Java programmer", "male", 30, 2300)); add(new Person("Jayden", "Corrina", "Java programmer", "female", 35, 1700)); add(new Person("Palmer", "Dene", "Java programmer", "male", 33, 2000)); add(new Person("Addison", "Pam", "Java programmer", "female", 34, 1300)); &#125; &#125;; List&lt;Person&gt; phpProgrammers = new ArrayList&lt;Person&gt;() &#123; &#123; add(new Person("Jarrod", "Pace", "PHP programmer", "male", 34, 1550)); add(new Person("Clarette", "Cicely", "PHP programmer", "female", 23, 1200)); add(new Person("Victor", "Channing", "PHP programmer", "male", 32, 1600)); add(new Person("Tori", "Sheryl", "PHP programmer", "female", 21, 1000)); add(new Person("Osborne", "Shad", "PHP programmer", "male", 32, 1100)); add(new Person("Rosalind", "Layla", "PHP programmer", "female", 25, 1300)); add(new Person("Fraser", "Hewie", "PHP programmer", "male", 36, 1100)); add(new Person("Quinn", "Tamara", "PHP programmer", "female", 21, 1000)); add(new Person("Alvin", "Lance", "PHP programmer", "male", 38, 1600)); add(new Person("Evonne", "Shari", "PHP programmer", "female", 40, 1800)); &#125; &#125;; 使用forEach方法来迭代输出上述列表: 123System.out.println("所有程序员的姓名:"); javaProgrammers.forEach((p) -&gt; System.out.printf("%s %s; ", p.getFirstName(), p.getLastName())); phpProgrammers.forEach((p) -&gt; System.out.printf("%s %s; ", p.getFirstName(), p.getLastName())); 过滤器filter() ,让我们显示指定筛选条件的程序员 123456789101112131415161718// 定义 filters Predicate&lt;Person&gt; ageFilter = (p) -&gt; (p.getAge() &gt; 25); Predicate&lt;Person&gt; salaryFilter = (p) -&gt; (p.getSalary() &gt; 1400); Predicate&lt;Person&gt; genderFilter = (p) -&gt; ("female".equals(p.getGender())); System.out.println("下面是年龄大于 24岁且月薪在$1,400以上的女PHP程序员:"); phpProgrammers.stream() .filter(ageFilter) .filter(salaryFilter) .filter(genderFilter) .forEach((p) -&gt; System.out.printf("%s %s; ", p.getFirstName(), p.getLastName())); // 重用filters System.out.println("年龄大于 24岁的女性 Java programmers:"); javaProgrammers.stream() .filter(ageFilter) .filter(genderFilter) .forEach((p) -&gt; System.out.printf("%s %s; ", p.getFirstName(), p.getLastName())); 参考 Java Lambda表达式入门]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@JAVA基础: 枚举类]]></title>
    <url>%2Flanguages%2F6f104900.html</url>
    <content type="text"><![CDATA[一个类的对象是有限且固定的，如：季节类，它只有4个对象；行星类，只有9个对象。 虽然可以使用静态变量来表示（如下），但会存在一些问题： 类型不安全：因为上面的每个季节实际上是一个 int 整数，因此完全可以把一个季节当成一个 int 整数使用，例如进行加法运算 SEASON SPRING + SEASON SUMMER，这样的代码完全正常。 没有命名空间：当需要使用季节时，必须在 SPRING 前使用 SEASON 前缀，否则程序可能与其他类中的静态常量混淆。 打印输出的意义不明确：当输出某个季节时，例如输出 SEASON SPRING，实际上输出的是 1, 这个 1 很难猜测它代表了春天。 1234public static final int SEASON_SPRING = 1;public static final int SEASON_SUMMER = 2;public static final int SEASON_FALL = 3;public static final int SEASON_WINTER = 4; 枚举类与普通类的区别： 枚举类默认集成了 java.lang.Enum 类，而不是 Object 类 非抽象的枚举类不能被继承 枚举类的构造器只能使用 private 修饰符，若构造器省略修饰符，则默认为 private 枚举类的所有实例必须在枚举类的第一行显式列出，否则这个枚举类永远都不能产生实例。列出这些实例后，系统会自动为其添上 pulic static final 修饰符，无需程序员显式添加。 （注：枚举类的枚举值是个实例，即对象，而不是值） 枚举类的创建枚举类也是类，故同样可以在枚举类中定义成员变量、方法等，亦可以实现一个或多个接口。定义枚举类时，需要显式的列出所有枚举值，所有的枚举值之间用,隔开，枚举值列举结束后用;结束，这些枚举值代表了该枚举类的所有可能的实例。 若枚举类中定义了抽象方法，则系统会默认为该枚举类添加 abstract 关键字，而使其成为抽象枚举类，无需程序员手动添加 abstract（也不允许使用 abstract 关键字修饰枚举类） 123456789101112131415161718192021222324252627282930313233public interface GenderDesc&#123; public void info();&#125;public enum Gender implements GenderDesc &#123; // 在第一行列出2个枚举实例 MALE,FEMALE; private final String name; // 枚举类的构造器必须要私有的 private Gender(String name)&#123; this.name = name; &#125; public String getName()&#123; return this.name; &#125; // 可以直接实现接口的方法，但若想对每个枚举值分别实现，则应该采取类似于匿名内部类的形式 MALE(“男”)&#123; public void info()&#123; System.out.println("这个枚举值代表男性"); &#125; &#125;, FEMALE(“女”)&#123; public void info()&#123; System.out.println("这个枚举值代表女性"); &#125; &#125; &#125; 枚举类的使用 编译上面的文件，将会看到生成Gender.class, Gender$1.class,Gender$2.class三个文件，这样的三个 class 文件表明，MALE 和 FEMALE 实际是 Gender匿名子类的实例，而不是Gender 类的实例。 12// 通过 ENUM 类的 valueOf() 方法获得指定枚举类的枚举值SEASONENUM seasonEnum = ENUM.valueOf(SEASONENUM.class, SPRING);]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@JAVA基础: 异常处理]]></title>
    <url>%2Flanguages%2Fbe4602f2.html</url>
    <content type="text"><![CDATA[异常机制可以保证程序中的异常处理代码和正常业务代码分离，保证程序代码更加优雅，并可以提高程序的健壮性。 概述Java 的异常机制主要依赖于try, catch, finally, throw, throws五个关键字。 try 关键字后紧跟一个花括号括起来的代码块，它里面放置可能引发异常的代码； catch 后对应异常类型和代码块，用于表明该 catch 块用于处理这种类型的代码块； 多个 catch 块后还可跟一个 finally块，finally 块用于回收在 try 块里打开的物理资源，异常机制会保证 finally块总被执行； throws 关键字主要在方法签名后使用，用于声明该方法可能会抛出的异常； 而 throw 可以单独作为语句使用，抛出一个具体的异常。 Java 的异常处理机制让程序具有更好的容错性，当程序出现意外情形时，系统会自动生成一个 Exception 对象来通知程序，通过在 try 块后添加多个 catch 块可以无需在处理快中使用 if、swich 判断异常类型，但依然可以针对不同的异常类型提供相应的处理逻辑，从而提供更细致、更有条理的异常处理逻辑。 如果执行 try 块里的业务逻辑代码时出现异常，系统自动生成一个异常对象，该异常对象被提交给 Java 运行时环境，这个过程被称为抛出（throw）异常。 当 Java 运行时环境收到异常对象时，会寻找能处理该异常对象的 catch 块，如果找到合适的 catch 块，则把该异常对象交给该 catch 块处理，这个过程被称为捕获（catch）异常；如果 Java 运行时环境找不到捕获异常的 catch 块，则运行时环境终止，Java 程序也将退出。 注：try 块里声明的变量是代码块内局部变量，它只在 try 块内有效，在 catch 块中无法访问该变量。 Java 异常捕获流程示意图如下： 一个异常捕获例子：（注：从 Java7开始，一个 catch 块可以捕获多种类型的异常） 12345678910111213141516171819202122Public class DivTest&#123; public static void main(String[] args)&#123; try&#123; int a = Integer. ParseInt (args [0]); int b = Integer. ParseInt (args [1]); int c = a/b; System.out.println("您输入的两个数相除的结果是：" + c); &#125;catch (IndexOutOfBoundsException | NumberFormatException | ArithmenticException ie)&#123; System.out.println("程序发生了数组越界、数字格式异常、算数异常之一"); //捕获多种异常时，异常变量默认有 finally 修饰符 //所以下面代码有误 ie = new ArithementicException("test"); &#125;catch (Exception e)&#123; System.out.println("未知异常"); //捕获一种异常时，异常变量没有 finally 修饰符 //所以下面代码完全正确 e = new RuntimeException("test"); &#125; &#125;&#125; 异常分类 这是一个简化的Java异常层次结构示意图，需要注意的是所有的类都是从Throwable继承而来，下一层则分为两个结构，Error和Exception。其中Error类层次描述了Java运行时系统的内部错误和资源耗尽错误，这种错误除了简单的报告给用户，并尽力阻止程序安全终止之外，一般也米有别的解决办法了。 Checked 异常和 Unchecked 异常区别？派生于Error或者RuntimeException的异常称为unchecked异常，所有其他的异常成为checked异常。Checked异常必须被显式地捕获或者传递，而unchecked异常则可以不必捕获或抛出。 在设计 Java 程序时，需要关注 Exception 层次结构。其又派生出两个分支，一个分支是 RuntimeException；另一个分支包含其他异常。划分两个分支的规则是：由程序错误导致的异常属于 RuntimeException；而程序本身没有问题，但由于像 I/O 错误这类问题导致的异常属于其他异常 派生于 RuntimeException 的异常包含下面几种情况： 错误的类型转换。 数组访问越界。 访问 null 指针。 不是派生于 RuntimeException 的异常包括： 试图在文件尾部后面读取数据。 试图打开一个不存在的文件。 试图根据给定的字符串查找 Class 对象，而这个字符串表示的类并不存在。 “如果出现 RuntimeException 异常，那么就一定是你的问题”是一条相当有道理的规则。应该通过检测数组下标是否越界来避免 ArrayIndexOutOfBoundsException 异常；应该通过在使用变量之前检测是否为 null 来杜绝 NullPointerException 异常的发生。 如何处理不存在的文件呢？难道不能先检查文件是否存在再打开它吗？嗯，这个文件有可能在你检查它是否存在之前就已经被删除了。因此，“是否存在”取决于环境，而不只是取决于你的代码。 Java 语言规范将派生于 Error 类或 RuntimeException 类的所有异常称为非受查（unchecked）异常，所有其他的异常称为受查（checked）异常，这是两个很有用的术语。编译器将核查是否为所有的受查异常提供了异常处理器。如果程序没有处理Checked 异常，该程序在编译时就会报错，将无法通过编译。 简单来说，Checked 异常未处理，编译时就会报错，而 Runtime 异常未处理在编译阶段是不会被发现的，只有在运行时才会被发现。 捕获异常如果某个异常发生的时候没有任何地方进行捕获，那程序就会终止执行，并在控制台上打印出异常信息，其中包括异常的类型和堆栈的内容。 当 Java 运行时决定调用某个 catch 块来处理该异常对象时，会将异常对象赋给 catch 块后的异常形参，程序可通过该参数来获得异常的相关信息。所有的异常对象都包含了如下几个常用方法： e.getMessage()：返回该异常的详细描述字符串。 e.getClass().getName()：得到详细的错误信息 e.getCause()：重新得到原始异常 e.printStackTrace()：将该异常的跟踪栈信息输出到标准错误输出。 e.printStackTrace(PrintStream s)：将该异常的跟踪栈信息输出到指定输出流。 e.getStackTrace()：返回该异常的跟踪栈信息。会得到 StackTraceElement 对象的一个数组，可以在程序中分析这个对象数组 使用 finally 回收物理资源程序在 try 块里打开了一些物理资源（如数据库连接、网络连接和磁盘文件等），这些物理资源都必须显式回收。Java 的垃圾回收机制不会回收任何物理资源，垃圾回收机制只会回收堆内存中对象所占用的内存。 为了保证一定能回收 try 块中打开的资源，异常处理机制提供了 finally 块，不管 try 块中的代码是否出现异常，也不管那一个 catch 块被执行，甚至 try 块或 catch 块中执行了 return 语句，finally 块总会被执行。 在通常情况下，不要在 finally 块中使用 return 或 throw 等导致方法终止的语句，一旦在 finally 块中使用了上述的语句，将会导致 try 块、catch 块中的 return 或 throw 语句失效。系统在执行到 try 块或 catch 块中的 return 或 throw 语句时，会先去寻找是否有 finally 块，若有 finally 块，则先执行 finally 块，再跳转回 try 或 catch 块中去执行刚刚的 return 或 throw 语句，若 finally 块中有 return 或 throw 语句，则try 块、catch 块中的 return 或 throw 语句失效。 异常处理嵌套的深度没有明确的限制，但通常没有必要使用超过两层的嵌套异常处理。 Java7以后，几乎所有的“资源类”（包括文件IO 的各种类，JDBC 的connection、statement 等接口）进行了改写，改写后资源类都实现了 AutoCloseable 或 Closeable 接口，可以在 try 块后紧跟一对圆括号，将需要在程序结束后关闭资源的类放入其中，Java 会自动关闭这些资源，不再需要在 finally 块里显式关闭try 块中使用的物理资源。 使用 throws 声明抛出异常throws 声明抛出的语法格式紧跟在方法签名之后，使用 throws 声明抛出的异常，表明当前方法不处理该类型的异常，将异常抛给其调用者，调用者需要用 try…catch 处理这个异常，或者继续使用 throws 将该异常抛出去给下一个上级调用者，若直到最顶级调用者，仍未处理该异常，JVM 会会打印出异常跟踪栈信息，并将程序终止。 使用 throw 抛出异常如果需要在程序中手动抛出异常，则应使用 throw 语句，throw 语句抛出的不是异常类，而是一个异常实例，如 throw new Exception(&quot;这是一条异常信息。&quot;);，当 Java 运行时接收到开发者手动抛出的异常时，与系统自动抛出的异常一样，JVM 都会中止当前的执行刘，跳转到该异常对应的 catch 块，由该 catch 块来处理该异常。 自定义异常类用户自定义异常类都应该继承 Exception 基类，若要自定义Runtime异常，则应该继承 RuntimeException 类，定义异常类时需要定义两个构造器： 无参构造器 带一个字符串参数的构造器，这个字符串将作为该异常对象的描述信息（也就是异常对象的 getMessage()方法的返回值） 12345678public class AuctionException extends Exception&#123; // 无参构造器 public AuctionException()&#123;&#125;; public AuctionException(String msg)&#123; super(msg); &#125;&#125; 企业级应用对异常的处理通常分成两个部分： 应用后台需要通过日志来记录异常发生的详细情况 应用需要根据异常向应用使用者传达某种提示 异常链（职责链模式） 当业务逻辑层访问持久层出现 SQLException 异常时，程序不应该把底层的SQLException异常穿到用户界面，而是应该先捕获原始异常，让后将该异常转译，抛出一个业务异常，该业务异常中包含了对用户的提示，如“系统出现异常”这类的提示。 在 JDK1.4 后，所有Throwable的子类在构造器中都可以接收一个异常实例作为参数，而不再是仅仅只能接收以个 String 参数。 异常跟踪栈 很多初学者一看到上图的异常信息，就会惊慌失措，其实上图的异常跟踪栈信息非常详细，第一行显示了异常的类型和异常的详细信息，接下来跟踪栈记录程序中所有的异常发生点，从上到下依次为异常的第一个触发点，直到最外层的程序入口main 方法或Thread 类的 run 方法。 举例如下： 程序在 Thread 的 run 方法中出现了 ArithmeticException异常，这个异常的源头在ThreadExceptionTest 的 secondMethod 方法，位于 ThreadExceptionTest.java 的第27行，这个异常传播到Thread 类的 run 方法就会结束（如果该异常没有得到处理，将会导致该线程被中止运行） 虽然 printStackTrace() 方法可以很方便地用于追踪异常的发生情况，可以用它来调试程序，但在最后发布的程序中，应该避免使用它；而应该对捕获的异常进行适当的处理，而不是简单地将异常的跟踪栈信息打印出来。 使用异常机制的技巧不要过度使用异常 例子： 1if(!s.empty()) s.pop(); 12345try&#123; s.pop();&#125;catch(EmptyStackException e)&#123; ...&#125; 在测试机上，前者将花费646毫秒，后者将花费 21739毫秒，捕获异常花费的时间大大超过前者。 异常处理机制的初衷是将不可预期异常的处理代码和正常的业务逻辑代码分离，因此绝不要使用异常处理来代替正常的业务逻辑判断。 异常机制的效率比正常流程的效率差。因为 Java 运行时接收到这个异常后，还需要进入相应的 catch 块来捕获该异常，再进行处理 异常只应该用于处理非正常的情况，不要使用异常处理来代替正常的流程控制，对于一些完全可预知、而且处理方式清除的错误，程序应该提供相应的错误处理代码，而不是笼统地称为异常。 不要使用过于庞大的 try 块 当 try 块过于庞大时，就难免在 try 后紧跟大量的 catch块才可以针对不同的异常提供不同的处理逻辑，同一个 try 块后紧跟大量的catch 块需要分析它们之间的逻辑关系，反而增加了编程的复杂性 正确做法是，把大块的 try 块分割成多个可能出现异常的程序段落，并把它们放在单独的try 块中，从而分别捕获处理异常 不要忽略捕获到的异常 既然已经捕获到了异常，就应该在 catch 块中对该异常做一定处理， catch 块为空是不可取的，最差也应该在catch 块中打印错误跟踪栈信息，最好是对异常做一定的处理，或者将该异常抛出，交给调用者处理 在检测错误时，“苛刻”要比放任更好当检测到错误的时候，有些程序员担心抛出异常。在用无效的参数调用一个方法时，返回一个虚拟的数值，还是抛出一个异常，哪种处理方式更好？例如，当栈空时，Stack.pop 是返回一个 null，还是抛出一个异常？一般来说：在出错的地方抛出一个 EmptyStackException 异常要比在后面抛出一个NullPointerException 异常更好。 不要羞于传递异常 很多程序员都感觉应该捕获抛出的全部异常。如果调用了一个抛出异常的方法，例如，FileInputStream 构造器或 readLine 方法，这些方法就会本能地捕获这些可能产生的异常。其实，传递异常要比捕获这些异常更好： 123pub1ic void readStuff (String fi1ename) throws I0Exception&#123; InputStream in= new FileInputStream (filename);&#125; 即：“早抛出，晚捕获”。 参考链接 [Java异常：选择Checked Exception还是Unchecked Exception?](http://blog.csdn.net/kingzone_2008/article/details/8535287} 取的，最差也应该在catch 块中打印错误跟踪栈信息，最好是对异常做一定的处理，或者将该异常抛出，交给调用者处理]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@开发类笔试知识点梳理(一): Java]]></title>
    <url>%2Flanguages%2F56fdb8ac.html</url>
    <content type="text"><![CDATA[Java 基础 最基本的语言基础：语法，关键字含义，面向对象… 集合类(ArrayList, HashMap, ConcurrentHashmap…等等) 多线程(锁，CAS，线程池，concurrent 包下的类) 语言特性：反射，动态代理，泛型，Java 8 新特性 IO (装饰器模式，NIO) JVM：内存模型，垃圾回收，类加载机制 Java Web Tomcat，Servlet，JSP，Cookie/Session 等基本概念 框架使用和原理：Spring(AOP，IoC)，MyBatis 等 基础部分八大基本数据类型和包装类Java 语言是一个面向对象的语言，但是 Java 中的基本数据类型却不是面向对象的，这在实际使用时存在诸多的不便，为了解决这个不足，在 Java 中每个基本数据类型都有与之对应的类，这些类即包装类。（下表罗列了八大基本数据类型的大小、取值范围、应用场景及各自所对应的包装类） 基本类型 大小 包装器类型 取值范围(有符号位&amp;无符号位) boolean / Boolean char 16bit Char $[-2^{15},2^{15}-1]$，$[0,2^{16}-1]$ byte 8bit Byte $[-2^7,2^7-1]$，$[0,2^8-1]$ short 16bit Short $[-2^{15},2^{15}-1]$，$[0,2^{16}-1]$ int 32bit Int $[-2^{31},2^{31}-1]$，$[0,2^{32}-1]$ long 64bit Long $[-2^{63},2^{63}-1]$，$[0,2^{64}-1]$ float 32bit Float double 64bit Double void / Void 其中，浮点型的取值范围及其在内存中如何表示？十进制小数与二进制小数之间如何转换？可以分别参考这几篇文章： 浮点型数据存储结构 float类型最大值和最小值 十进制小数分数与二进制的转换 引入包装类的目的？ 方便类型转换。比如 String 与基本数据类型之间的转换，基本数据类型之间的转换。 以集合框架List 为例，它的 add(Object o) 方法，只接受引用类型——即对象，而怎样把一个数值（基本数据类型）放入到 List 中呢？其对应的包装类就派上用场了。 包装类在实际中用得最多的还是字符串与基本类型之间的转换，如下面这段代码： 12345678910public class Test&#123; public static void main(String args[])&#123; String str1 = "30" ; // 由数字组成的字符串 String str2 = "30.3" ; // 由数字组成的字符串 int x = Integer.parseInt(str1) ; // 将字符串变为int型 float f = Float.parseFloat(str2) ; // 将字符串变为float型 int c = 10; String str3 = Integer.toString(c); &#125; &#125; 包装类和基本数据类型的区别？ 包装类是引用类型，基本数据类型是值类型，如 Integer 是引用类型，int 是值类型 包装类型的默认初始值为null，基本类型为0、false等 字符串首先，需要明确的是，String 并不是基本数据类型，而是一个对象，并且是不可变的对象（查看源码就会发现String类为final型的）。 String、StringBuilder、StringBuffer 类型 可变？ 线程安全 速度 如何选择 String 字符串常量 不可变 线程安全 最慢 操作少量数据时使用 StringBuffer 字符串变量 可变 线程安全 中间 多线程，大量数据 StringBuilder 字符串变量 可变 线程不安全 最快 单线程，大量数据 参考链接 2年Java开发工作经验面试总结 java面试需要掌握知识点|掘金技术征文 未完待续 .post-body .fancybox img.pic_styl { display: inline !important; height: 140px; width: auto;}]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@算法基础: 八大排序和三大查找]]></title>
    <url>%2Falgorithms%2F88f03389.html</url>
    <content type="text"><![CDATA[八大排序，三大查找 是《数据结构》当中非常基础的知识点。 插入排序、归并排序、堆排序、快速排序均是比较排序算法，它们都是通过对元素进行比较操作来确定输入数组的有序次序；如果通过比较操作之外的方法来获得输入序列有序次序的信息，就有可能打破 $\Omega(nlogn)$的下界，比如：计数排序算法、基数排序算法、桶排序算法。 八大排序插入排序直接插入排序（Straight Insertion Sort） 插入排序是一种原址排序算法。 基本思想将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过。因此，从上面的描述中我们可以发现，直接插入排序可以用两个循环完成： 第一层循环：遍历待比较的所有数组元素 第二层循环：将本轮选择的元素(selected)与已经排好序的元素(ordered)相比较。如果：selected &gt; ordered，那么将二者交换 注意如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。 示例 案列插入排序的工作原理类似于扑克牌的抓牌过程。开始时，左手为空且桌子上的牌面向下，然后，我们每次从桌子上拿走一张牌并将它插入左手中正确的位置。为了找到一张牌的正确位置，我们从右到左将它与手中的每张牌进行比较，最终，拿在手中牌总是排好序的，原来这些牌是桌子上牌堆顶部的牌。 伪代码 123456789INSERT-SORT(A)for j = 2 to A.length key = A[j] // Insert key to the sorted sequence A[1,2,...,j-1] i = j-1 while j &gt; 0 and A[i] &gt; key A[i+1] = A[i] i-- A[i+1] = key 算法中将待排序的数列 A，分为A[1,2,...,j-1] 和 A[j,j+1,...,n]两个子数组，其中前者为已排序的数组，即算法中用下表 i 标记的部分，后者为待排序的数组。 代码实现 12345678910111213141516171819202122232425public class StraightInsertionSort &#123; public static void sort(int[] arr)&#123; for(int j=1;j&lt;arr.length;j++)&#123; int i = j-1; int key = arr[j]; //将本轮选择的元素(selected)与已经排好序的元素(ordered)相比较 while(i&gt;=0 &amp;&amp; key&lt;arr[i])&#123; // selected &lt; ordered，将两者进行交换 int tmp = arr[i+1]; arr[i+1] = arr[i]; arr[i] = tmp; i--; &#125; arr[i+1] = key; // 否则，将 selected 放在 ordered 之后 &#125; &#125; public static void main(String[] args)&#123; int[] a = &#123;49, 38, 65, 97, 76, 13, 27, 50&#125;; sort(a); for(int i=0;i&lt;a.length;i++)&#123; System.out.println(a[i]+" "); &#125; &#125;&#125; 希尔排序（Shell’s Sort） 希尔排序是1959 年由D.L.Shell 提出来的，相对直接排序有较大的改进。希尔排序又叫缩小增量排序。 基本思想将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；每次将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。同样的：从上面的描述中我们可以发现：希尔排序的总体实现应该由三个循环完成： 第一层循环：将gap依次折半，对序列进行分组，直到gap=1 第二、三层循环：也即直接插入排序所需要的两次循环。具体描述见上。 示例以 n=10 的一个数组arr = {49, 38, 65, 97, 26, 13, 27, 49, 55, 4}为例 第一次 gap = 10 / 2 = 5 123456789101149 38 65 97 26 13 27 49 55 41A 1B 2A 2B 3A 3B 4A 4B 5A 5B``` 1A,1B，2A,2B等为分组标记，数字相同的表示在同一组，每次对同一组的数据进行直接插入排序。即分成了五组(49, 13) (38, 27) (65, 49) (97, 55) (26, 4)这样每组排序后就变成了(13, 49) (27, 38) (49, 65) (55, 97) (4, 26)，下同。- 第二次 gap = 5 / 2 = 2 13 27 49 55 4 49 38 65 97 261A 1B 1C 1D 1E 2A 2B 2C 2D 2E123分成了(13, 49, 4, 38, 97)和(27, 55, 49, 65, 26)两组，对两组分别进行直接插入排序。- 第三次 gap = 2 / 2 = 1 4 26 13 27 38 49 49 55 97 651A 1B 1C 1D 1E 1F 1G 1H 1I 1J12- 第四次 gap = 1 / 2 = 0 排序完成得到数组： 4 13 26 27 38 49 49 55 65 9712345678910111213141516171819202122232425262728293031323334完成排序。**代码实现**```javapublic class ShellSort &#123; public static void sort(int[] arr)&#123; // 依次改变gap值对列表进行分组 for(int gap=arr.length/2;gap&gt;0;gap/=2)&#123; // 下面：利用直接插入排序的思想对分组数据进行排序 for(int j=gap;j&lt;arr.length;j+=gap)&#123; int i = j-gap; int key = arr[j]; while(i&gt;=0 &amp;&amp; key&lt;arr[i])&#123; int tmp = arr[i+gap]; arr[i+gap]=arr[i]; arr[i] = tmp; i-=gap; &#125; arr[i+gap] = key; &#125; &#125; &#125; public static void main(String[] args)&#123; int[] a = &#123;49, 38, 65, 97, 76, 13, 27, 50&#125;; sort(a); for(int i=0;i&lt;a.length;i++)&#123; System.out.println(a[i]+&quot; &quot;); &#125; &#125;&#125; 选择排序简单选择排序（Simple Selection Sort）基本思想 从待排序序列中，找到关键字最小的元素； 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换； 从余下的 N - 1 个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束。因此我们可以发现，简单选择排序也是通过两层循环实现。 第一层循环：依次遍历序列当中的每一个元素第二层循环：将遍历得到的当前元素依次与余下的元素进行比较，符合最小元素的条件，则交换。 示例 12345初始值：3 1 5 7 2第1趟：1 3 5 7 2第2趟：1 2 5 7 3第3趟：1 2 3 7 5第4趟：1 2 3 5 7 代码实现 1234567891011121314151617181920212223242526public class SimpleSelectionSort &#123; public static void sort(int[] arr)&#123; for(int i=0; i&lt;arr.length;i++)&#123; int min = i; // 找到序列中第 i 个数之后的所有数中的最小数 for(int j=i+1; j&lt;arr.length;j++)&#123; if(arr[min] &gt; arr[j])&#123; min = j; &#125; &#125; // 将最小数与第 i 个数进行交换 int tmp = arr[i]; arr[i] = arr[min]; arr[min] = tmp; &#125; &#125; public static void main(String[] args)&#123; int[] a = &#123;49, 38, 65, 97, 76, 13, 27, 50&#125;; sort(a); for(int i=0;i&lt;a.length;i++)&#123; System.out.println(a[i]+" "); &#125; &#125;&#125; 堆排序（Heap Sort） 堆排序是一种树形选择排序，是对直接选择排序的有效改进。是一种$O(nlogn)$的原址排序算法，它使用了一种被称为堆的重要数据结构，堆还可用来实现优先队列。 堆：堆是一种重要的数据结构，为一棵完全二叉树, 底层用数组存储数据。如：array[0，…，n-1] 表示成一颗完全二叉树的顺序存储模式，对于数组 array 的任意索引 $i$，其根节点和叶子节点的内在关系如下： 根节点：i==0?null:(i-1)/2 左节点：2i+1 右节点：2i+2 分为小顶堆和大顶堆，对于待排序序列 array[0，…，n-1]，当且仅当满足下列要求：(0 &lt;= i &lt;= (n-1)/2) 大顶堆：array[i] &gt;= array[2i+1] 且 array[i] &gt;= array[2i+2] 小顶堆：array[i] &lt;= array[2i+1] 且 array[i] &lt;= array[2i+2] 基本思想所谓堆排序就是利用堆这种数据结构来对数组排序，我们使用的是最大堆。处理的思想和冒泡排序，选择排序非常的类似，一层层封顶，只是最大元素的选取使用了最大堆。最大堆的最大元素一定在第0位置，构建好堆之后，交换0位置元素与顶即可。堆排序为原位排序(空间小), 且最坏运行时间是O(nlgn)，是渐进最优的比较排序算法。 堆排序可以按照以下步骤来完成： 首先将序列构建称为大顶堆；（这样满足了大顶堆那条性质：位于根节点的元素一定是当前序列的最大值） 取出当前大顶堆的根节点，将其与序列末尾元素进行交换；（此时：序列末尾的元素为已排序的最大值；由于交换了元素，当前位于根节点的堆并不一定满足大顶堆的性质） 对交换后的n-1个序列元素进行调整，使其满足大顶堆的性质； 重复2.3步骤，直至堆中只有1个元素为止 因此，实现堆排序需解决两个问题： 如何将n 个待排序的数建成堆； 输出堆顶元素后，怎样调整剩余n-1 个元素，使其成为一个新堆。 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class HeapSort &#123; /** * 建立大顶堆 * * @param arr 待排序的序列 * @return */ private int[] buildMaxHeap(int[] arr, int heapSize) &#123; // 从序列中的最后一个数 heapSize-1 的父节点 (heapSize-2)/2 开始，直到堆顶 0，反复调整堆 for (int index = (heapSize - 2) / 2; index &gt;=0 ; index--) &#123; adjustMaxHeap(arr, heapSize, index); &#125; return arr; &#125; /** * 调整堆，使其始终满足大顶堆的性质 * * @param arr 待排序序列 * @param index 从哪个根节点子树开始调整 * @param heapSize 待调整堆的元素个数(即待排序的元素个数) * @return */ private int[] adjustMaxHeap(int[] arr, int heapSize, int index) &#123; int left = 2 * index + 1; int right = 2 * index + 2; int max = index; // 待调整堆数组的最后一个元素为 heapSize-1，则其父亲节点为 (heapSize-2)/2 if (left &lt; heapSize &amp;&amp; arr[left] &gt; arr[max]) &#123; max = left; &#125; if (right &lt; heapSize &amp;&amp; arr[right] &gt; arr[max]) &#123; max = right; &#125; // 若子树的根节点不是最大的数，则交换根节点与子树中最大的那个节点元素，使该子树满足大顶堆性质 if (max != index) &#123; int tmp = arr[index]; arr[index] = arr[max]; arr[max] = tmp; &#125; return arr; &#125; public void sort(int[] arr) &#123; // 先建立大顶堆，保证最大值位于根节点；并且父节点的值大于叶子结点 int heapSize = arr.length; buildMaxHeap(arr,heapSize); // 将大顶堆的堆顶元素与最后一个元素进行交换(即将最大的元素放在序列的最后一个位置) for (int i = heapSize - 1; i &gt; 0; i--) &#123; int tmp = arr[i]; arr[i] = arr[0]; arr[0] = tmp; // 交换后待调整的堆的元素个数减一 heapSize--; // 调整交换元素后的堆，使其仍旧满足大顶堆的性质 buildMaxHeap(arr,heapSize); &#125; &#125;&#125;public class Test&#123; public static void main(String[] args) &#123; int[] a = &#123;49, 38, 65, 97, 76, 13, 27, 50&#125;; new HeapSort().sort(a); for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i] + " "); &#125; &#125;&#125; 交换排序冒泡排序（Bubble Sort）基本思想 将序列当中的左右元素，依次比较，保证右边的元素始终大于左边的元素；（ 第一轮结束后，序列最后一个元素一定是当前序列的最大值；） 对序列当中剩下的n-1个元素再次执行步骤1。 对于长度为n的序列，一共需要执行n-1轮比较（利用while循环可以减少执行次数） 代码实现 12345678910111213141516171819202122class BubbleSort&#123; public void sort(int[] arr) &#123; for(int i=0; i&lt;arr.length-1;i++)&#123; for(int j=0;j&lt;arr.length-i-1;j++)&#123; if(arr[j]&gt;arr[j+1])&#123; int tmp = arr[j]; arr[j]=arr[j+1]; arr[j+1] = tmp; &#125; &#125; &#125; &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; int[] a = &#123;49, 38, 65, 97, 76, 13, 27, 50&#125;; new BubbleSort().sort(a); for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i] + " "); &#125; &#125;&#125; 快速排序（Quick Sort）基本思想 从序列当中选择一个基准数(pivot)。在这里我们选择序列当中第一个数作为基准数 将序列当中的所有数依次遍历，比基准数大的位于其右侧，比基准数小的位于其左侧 重复步骤1.2，直到所有子集当中只有一个元素为止。 代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243class QuickSort&#123; private int partition(int[] arr, int lo, int hi) &#123; int key = arr[lo]; // 循环结束后，说明 lo=hi，此时左边的值全都小于key,右边的值全都大于key // key的位置移动正确，那么此时只需对左右两侧的序列调用此函数进一步排序即可 while (lo &lt; hi) &#123; // 从右开始向左寻找第一个小于基准值 key 的值 while (hi &gt; lo &amp;&amp; arr[hi] &gt;= key) &#123; hi--; &#125; // 将小于key的值移到左边 arr[lo] = arr[hi]; // 从左往右寻找第一个大于基准值 key 的值 while (lo &lt; hi &amp;&amp; arr[lo] &lt;= key) &#123; lo++; &#125; // 将大于 key 的值移到右边 arr[hi] = arr[lo]; arr[lo] = key; &#125; return lo; &#125; public void sort(int[] arr, int start, int end) &#123; // 经过上一次循环，序列被基准值 key 分为左右两部分，左侧的值均小于基准值，右侧的值均大于基准值 // 接下来，只需分别对左右两部分的子序列分别继续迭代执行上面的步骤 if(start&lt;end)&#123; int keyLoc = partition(arr, start, end); sort(arr, start, keyLoc-1 ); sort(arr, keyLoc+1, end); &#125; &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; int[] a = &#123;49, 38, 65, 97, 76, 13, 27, 50&#125;; new QuickSort().sort(a,0,a.lenght-1); for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i] + " "); &#125; &#125;&#125; 归并排序（Merge Sort）基本思想归并排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 基本过程如下： 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 重复步骤3直到某一指针达到序列尾 将另一序列剩下的所有元素直接复制到合并序列尾 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class MergeSort&#123; public void sort(int[] arr, int start, int end) &#123; if (start &gt;= end) return; int center = (start + end) / 2; sort(arr, start, center); sort(arr, center + 1, end); merge(arr, start, center, end); &#125; /** * 将两个数组进行归并，归并前两个数组已有序，归并后依然有序 * * @param arr 数组对象 * @param start 左数组的第一个元素的索引 * @param center 左数组最后一个元素的索引，center+1 为右数组第一个元素的索引 * @param end 右数组最后一个元素的索引 */ private void merge(int[] arr, int start, int center, int end) &#123; // 申请一个临时空间，用于存放归并过程中的数组 int[] tmpArr = new int[arr.length]; // 缓存右数组第一个元素的索引 int right = center + 1; // 缓存左数组第一个元素的索引 int left = start; // 临时数组的索引 int tmp = start; while (left &lt;= center &amp;&amp; right &lt;= end) &#123; // 从左右两个数组中选出较小的那个数存入临时数组 tmpArr 中 if (arr[left] &lt;= arr[right]) &#123; tmpArr[tmp] = arr[left]; tmp++; left++; &#125; else &#123; tmpArr[tmp] = arr[right]; tmp++; right++; &#125; &#125; // 剩余部分放入临时数组(两个 while 循环只会执行一个) // 如果左数组还有数 while (left &lt;= center) &#123; tmpArr[tmp] = arr[left]; tmp++; left++; &#125; // 如果右数组还有数 while (right &lt;= end) &#123; tmpArr[tmp] = arr[right]; tmp++; right++; &#125; // 将临时数组 tmpArr 中的所有内容拷贝回原数组 arr 中 for (int i = start; i &lt; tmp; i++) &#123; arr[i] = tmpArr[i]; &#125; &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; int[] a = &#123;49, 38, 65, 97, 76, 13, 27, 50&#125;; new MergeSort().sort(a,0,a.lenght-1); for (int i = 0; i &lt; a.length; i++) &#123; System.out.println(a[i] + " "); &#125; &#125;&#125; 三大查找二分查找法二分查找(折半查找)优点是比较次数少，查找速度快，平均性能好；其缺点是要求待查表为有序表，且插入删除困难。时间复杂度可以表示$O(h)=O(\log_2n)$。比如数组长度为10，最多找4次。 1234567891011121314151617181920212223242526272829303132333435import java.util.Scanner;public class PaiXu&#123; public static void main(String[] args)&#123; Integer[] haha = &#123;1,3,5,7,9,11,13,15,17,19,21,23,25,27&#125;; Scanner sc = new Scanner(System.in); System.out.println("请输入您要查找的值："); int z = sc.nextInt(); int y = binarySearch(haha,z); if(y == -1)&#123; System.out.println("要查找的值不存在"); &#125; &#125; public static int binarySearch(Integer[] srcArray,int des)&#123; int x = 1; int low = 0; int high = srcArray.length-1; while(low&lt;=high)&#123; System.out.println("第"+x+"次比较"); x++; int mid = (high+low)/2; if(des == srcArray[mid])&#123; System.out.println(des+"找到了,在第"+mid+"个位置"); return mid; &#125;else if(des &lt; srcArray[mid])&#123; System.out.println(srcArray[mid]+"比"+des+"大，继续查找"); high = mid-1; &#125;else&#123; System.out.println(srcArray[mid]+"比"+des+"小，继续查找"); low = mid+1; &#125; &#125; return -1; &#125;&#125; 算法问题最大子数组问题 1234567891011121314FIND-MAX-CROSSING-SUBARRAY(A,low,mid,high)left_sum = -∞sum = 0for i = mid downto low sum = sum + A[i] if sum &gt; left_sum left_sum = sum max_left = iright_sum = -∞sum = 0for j = mid+1 to high sum = sum + A[j] max_right = jreturn (max_left, max_right, left_sum+right_sum) 1234567891011121314FIND-MAXIMUM-SUBARRAY(A,low,high)if high == low return (low, high, A[low])else mid = (low+high)/2 (left_low, left_high, left_sum) = FIND-MAXIMUM-SUBARRAY(A,low,mid) (right_low, right_high, right_sum) = FIND-MAXIMUM-SUBARRAY(A,mid+1,high) (cross_low, cross_high, cross_sum) = FIND-MAX-CROSSIONG-SUBARRAY(A,low,mid,high) if left_sum &gt;= right_sum and left_sum &gt;= cross_sum return (left_low, left_hith, left_sum) else if right_sum &gt;= left_sum and right_sum &gt;= cross_sum return(right_low, right_high, right_sum) else return(cross_low, cross_high, cross_sum) 矩阵乘法由矩阵乘法的定义我们可以给出如下伪代码，需要花费 $\Omega(n^3)$123456789SQUARE-MATRIX-MULTIPLY(A,B)n = A.rowslet C be a new n*n matrixfor i = 1 to n for j = 1 to n c_ij = 0 for k = 1 to n c_ij = c_ij + a_ik · b_kjreturn C 参考链接 八大排序算法 数据结构常见的八大排序算法]]></content>
      <categories>
        <category>algorithms</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[@神经网络]]></title>
    <url>%2Flanguages%2Fcee620b1.html</url>
    <content type="text"><![CDATA[overview: backpropagation algorithm, gradient checking, visualizing the hidden layer, regularized neural network. 建模 Model Representation Neural Network Architecture: Hypothesis If network has $sl$ units in layer $l$ and $s{l+1}$ units in layer $l+1$. X = \begin{bmatrix} x_1 \newline x_2 \newline \cdots \newline x_n \end{bmatrix} \quad a^{(1)} = \begin{bmatrix} x_0 \newline x_1 \newline x_2 \newline \cdots \newline x_n \end{bmatrix} \quad z^{(l)} = \begin{bmatrix} z_1^{(l)} \newline z_2^{(l)} \newline \cdots \newline z_{s_l}^{(l)} \end{bmatrix} \quad Z^{(l)} = \begin{bmatrix} z_0^{(l)} \newline z_1^{(l)} \newline z_2^{(l)} \newline \cdots \newline z_{s_l}^{(l)} \end{bmatrix} \quad h_{\Theta}(x) = \begin{bmatrix} h_\Theta(x)_1 \newline h_\Theta(x)_2 \newline \cdots \newline h_\Theta(x)_K \newline \end{bmatrix} Note: 其中的 $x_0$, $z_0$是 bias unit，均为1或单位向量。 The graph of our functions may look like: \begin{align*}\begin{bmatrix}x_0 \newline x_1 \newline x_2 \newline\cdots \newline x_n\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(2)} \newline a_1^{(2)} \newline a_2^{(2)} \newline\cdots\end{bmatrix} \rightarrow\begin{bmatrix}a_0^{(3)} \newline a_1^{(3)} \newline a_2^{(3)} \newline\cdots\end{bmatrix} \rightarrow \cdots \rightarrow\begin{bmatrix}h_\Theta(x)_1 \newline h_\Theta(x)_2 \newline h_\Theta(x)_3 \newline \cdots \newline\end{bmatrix} \rightarrow\end{align*} h_{\Theta}(X) = a^L \tag{1} NOTE: $L$ 表示最后一层(即输出层)。 \left\lbrace \begin{aligned} & a^{(l)} = g(Z^{(l)}) \quad l=2..L \newline & z^{(l)} = \Theta^{(l-1)}a^{(l-1)} \newline & g(z) = \frac{1}{1+e^{-z}} \end{aligned} \right. $L$= total number of layers in the network$s_l$ = number of units (not counting bias unit) in layer $l$$K$ = number of output units/classes$m$ = number of dataset$n$ = number of features$\delta_j^{(l)}$ = “error” of node $j$ in layer $l$$a_j^{(l)}$ = activation node $j$ in layer $l$. Cost Function 神经网络的代价函数是逻辑回归代价函数的推广，在前文“@逻辑回归”中，我们知道其代价函数如下： J(\theta) = - \frac{1}{m} \sum_{i=1}^m \large[ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))\large] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2以下是神经网的代价函数。 \begin{gather*}\large J(\Theta) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2\end{gather*} \tag{2}\label{2} Back propagation 利用 反向传播算法 计算 $\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}J(\Theta)$。 \left\lbrace \begin{aligned} & \dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}J(\Theta) = D^{(l)}_{i,j} = \dfrac{1}{m}\Delta^{(l)}_{i,j} &\quad for \, j=0 \newline & \dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}J(\Theta) = D^{(l)}_{i,j} = \dfrac{1}{m}\Delta^{(l)}_{i,j} + \frac{\lambda}{m}\Theta^{(l)}_{i,j} &\quad for \, j \ge1 \end{aligned} \right. \tag{3}\label{3} step1: compute $\delta^{(L-1)}$ \delta^{(L)} = a^{(L)} - y \tag{3-1} step2: compute $\delta^{(L-1)}$, $\delta^{(L-2)}$, … , $\delta^{(2)}$. \left\lbrace \begin{aligned} & \delta^{(l)} = ((\Theta^{(l)})^T \delta^{(l+1)})\ .*\ g'(z^{(l)}) \newline & g'(u) = g(u)\ .*\ (1 - g(u)) \end{aligned} \right. \tag{3-2} step3: \Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^T \tag{3-3}\label{3-3}Note: 将$\eqref{3-3}$代入$\eqref{3}$即可。 Gradient Checking 由于我们通过BP算法这种巧妙的方式求得了代价函数的导数，如何校验其正确性？这里就可以用 高等数学 里的导数的定义(极限的定义)来计算导数，然后再比较：用BP算法求得的导数 和 用导数的定义 求得的导数，这二者之间的差距。 导数定义(极限定义)—-非正式定义，如下： \left\lbrace \begin{aligned} \dfrac{\partial}{\partial\Theta}J(\Theta) \approx \dfrac{J(\Theta + \epsilon) - J(\Theta - \epsilon)}{2\epsilon} \newline \epsilon = \dfrac{\sqrt{6}}{\sqrt{\mathrm{Loutput} + \mathrm{Linput}}} \end{aligned} \right. \tag{4}\label{4} Random Initialization 在之前提到的逻辑回归和线性回归中，参数$\Theta$均只需初始化为 $0$ 即可，但在神经网络中，如果简单将 $\Theta$ 初始化为零矩阵，将会导致隐藏层$a^{(l)}$的每个 unit 都是相等的，因此，为了让学习更有效率，一般将 $\Theta$ 初始化在 $[-\epsilon, \epsilon]$。 \Theta^{(l)} = 2 \epsilon \; \mathrm{rand}(\mathrm{Loutput}, \mathrm{Linput} + 1) - \epsilon \tag{5} 应用该实例来源于 coursera machine learning programming exercise3&amp;4. 目的使用BP算法训练神经网络以识别手写阿拉伯数字(0-9)。 DataSet完整数据集在这里 一共有5000个训练样本，每个训练样本是400维的向量（20X20像素的 grayscale image），用矩阵 $X$ 保存。样本的结果(label of training set)保存在向量 $\overrightarrow{y}$ 中，$\overrightarrow{y}$ 是一个5000行1列的列向量。 注意，由于Matlab下标是从1开始的，故用 10 表示数字 0。 完整代码完整代码可在这里下载。 下面只列出其中的主程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217%% Machine Learning Online Class - Exercise 4 Neural Network Learning%% Initializationclear ; close all; clc%% Setup the parameters you will use for this exerciseinput_layer_size = 400; % 20x20 Input Images of Digitshidden_layer_size = 25; % 25 hidden unitsnum_labels = 10; % 10 labels, from 1 to 10 % (note that we have mapped "0" to label 10)%% =========== Part 1: Loading and Visualizing Data =============% We start the exercise by first loading and visualizing the dataset. % You will be working with a dataset that contains handwritten digits.%% Load Training Datafprintf('Loading and Visualizing Data ...\n')load('ex4data1.mat');m = size(X, 1);% Randomly select 100 data points to displaysel = randperm(size(X, 1));sel = sel(1:100);displayData(X(sel, :));fprintf('Program paused. Press enter to continue.\n');pause;%% ================ Part 2: Loading Parameters ================% In this part of the exercise, we load some pre-initialized % neural network parameters.fprintf('\nLoading Saved Neural Network Parameters ...\n')% Load the weights into variables Theta1 and Theta2load('ex4weights.mat');% Unroll parameters nn_params = [Theta1(:) ; Theta2(:)];%% ================ Part 3: Compute Cost (Feedforward) ================% To the neural network, you should first start by implementing the% feedforward part of the neural network that returns the cost only. You% should complete the code in nnCostFunction.m to return cost. After% implementing the feedforward to compute the cost, you can verify that% your implementation is correct by verifying that you get the same cost% as us for the fixed debugging parameters.%% We suggest implementing the feedforward cost *without* regularization% first so that it will be easier for you to debug. Later, in part 4, you% will get to implement the regularized cost.%fprintf('\nFeedforward Using Neural Network ...\n')% Weight regularization parameter (we set this to 0 here).lambda = 0;J = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, ... num_labels, X, y, lambda);fprintf(['Cost at parameters (loaded from ex4weights): %f '... '\n(this value should be about 0.287629)\n'], J);fprintf('\nProgram paused. Press enter to continue.\n');pause;%% =============== Part 4: Implement Regularization ===============% Once your cost function implementation is correct, you should now% continue to implement the regularization with the cost.%fprintf('\nChecking Cost Function (w/ Regularization) ... \n')% Weight regularization parameter (we set this to 1 here).lambda = 1;J = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, ... num_labels, X, y, lambda);fprintf(['Cost at parameters (loaded from ex4weights): %f '... '\n(this value should be about 0.383770)\n'], J);fprintf('Program paused. Press enter to continue.\n');pause;%% ================ Part 5: Sigmoid Gradient ================% Before you start implementing the neural network, you will first% implement the gradient for the sigmoid function. You should complete the% code in the sigmoidGradient.m file.%fprintf('\nEvaluating sigmoid gradient...\n')g = sigmoidGradient([-1 -0.5 0 0.5 1]);fprintf('Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\n ');fprintf('%f ', g);fprintf('\n\n');fprintf('Program paused. Press enter to continue.\n');pause;%% ================ Part 6: Initializing Pameters ================% In this part of the exercise, you will be starting to implment a two% layer neural network that classifies digits. You will start by% implementing a function to initialize the weights of the neural network% (randInitializeWeights.m)fprintf('\nInitializing Neural Network Parameters ...\n')initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size);initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels);% Unroll parametersinitial_nn_params = [initial_Theta1(:) ; initial_Theta2(:)];%% =============== Part 7: Implement Backpropagation ===============% Once your cost matches up with ours, you should proceed to implement the% backpropagation algorithm for the neural network. You should add to the% code you've written in nnCostFunction.m to return the partial% derivatives of the parameters.%fprintf('\nChecking Backpropagation... \n');% Check gradients by running checkNNGradientscheckNNGradients;fprintf('\nProgram paused. Press enter to continue.\n');pause;%% =============== Part 8: Implement Regularization ===============% Once your backpropagation implementation is correct, you should now% continue to implement the regularization with the cost and gradient.%fprintf('\nChecking Backpropagation (w/ Regularization) ... \n')% Check gradients by running checkNNGradientslambda = 3;checkNNGradients(lambda);% Also output the costFunction debugging valuesdebug_J = nnCostFunction(nn_params, input_layer_size, ... hidden_layer_size, num_labels, X, y, lambda);fprintf(['\n\nCost at (fixed) debugging parameters (w/ lambda = %f): %f ' ... '\n(for lambda = 3, this value should be about 0.576051)\n\n'], lambda, debug_J);fprintf('Program paused. Press enter to continue.\n');pause;%% =================== Part 8: Training NN ===================% You have now implemented all the code necessary to train a neural % network. To train your neural network, we will now use "fmincg", which% is a function which works similarly to "fminunc". Recall that these% advanced optimizers are able to train our cost functions efficiently as% long as we provide them with the gradient computations.%fprintf('\nTraining Neural Network... \n')% After you have completed the assignment, change the MaxIter to a larger% value to see how more training helps.options = optimset('MaxIter', 50);% You should also try different values of lambdalambda = 1;% Create "short hand" for the cost function to be minimizedcostFunction = @(p) nnCostFunction(p, ... input_layer_size, ... hidden_layer_size, ... num_labels, X, y, lambda);% Now, costFunction is a function that takes in only one argument (the% neural network parameters)[nn_params, cost] = fmincg(costFunction, initial_nn_params, options);% Obtain Theta1 and Theta2 back from nn_paramsTheta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), ... hidden_layer_size, (input_layer_size + 1));Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), ... num_labels, (hidden_layer_size + 1));fprintf('Program paused. Press enter to continue.\n');pause;%% ================= Part 9: Visualize Weights =================% You can now "visualize" what the neural network is learning by % displaying the hidden units to see what features they are capturing in % the data.fprintf('\nVisualizing Neural Network... \n')displayData(Theta1(:, 2:end));fprintf('\nProgram paused. Press enter to continue.\n');pause;%% ================= Part 10: Implement Predict =================% After training the neural network, we would like to use it to predict% the labels. You will now implement the "predict" function to use the% neural network to predict the labels of the training set. This lets% you compute the training set accuracy.pred = predict(Theta1, Theta2, X);fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100); 代码分步讲解 step1: 样本数据的可视化step2: 模型表示，确定神经网络的结构。step3: 初始化参数 $\Theta$step4: Feedforward and compute cost function with regularization.step5: 用 BP 算法计算 $\nabla J(\Theta)，并正则化 regularization$step6: 梯度检查(Gradient Checking)，校验 BP 算法的正确性。step7: 用 fminuncg 函数计算 $J(\Theta)$ 的最优解 $\Theta$step8: 模型评估 step1: 样本数据的可视化 12345678load('ex4data1.mat');m = size(X, 1);% Randomly select 100 data points to displaysel = randperm(size(X, 1));sel = sel(1:100);displayData(X(sel, :)); 其中displayData(X, example_width)代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859function [h, display_array] = displayData(X, example_width)%DISPLAYDATA Display 2D data in a nice grid% [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data% stored in X in a nice grid. It returns the figure handle h and the % displayed array if requested.% Set example_width automatically if not passed inif ~exist('example_width', 'var') || isempty(example_width) example_width = round(sqrt(size(X, 2)));end% Gray Imagecolormap(gray);% Compute rows, cols[m n] = size(X);example_height = (n / example_width);% Compute number of items to displaydisplay_rows = floor(sqrt(m));display_cols = ceil(m / display_rows);% Between images paddingpad = 1;% Setup blank displaydisplay_array = - ones(pad + display_rows * (example_height + pad), ... pad + display_cols * (example_width + pad));% Copy each example into a patch on the display arraycurr_ex = 1;for j = 1:display_rows for i = 1:display_cols if curr_ex &gt; m, break; end % Copy the patch % Get the max value of the patch max_val = max(abs(X(curr_ex, :))); display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ... pad + (i - 1) * (example_width + pad) + (1:example_width)) = ... reshape(X(curr_ex, :), example_height, example_width) / max_val; curr_ex = curr_ex + 1; end if curr_ex &gt; m, break; endend% Display Imageh = imagesc(display_array, [-1 1]);% Do not show axisaxis image offdrawnow;end 随机选择100个样本数据，可视化的结果如下： step2: 模型表示，确定神经网络的结构。建立一个三层的神经网络模型， 123input_layer_size = 400; % 20x20 Input Images of Digitshidden_layer_size = 25; % 25 hidden unitsnum_labels = 10; % 10 labels, from 1 to 10 数据集中的每个样本是$20\times20$即400维的向量，故输入层的单元数设为 400；0~9 共10个数字，即分为10类，故输出层的单元数设为10；隐藏层的单元数设为25；这里所说的单元数均是默认不包括偏置单元(bias unit)的。 step3: 初始化参数$\Theta$ 12345initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size);initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels);% Unroll parametersinitial_nn_params = [initial_Theta1(:) ; initial_Theta2(:)]; 其中的randInitializeWeights(L_in, L_out)代码如下： 123456789101112131415161718function W = randInitializeWeights(L_in, L_out)%RANDINITIALIZEWEIGHTS Randomly initialize the weights of a layer with L_in%incoming connections and L_out outgoing connections% W = RANDINITIALIZEWEIGHTS(L_in, L_out) randomly initializes the weights % of a layer with L_in incoming connections and L_out outgoing % connections. %% Note that W should be set to a matrix of size(L_out, 1 + L_in) as% the first column of W handles the "bias" terms%% You need to return the following variables correctly W = zeros(L_out, 1 + L_in);epsilon_init = sqrt(6)/sqrt(L_in+L_out);W = rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init;end step4: Feedforward and compute cost function with regularization. 1234567891011121314151617181920212223242526272829303132Theta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), ... hidden_layer_size, (input_layer_size + 1));Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), ... num_labels, (hidden_layer_size + 1));% Setup some useful variablesm = size(X, 1); % You need to return the following variables correctly J = 0;Theta1_grad = zeros(size(Theta1));Theta2_grad = zeros(size(Theta2));a_super_1 = [ones(m, 1) X]; % add bias unitz_super_2 = a_super_1 * Theta1';a_super_2 = sigmoid(z_super_2);a_super_2 = [ones(m, 1) a_super_2]; % add bias unitz_super_3 = a_super_2 * Theta2';htheta = sigmoid(z_super_3);J = 0;for k = 1:num_labels y_k = y==k; htheta_k = htheta(:,k); J_k = ( -y_k'*log(htheta_k) - (1-y_k)'*log(1-htheta_k) )/m; J = J + J_k;endregularization = lambda / (2*m) * (sum(sum((Theta1(:,2:end)).^2)) + sum(sum((Theta2(:,2:end)).^2)) );J = J + regularization; step5: 用 BP 算法计算 $\nabla J(\Theta)$，并正则化 regularization 注：$y$ 需要做处理， y=\begin{bmatrix} y_1 \newline y_2 \newline \cdots \newline y_{5000} \newline \end{bmatrix}如 $y_1=3$ 即表示样本为数字3，则将其变为 $y_1=\begin{bmatrix}0 \; 0 \; 1 \; 0 \; 0 \; 0 \; 0 \; 0 \; 0 \; 0 \;\end{bmatrix}$如 $y_2=10$ 即表示样本为数字0，则将其变为 $y_2=\begin{bmatrix}0 \; 0 \; 0 \; 0 \; 0 \; 0 \; 0 \; 0 \; 0 \; 1 \;\end{bmatrix}$ 12345678910111213141516171819for k = 1:num_labels y_binary_k(:,k) = y==k;enddelta_super_3 = htheta - y_binary_k;delta_super_2 = delta_super_3 * Theta2 .* sigmoidGradient([ones(m,1) z_super_2]);delta_super_2 = delta_super_2(:,2:end);Theta1_grad = Theta1_grad + delta_super_2' * a_super_1;Theta2_grad = Theta2_grad + delta_super_3' * a_super_2;Theta1_grad = Theta1_grad/m;Theta2_grad = Theta2_grad/m;Theta1_grad(:, 2:end) = Theta1_grad(:, 2:end) + lambda / m * Theta1(:, 2:end);Theta2_grad(:, 2:end) = Theta2_grad(:, 2:end) + lambda / m * Theta2(:, 2:end);grad = [Theta1_grad(:) ; Theta2_grad(:)]; step6: 梯度检查(Gradient Checking)，校验 BP 算法的正确性。 123456789101112numgrad = zeros(size(theta));perturb = zeros(size(theta));e = 1e-4;for p = 1:numel(theta) % Set perturbation vector perturb(p) = e; loss1 = J(theta - perturb); loss2 = J(theta + perturb); % Compute Numerical Gradient numgrad(p) = (loss2 - loss1) / (2*e); perturb(p) = 0;end step7: 用 fminuncg 函数计算 $J(\Theta)$ 的最优解 $\Theta$ 12345678910111213141516options = optimset('MaxIter', 50);% You should also try different values of lambdalambda = 1;% Create "short hand" for the cost function to be minimizedcostFunction = @(p) nnCostFunction(p, input_layer_size, hidden_layer_size, num_labels, X, y, lambda);% Now, costFunction is a function that takes in only one argument (the% neural network parameters)[nn_params, cost] = fmincg(costFunction, initial_nn_params, options);% Obtain Theta1 and Theta2 back from nn_paramsTheta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), hidden_layer_size, (input_layer_size + 1));Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), num_labels, (hidden_layer_size + 1)); step8: 模型评估 12pred = predict(Theta1, Theta2, X);train_accuracy = mean(double(pred == y)) * 100; 其中predict(Theta1, Theta2, X)代码如下： 1234567891011121314151617function p = predict(Theta1, Theta2, X)%PREDICT Predict the label of an input given a trained neural network% p = PREDICT(Theta1, Theta2, X) outputs the predicted label of X given the% trained weights of a neural network (Theta1, Theta2)% Useful valuesm = size(X, 1);num_labels = size(Theta2, 1);% You need to return the following variables correctly p = zeros(size(X, 1), 1);h1 = sigmoid([ones(m, 1) X] * Theta1');h2 = sigmoid([ones(m, 1) h1] * Theta2');[dummy, p] = max(h2, [], 2);end 参考链接 神经网络浅讲 stanford ml course - Week 5 Lecture Notes]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@过拟合问题]]></title>
    <url>%2Falgorithms%2Fbec21aa6.html</url>
    <content type="text"><![CDATA[overview: regularized linear and logistic regression, overfitting. 概述一般而言，当模型的特征 (feature variables) 非常多，而训练的样本数目 (training set) 又比较少的时候，训练得到的假设函数 (hypothesis function) 能够非常好地匹配训练集中的数据，此时的代价函数 (cost function) 几乎为0。下图中最右侧的那个模型 就是一个过拟合的模型。 过拟合模型的弊端：尽管它几乎能完美匹配训练集中的每一个样本，但其不能很好地对未知的 (新样本实例)input instance 进行预测。通俗地说，就是过拟合模型的预测能力差。 正则化 (Regularization)可以解决过拟合问题。 前面提到，正是因为 feature variable 非常多，导致 hypothesis function 的幂次很高，hypothesis function 变得很复杂(弯弯曲曲的)，从而能穿过每一个样本点(完美匹配每个样本)。如果添加一个”正则化项”，减少高幂次的特征变量的影响，hypothesis function 不就变得平滑了吗？ 正如前面提到，梯度下降算法的目标是最小化 cost function，而现在把 $\theta_3$ 和 $\theta_4$ 的系数设置为1000，设得很大，求偏导数时，相应地得到的 $\theta_3$ 和 $\theta_4$ 就都约等于0了。 更一般地，我们对每一个 $\theta_j \;(j&gt;=1)$ 进行正则化(注：不对 $\theta_0$ 正则化)，就得到了一个新的的代价函数 $\eqref{1-1}$：其中的 $\lambda$ 为正则化参数(regularization parameter) 从上面的 $J(\theta)$ 可以看出：如果 $\lambda=0$ ，则表示没有使用正则化；如果 $\lambda$ 过大，使得模型的各个参数都变得很小，导致$h(x)=\theta_0$，从而造成欠拟合；如果 $\lambda$ 很小，则未充分起到正则化的效果。因此，$\lambda$ 的值要合适。 建模线性回归的过拟合问题Hypothesis: h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\cdots \tag{1-1}\label{1-1}Cost Function \begin{aligned} &J(\theta) = \dfrac{1}{2m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda\ \sum_{j=1}^n \theta_j^2 \\ &\min_\theta J(\theta) \end{aligned} \tag{1-2}\label{1-2}Gradient Descent \begin{align*} & \text{Repeat}\ \lbrace \newline & \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline & \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline & \ \ \ \ \ \ \, \ = \theta_j(1 - \alpha\frac{\lambda}{m}) - \alpha\frac{1}{m} \sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \newline & \rbrace \end{align*} \tag{1-3}\label{1-3}另外$\eqref{1-3}$中， \sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \Rightarrow \text{向量形式为：}X^T(g(X\Theta)-\overrightarrow{y})Normal Equation \begin{align*} & \theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty \newline & \text{where}\ \ L = \begin{bmatrix} 0 & & & & \newline & 1 & & & \newline & & 1 & & \newline & & & \ddots & \newline & & & & 1 \newline \end{bmatrix} \end{align*} \tag{1-4}\label{1-4}Note: 在这里同时列出了 gradient descent 和 normal equation 两种求解 $J(\Theta)$ 最优解 $\Theta$ 的方法，具体可参考这篇文章(@线性回归) 逻辑回归的过拟合问题Hypothesis: h_\theta(x)=g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_1x_2+\theta_5x_2^2+\theta_6x_1^3+\cdots)Cost Function J(\theta) = - \frac{1}{m} \sum_{i=1}^m \large[ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))\large] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2 \tag{2-1}\label{2-1} Note: $\sum_{j=1}^n \theta_j^2$中是不包含 $\theta_0$ 项的。 换句话说，$\overrightarrow{\theta}$是一个$(\theta_0..\theta_n)$的$n+1$维列向量，但公式中第二个$\sum$ 是从$\theta_1$开始的，不包含 $\theta_0$。 Gradient Descent \begin{align*} & \text{Repeat}\ \lbrace \newline & \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline & \ \ \ \ \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J( \theta) \newline & \ \ \ \ \ \ \ \, = \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\rbrace\newline & \rbrace \end{align*} \tag{2-2}\label{2-2}应用该实例来源于 coursera machine learning programming exercise2. 目的用逻辑回归根据芯片的两次测试结果判断芯片是否合格。 DataSet数据集的部分内容如下，完整数据集在这里 microchip test1 microchip test2 Accepted/Rejected 0.051267 0.69956 1 -0.092742 0.68494 1 0.18376 0.93348 0 1.0709 0.10015 0 … … … 完整代码完整代码可在这里下载。 下面只列出其中的主程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114%% Machine Learning Online Class - Exercise 2: Logistic Regression Regularization%% Load Data% The first two columns contains the X values and the third column% contains the label (y).data = load('ex2data2.txt');X = data(:, [1, 2]); y = data(:, 3);plotData(X, y);% Put some labelshold on;% Labels and Legendxlabel('Microchip Test 1')ylabel('Microchip Test 2')% Specified in plot orderlegend('y = 1', 'y = 0')hold off;%% =========== Part 1: Regularized Logistic Regression ============% In this part, you are given a dataset with data points that are not% linearly separable. However, you would still like to use logistic% regression to classify the data points.%% To do so, you introduce more features to use -- in particular, you add% polynomial features to our data matrix (similar to polynomial% regression).%% Add Polynomial Features% Note that mapFeature also adds a column of ones for us, so the intercept% term is handledX = mapFeature(X(:,1), X(:,2));% Initialize fitting parametersinitial_theta = zeros(size(X, 2), 1);% Set regularization parameter lambda to 1lambda = 1;% Compute and display initial cost and gradient for regularized logistic% regression[cost, grad] = costFunctionReg(initial_theta, X, y, lambda);fprintf('Cost at initial theta (zeros): %f\n', cost);fprintf('Expected cost (approx): 0.693\n');fprintf('Gradient at initial theta (zeros) - first five values only:\n');fprintf(' %f \n', grad(1:5));fprintf('Expected gradients (approx) - first five values only:\n');fprintf(' 0.0085\n 0.0188\n 0.0001\n 0.0503\n 0.0115\n');fprintf('\nProgram paused. Press enter to continue.\n');pause;% Compute and display cost and gradient% with all-ones theta and lambda = 10test_theta = ones(size(X,2),1);[cost, grad] = costFunctionReg(test_theta, X, y, 10);fprintf('\nCost at test theta (with lambda = 10): %f\n', cost);fprintf('Expected cost (approx): 3.16\n');fprintf('Gradient at test theta - first five values only:\n');fprintf(' %f \n', grad(1:5));fprintf('Expected gradients (approx) - first five values only:\n');fprintf(' 0.3460\n 0.1614\n 0.1948\n 0.2269\n 0.0922\n');fprintf('\nProgram paused. Press enter to continue.\n');pause;%% ============= Part 2: Regularization and Accuracies =============% Optional Exercise:% In this part, you will get to try different values of lambda and% see how regularization affects the decision coundart%% Try the following values of lambda (0, 1, 10, 100).%% How does the decision boundary change when you vary lambda? How does% the training set accuracy vary?%% Initialize fitting parametersinitial_theta = zeros(size(X, 2), 1);% Set regularization parameter lambda to 1 (you should vary this)lambda = 1;% Set Optionsoptions = optimset('GradObj', 'on', 'MaxIter', 400);% Optimize[theta, J, exit_flag] = ... fminunc(@(t)(costFunctionReg(t, X, y, lambda)), initial_theta, options);% Plot BoundaryplotDecisionBoundary(theta, X, y);hold on;title(sprintf('lambda = %g', lambda))% Labels and Legendxlabel('Microchip Test 1')ylabel('Microchip Test 2')legend('y = 1', 'y = 0', 'Decision boundary')hold off;% Compute accuracy on our training setp = predict(theta, X);fprintf('Train Accuracy: %f\n', mean(double(p == y)) * 100);fprintf('Expected accuracy (with lambda = 1): 83.1 (approx)\n'); 代码分步讲解 step1: 绘制散点图，观察训练集的数据分布。step2: mapFeature。对特征$X$进行预处理，增加 feature 的个数step3: 计算 cost function $J(\Theta)$ 以及 $\nabla J(\Theta)$step4: 调用 Octave/Matalb’s fminunc function 找到 &gt; $J(\Theta)$ 的最优解$\Theta$step5: 绘制 Decision Boundary。step6: 模型评估 step1: 绘制散点图，观察训练集的数据分布。 123456789data = load('ex2data2.txt');X = data(:, [1, 2]); y = data(:, 3);plotData(X, y);hold on;xlabel('Microchip Test 1')ylabel('Microchip Test 2')legend('y = 1', 'y = 0')hold off; 其中plotData(X,y)函数的代码如下： 12345678910111213141516171819function plotData(X, y)%PLOTDATA Plots the data points X and y into a new figure % PLOTDATA(x,y) plots the data points with + for the positive examples% and o for the negative examples. X is assumed to be a Mx2 matrix.% Create New Figurefigure; hold on;% Find indices of Positive and Negativepos = find(y==1);neg = find(y==0);%Plotplot(X(pos, 1), X(pos, 2), 'k+', 'LineWidth', 2, 'MarkerSize', 7);plot(X(neg, 1), X(neg, 2), 'ko', 'MarkerFaceColor', 'y', 'MarkerSize',7);hold off;end step2: mapFeature。对特征$X$进行预处理，增加 feature 的个数 从上图可以猜测出，分类器是非线性的，$\theta_0+\theta_1x_1+\theta_2x_2$ 已无法满足要求，需要对 feature 做些处理，这里将特征的最高维度设为6维。 $\text{origin feature}:X=\begin{bmatrix} 1 \newline x_1 \newline x_2 \end{bmatrix} \quad \Rightarrow \text{after map feature}:X=\begin{bmatrix} 1 \newline x_1 \newline x_2 \newline x_1^2 \newline x_1x_2 \newline x_2^2 \newline x_1^3 \newline \cdots \newline x_1x_2^5 \newline x_2^6 \end{bmatrix}$ 1X = mapFeature(X(:,1), X(:,2)); 其中的 mapFeature(X1, X2) 函数的实现代码如下： 123456789101112131415161718192021function out = mapFeature(X1, X2)% MAPFEATURE Feature mapping function to polynomial features%% MAPFEATURE(X1, X2) maps the two input features% to quadratic features used in the regularization exercise.%% Returns a new feature array with more features, comprising of % X1, X2, X1.^2, X2.^2, X1*X2, X1*X2.^2, etc..%% Inputs X1, X2 must be the same size%degree = 6;out = ones(size(X1(:,1)));for i = 1:degree for j = 0:i out(:, end+1) = (X1.^(i-j)).*(X2.^j); endendend step3: 计算 cost function $J(\Theta)$ 以及 $\nabla J(\Theta)$ note:此处的$J(\Theta)$以及$\nabla J(\Theta)$是带有正规化项的，即使用的是公式$\eqref{1-2}$ 123456789% Initialize fitting parametersinitial_theta = zeros(size(X, 2), 1);% Set regularization parameter lambda to 1lambda = 1;% Compute and display initial cost and gradient for regularized logistic% regression[cost, grad] = costFunctionReg(initial_theta, X, y, lambda); 其中 costFunctionReg(theta, X, y, lambda) 函数的实现代码如下： 123456789101112131415161718function [J, grad] = costFunctionReg(theta, X, y, lambda)%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization% J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using% theta as the parameter for regularized logistic regression and the% gradient of the cost w.r.t. to the parameters. % Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));h = sigmoid(X*theta);J = ( y'*log(h)+(ones(size(y))-y)'*log(ones(size(h))-h) )/(-m) + lambda/(2*m)*(theta(2:length(theta)))'*(theta(2:length(theta)));grad = ( X' * ( h-y ) )/m + ( lambda / m ) * ( [0; ones( length(theta) - 1 , 1 )].*theta );end 其中 sigmoid(z) 函数的代码如下： 12345678910function g = sigmoid(z)%SIGMOID Compute sigmoid function% g = SIGMOID(z) computes the sigmoid of z.% You need to return the following variables correctly g = zeros(size(z));g = 1 ./ (ones(size(z)) + exp(-z));end step4: 调用 Octave/Matalb’s fminunc function 找到 $J(\Theta)$ 的最优解$\Theta$ 123456789101112% Initialize fitting parametersinitial_theta = zeros(size(X, 2), 1);% Set regularization parameter lambda to 1 (you should vary this)lambda = 1;% Set Optionsoptions = optimset('GradObj', 'on', 'MaxIter', 400);% Optimize[theta, J, exit_flag] = ... fminunc(@(t)(costFunctionReg(t, X, y, lambda)), initial_theta, options); step5: 绘制 Decision Boundary。 12345678910plotDecisionBoundary(theta, X, y);hold on;title(sprintf('lambda = %g', lambda))% Labels and Legendxlabel('Microchip Test 1')ylabel('Microchip Test 2')legend('y = 1', 'y = 0', 'Decision boundary')hold off; 其中 plotDecisionBoundary(theta, X, y) 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748function plotDecisionBoundary(theta, X, y)%PLOTDECISIONBOUNDARY Plots the data points X and y into a new figure with%the decision boundary defined by theta% PLOTDECISIONBOUNDARY(theta, X,y) plots the data points with + for the % positive examples and o for the negative examples. X is assumed to be % a either % 1) Mx3 matrix, where the first column is an all-ones column for the % intercept.% 2) MxN, N&gt;3 matrix, where the first column is all-ones% Plot DataplotData(X(:,2:3), y);hold onif size(X, 2) &lt;= 3 % Only need 2 points to define a line, so choose two endpoints plot_x = [min(X(:,2))-2, max(X(:,2))+2]; % Calculate the decision boundary line plot_y = (-1./theta(3)).*(theta(2).*plot_x + theta(1)); % Plot, and adjust axes for better viewing plot(plot_x, plot_y) % Legend, specific for the exercise legend('Admitted', 'Not admitted', 'Decision Boundary') axis([30, 100, 30, 100])else % Here is the grid range u = linspace(-1, 1.5, 50); v = linspace(-1, 1.5, 50); z = zeros(length(u), length(v)); % Evaluate z = theta*x over the grid for i = 1:length(u) for j = 1:length(v) z(i,j) = mapFeature(u(i), v(j))*theta; end end z = z'; % important to transpose z before calling contour % Plot z = 0 % Notice you need to specify the range [0, 0] contour(u, v, z, [0, 0], 'LineWidth', 2)endhold offend $\lambda=0$时，训练出来的模型（hypothesis function）如下：Train Accuracy: 86.440678$\lambda=1$时，训练出来的模型（hypothesis function）如下：Train Accuracy: 83.050847$\lambda=10$时，训练出来的模型（hypothesis function）如下：Train Accuracy: 74.576271$\lambda=100$时，训练出来的模型（hypothesis function）如下：Train Accuracy: 61.016949 可以看出当 $\lambda=100$ 时，已经出现了欠拟合；当$\lambda=0$时，模型与样本的拟合度最好，准确度 train accuracy 最高，由于评估时使用的是训练集(即原样本，不是新样本)，所以模型的准确度 train accuracy 比 $\lambda=1$ 时还要高，但若使用样本评估模型，其准确度将会有所降低，因为从 decision boundary 可以看出模型已经过拟合了。 step6: 模型评估 求得的逻辑回归模型是好还是坏呢？预测效果怎么样？需要拿一组数据测试一下，测试代码如下： 123% Compute accuracy on our training setp = predict(theta, X);% 调用predict函数测试模型train_accuracy = mean(double(p == y)) * 100; 其中的 predict(theta, X) 函数的实现代码如下： 1234567891011121314function p = predict(theta, X)%PREDICT Predict whether the label is 0 or 1 using learned logistic %regression parameters theta% p = PREDICT(theta, X) computes the predictions for X using a % threshold at 0.5 (i.e., if sigmoid(theta'*x) &gt;= 0.5, predict 1)m = size(X, 1); % Number of training examples% You need to return the following variables correctlyp = zeros(m, 1);p = X * theta &gt;= 0;end 原理如下：]]></content>
      <categories>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@逻辑回归]]></title>
    <url>%2Falgorithms%2F309c0b9e.html</url>
    <content type="text"><![CDATA[overview: logistic regression, binary classification, decision boundary, sigmoid function(logistic function), multiclass classification. 二分类问题建模非向量形式Hypothesis \left\{ \begin{aligned} h_{\theta}(x) &= g({\theta}^Tx) \\ z &= {\theta}^Tx \\ g(z) &= \frac{1}{1+e^{-z}} \end{aligned} \right. \tag{1-1}$g(z)$ 的函数图像如下： 其中： $g(z)$ 亦称为 sigmoid function(logistic function)，其值域约束在[0,1]之间。 $h_\theta(x)=P(y=1|x;\theta)$ $P(y=1|x;\theta)+P(y=0|x;\theta)=1$ Cost Function \begin{aligned} J(\theta) &= \frac{1}{m} \sum_{i=1}^mCost(h_{\theta}(x^{(i)},y^{(i)}) \\ &= - \frac{1}{m} \sum_{i=1}^m [y^{(i)} \log (h_{\theta}(x^{(i)}) + (1 - y^{(i)}) \log (1 - h_\theta(x^{(i)}))] \end{aligned} \tag{1-2} \left\{ \begin{aligned} Cost(h_{\theta}(x),y)&=-\log(h_{\theta}(x)) \quad &if \; y=1 \\ Cost(h_{\theta}(x),y)&=-\log(1-h_{\theta}(x)) \quad &if \; y=0 \end{aligned} \right. Gradient Descent \begin{align*} & Repeat \; \lbrace \quad for \; j:=0..n \newline & \; \theta_j := \theta_j - \alpha \dfrac{\partial}{\partial \theta_j}J(\theta) \newline & \rbrace\end{align*}$\Leftrightarrow$ \begin{align*} & Repeat \; \lbrace \quad for \; j:=0..n \newline & \; \theta_j := \theta_j - \frac{\alpha}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \newline & \rbrace \end{align*} \tag{1-3}\label{1-3}式$\eqref{1-3}$的推导过程如下： \begin{align*}\sigma(x)'&=\left(\frac{1}{1+e^{-x}}\right)'=\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}=\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\frac{e^{-x}}{(1+e^{-x})^2} \newline &=\left(\frac{1}{1+e^{-x}}\right)\left(\frac{e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{+1-1 + e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{1 + e^{-x}}{1+e^{-x}} - \frac{1}{1+e^{-x}}\right)=\sigma(x)(1 - \sigma(x))\end{align*} \begin{align*}\frac{\partial}{\partial \theta_j} J(\theta) &= \frac{\partial}{\partial \theta_j} \frac{-1}{m}\sum_{i=1}^m \left [ y^{(i)} log (h_\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\theta(x^{(i)})) \right ] \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} \frac{\partial}{\partial \theta_j} log (h_\theta(x^{(i)})) + (1-y^{(i)}) \frac{\partial}{\partial \theta_j} log (1 - h_\theta(x^{(i)}))\right ] \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ \frac{y^{(i)} \frac{\partial}{\partial \theta_j} h_\theta(x^{(i)})}{h_\theta(x^{(i)})} + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - h_\theta(x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ \frac{y^{(i)} \frac{\partial}{\partial \theta_j} \sigma(\theta^T x^{(i)})}{h_\theta(x^{(i)})} + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - \sigma(\theta^T x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ \frac{y^{(i)} \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})} + \frac{- (1-y^{(i)}) \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ \frac{y^{(i)} h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})} - \frac{(1-y^{(i)}) h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} (1 - h_\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\theta(x^{(i)}) x^{(i)}_j\right ] \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} (1 - h_\theta(x^{(i)})) - (1-y^{(i)}) h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} - y^{(i)} h_\theta(x^{(i)}) - h_\theta(x^{(i)}) + y^{(i)} h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline&= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} - h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline&= \frac{1}{m}\sum_{i=1}^m \left [ h_\theta(x^{(i)}) - y^{(i)} \right ] x^{(i)}_j\end{align*}向量形式Hypothesis h = g(X\Theta) \tag{1-1'}Cost Function J(\Theta)=\frac{1}{m} \cdot (-y^T\log(h)-(1-y^T)\log(1-h)) \tag{1-2'}Gradient Descent$Repeat \; \lbrace$ \Theta:=\Theta-\alpha \frac{1}{m}X^T(g(X\Theta)-\overrightarrow{y}) \tag{1-3'}$\rbrace$ 应用该实例来源于 coursera machine learning programming exercise2. 目的用逻辑回归根据学生的考试成绩来判断学生是否可以入学。 DataSet数据集的部分内容如下，完整数据集在这里 Exam1 Score Exam2 Score Admitted/NotAdmitted 34.62365962451697 78.0246928153624 0 30.28671076822607 43.89499752400101 0 35.84740876993872 72.90219802708364 0 60.18259938620976 86.30855209546826 1 … … … 完整代码完整代码可在这里下载。 下面只列出其中的主程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129%% Machine Learning Online Class - Exercise 2: Logistic Regression%% Load Data% The first two columns contains the exam scores and the third column% contains the label.data = load('ex2data1.txt');X = data(:, [1, 2]); y = data(:, 3);%% ==================== Part 1: Plotting ====================% We start the exercise by first plotting the data to understand the % the problem we are working with.fprintf(['Plotting data with + indicating (y = 1) examples and o ' ... 'indicating (y = 0) examples.\n']);plotData(X, y);% Put some labels hold on;% Labels and Legendxlabel('Exam 1 score')ylabel('Exam 2 score')% Specified in plot ordelegend('Admitted', 'Not admitted');hold off;fprintf('\nProgram paused. Press enter to continue.\n');pause;%% ============ Part 2: Compute Cost and Gradient ============% In this part of the exercise, you will implement the cost and gradient% for logistic regression. You neeed to complete the code in % costFunction.m% Setup the data matrix appropriately, and add ones for the intercept term[m, n] = size(X);% Add intercept term to x and X_testX = [ones(m, 1) X];% Initialize fitting parametersinitial_theta = zeros(n + 1, 1);% Compute and display initial cost and gradient[cost, grad] = costFunction(initial_theta, X, y);fprintf('Cost at initial theta (zeros): %f\n', cost);fprintf('Expected cost (approx): 0.693\n');fprintf('Gradient at initial theta (zeros): \n');fprintf(' %f \n', grad);fprintf('Expected gradients (approx):\n -0.1000\n -12.0092\n -11.2628\n');% Compute and display cost and gradient with non-zero thetatest_theta = [-24; 0.2; 0.2];[cost, grad] = costFunction(test_theta, X, y);fprintf('\nCost at test theta: %f\n', cost);fprintf('Expected cost (approx): 0.218\n');fprintf('Gradient at test theta: \n');fprintf(' %f \n', grad);fprintf('Expected gradients (approx):\n 0.043\n 2.566\n 2.647\n');fprintf('\nProgram paused. Press enter to continue.\n');pause;%% ============= Part 3: Optimizing using fminunc =============% In this exercise, you will use a built-in function (fminunc) to find the% optimal parameters theta.% Set options for fminuncoptions = optimset('GradObj', 'on', 'MaxIter', 400);% Run fminunc to obtain the optimal theta% This function will return theta and the cost [theta, cost] = ... fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);% Print theta to screenfprintf('Cost at theta found by fminunc: %f\n', cost);fprintf('Expected cost (approx): 0.203\n');fprintf('theta: \n');fprintf(' %f \n', theta);fprintf('Expected theta (approx):\n');fprintf(' -25.161\n 0.206\n 0.201\n');% Plot BoundaryplotDecisionBoundary(theta, X, y);% Put some labels hold on;% Labels and Legendxlabel('Exam 1 score')ylabel('Exam 2 score')% Specified in plot orderlegend('Admitted', 'Not admitted')hold off;fprintf('\nProgram paused. Press enter to continue.\n');pause;%% ============== Part 4: Predict and Accuracies ==============% After learning the parameters, you'll like to use it to predict the outcomes% on unseen data. In this part, you will use the logistic regression model% to predict the probability that a student with score 45 on exam 1 and % score 85 on exam 2 will be admitted.%% Furthermore, you will compute the training and test set accuracies of % our model.%% Your task is to complete the code in predict.m% Predict probability for a student with score 45 on exam 1 % and score 85 on exam 2 prob = sigmoid([1 45 85] * theta);fprintf(['For a student with scores 45 and 85, we predict an admission ' ... 'probability of %f\n'], prob);fprintf('Expected value: 0.775 +/- 0.002\n\n');% Compute accuracy on our training setp = predict(theta, X);fprintf('Train Accuracy: %f\n', mean(double(p == y)) * 100);fprintf('Expected accuracy (approx): 89.0\n');fprintf('\n'); 代码分步讲解 step1: 绘制散点图，观察训练集的数据分布step2: 计算 Cost Function $J(\Theta)$，以及梯度$\nabla J(\Theta)$step3: 调用 Octave/Matalb’s fminunc function 找到 $J(\Theta)$ 的最优解 $\Theta$step4: 绘制 Decision Boundarystep5: 模型的评估 step1: 绘制散点图，观察训练集的数据分布。 12345678data = load('ex2data1.txt');X = data(:, [1, 2]); y = data(:, 3);plotData(X, y);hold on;xlabel('Exam 1 score')ylabel('Exam 2 score')legend('Admitted', 'Not admitted');hold off; 其中plotData(X,y)函数的代码如下： 12345678910111213141516171819function plotData(X, y)%PLOTDATA Plots the data points X and y into a new figure % PLOTDATA(x,y) plots the data points with + for the positive examples% and o for the negative examples. X is assumed to be a Mx2 matrix.% Create New Figurefigure; hold on;% Find indices of Positive and Negativepos = find(y==1);neg = find(y==0);%Plotplot(X(pos, 1), X(pos, 2), 'k+', 'LineWidth', 2, 'MarkerSize', 7);plot(X(neg, 1), X(neg, 2), 'ko', 'MarkerFaceColor', 'y', 'MarkerSize',7);hold off;end step2: 计算 Cost Function $J(\Theta)$，以及梯度$\nabla J(\Theta)$ 12345678% Setup the data matrix appropriately, and add ones for the intercept term[m, n] = size(X);% Add intercept term to x and X_testX = [ones(m, 1) X];% Initialize fitting parametersinitial_theta = zeros(n + 1, 1);% Compute and display initial cost and gradient[cost, grad] = costFunction(initial_theta, X, y); 其中costFunction(theta, X, y)的代码如下： 12345678910111213141516function [J, grad] = costFunction(theta, X, y)%COSTFUNCTION Compute cost and gradient for logistic regression% J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the% parameter for logistic regression and the gradient of the cost% w.r.t. to the parameters.% Initialize some useful valuesm = length(y); % number of training examplesJ = 0;grad = zeros(size(theta));% Instructions: Compute the cost of a particular choice of theta.J = ( y' * log(sigmoid(X*theta)) + (ones(size(y))-y)' * log(ones(size(X*theta))-sigmoid(X*theta)) )/(-m);grad = ( X'*(sigmoid(X*theta)-y) )/m;end 其中sigmoid(z)的代码如下： 1234567function g = sigmoid(z)%SIGMOID Compute sigmoid function% g = SIGMOID(z) computes the sigmoid of z.g = 1 ./ (ones(size(z)) + exp(-z));end step3: 调用 Octave/Matalb’s fminunc function 找到 $J(\Theta)$ 的最优解 $\Theta$ 在线性回归中，我们通过自己编写 matlab 代码,如: @线性回归。本文我们通过使用 Octave/Matalb 中内嵌的 fminunc function，去求得最优解 $\Theta$，而不是自己使用 Gradient descent 在 for 循环求导来计算 $\Theta$。 12345678910% use a built-in function (fminunc) to find the% optimal parameters theta.% Set options for fminuncoptions = optimset('GradObj', 'on', 'MaxIter', 400);% Run fminunc to obtain the optimal theta% This function will return theta and the cost [theta, cost] = ... fminunc(@(t)(costFunction(t, X, y)), initial_theta, options); step4: 绘制 Decision Boundary。 123456789101112% Plot BoundaryplotDecisionBoundary(theta, X, y);% Put some labels hold on;% Labels and Legendxlabel('Exam 1 score')ylabel('Exam 2 score')% Specified in plot orderlegend('Admitted', 'Not admitted')hold off; 其中的plotDecisionBoundary(theta, X, y) 函数实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748function plotDecisionBoundary(theta, X, y)%PLOTDECISIONBOUNDARY Plots the data points X and y into a new figure with%the decision boundary defined by theta% PLOTDECISIONBOUNDARY(theta, X,y) plots the data points with + for the % positive examples and o for the negative examples. X is assumed to be % a either % 1) Mx3 matrix, where the first column is an all-ones column for the % intercept.% 2) MxN, N&gt;3 matrix, where the first column is all-ones% Plot DataplotData(X(:,2:3), y);hold onif size(X, 2) &lt;= 3 % Only need 2 points to define a line, so choose two endpoints plot_x = [min(X(:,2))-2, max(X(:,2))+2]; % Calculate the decision boundary line plot_y = (-1./theta(3)).*(theta(2).*plot_x + theta(1)); % Plot, and adjust axes for better viewing plot(plot_x, plot_y) % Legend, specific for the exercise legend('Admitted', 'Not admitted', 'Decision Boundary') axis([30, 100, 30, 100])else % Here is the grid range u = linspace(-1, 1.5, 50); v = linspace(-1, 1.5, 50); z = zeros(length(u), length(v)); % Evaluate z = theta*x over the grid for i = 1:length(u) for j = 1:length(v) z(i,j) = mapFeature(u(i), v(j))*theta; end end z = z'; % important to transpose z before calling contour % Plot z = 0 % Notice you need to specify the range [0, 0] contour(u, v, z, [0, 0], 'LineWidth', 2)endhold offend 其中的mapFeature(X1, X2)函数的实现代码如下： 123456789101112131415161718192021function out = mapFeature(X1, X2)% MAPFEATURE Feature mapping function to polynomial features%% MAPFEATURE(X1, X2) maps the two input features% to quadratic features used in the regularization exercise.%% Returns a new feature array with more features, comprising of % X1, X2, X1.^2, X2.^2, X1*X2, X1*X2.^2, etc..%% Inputs X1, X2 must be the same size%degree = 6;out = ones(size(X1(:,1)));for i = 1:degree for j = 0:i out(:, end+1) = (X1.^(i-j)).*(X2.^j); endendend step5: 模型的评估 求得的逻辑回归模型是好还是坏呢？预测效果怎么样？需要拿一组数据测试一下，测试代码如下： 1234prob = sigmoid([1 45 85] * theta); %这是一组测试数据，第一次考试成绩为45，第二次成绩为85% Compute accuracy on our training setp = predict(theta, X);% 调用predict函数测试模型train_accuracy = mean(double(p == y)) * 100; 其中的 predict(theta, X) 函数的实现代码如下： 1234567891011121314function p = predict(theta, X)%PREDICT Predict whether the label is 0 or 1 using learned logistic %regression parameters theta% p = PREDICT(theta, X) computes the predictions for X using a % threshold at 0.5 (i.e., if sigmoid(theta'*x) &gt;= 0.5, predict 1)m = size(X, 1); % Number of training examples% You need to return the following variables correctlyp = zeros(m, 1);p = X * theta &gt;= 0;end 原理如下： 多分类问题逻辑回归如何处理多分类问题？ 所谓 one-vs-all method 就是将二分类问题的方法应用到多分类问题中。比如: 我想分成$K$类。那么就将其中一类作为positive，另$k-1$合起来作为negative，这样进行$K$个$h_{\Theta}(X)$的参数优化； \begin{align*}& y \in \lbrace0, 1 ... n\rbrace \newline& h_\theta^{(0)}(x) = P(y = 0 | x ; \theta) \newline& h_\theta^{(1)}(x) = P(y = 1 | x ; \theta) \newline& \cdots \newline& h_\theta^{(n)}(x) = P(y = n | x ; \theta) \newline& \mathrm{prediction} = \max_i( h_\theta ^{(i)}(x) )\newline\end{align*} \tag{2-1}每次得到的一个 $h_{\Theta}(X)$ 是指给定 $\Theta$ 和 $X$，它属于positive的类的概率。 给定一个输入向量 $X$，获得 $\max h_\Theta(X)$ 的类就是 $X$ 所分到的类。 所谓多分类问题，是指分类的结果为三类以上。比如，预测明天的天气结果为三类：晴(用 y==1 表示)、阴（用 y==2表示）、雨（用 y==3表示） 分类的思想，其实与逻辑回归分类(默认是指二分类，binary classification)很相似，对“晴天”进行分类时，将另外两类(阴天和下雨)视为一类：(非晴天)，这样，就把一个多分类问题转化成了二分类问题。示意图如下：(图中的圆圈 表示：不属于某一类的 所有其他类) 应用目的用逻辑回归实现多分类问题：识别手写的阿拉伯数字(0~9)。 DataSet完整数据集在这里下载。一共有 5000 个训练样本，每个样本是400维的向量（$20\times20$像素的 grayscale image），用矩阵 $X$ 保存。样本的结果(label of training set)保存在向量 $\overrightarrow{y}$ 中，$\overrightarrow{y}$ 是一个 $5000 \times 1$ 的列向量。 完整代码完整代码可在这里下载。 下面只列出其中的主程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768%% Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all%% Setup the parameters you will use for this part of the exerciseinput_layer_size = 400; % 20x20 Input Images of Digitsnum_labels = 10; % 10 labels, from 1 to 10 % (note that we have mapped "0" to label 10)%% =========== Part 1: Loading and Visualizing Data =============% We start the exercise by first loading and visualizing the dataset.% You will be working with a dataset that contains handwritten digits.%% Load Training Datafprintf('Loading and Visualizing Data ...\n')load('ex3data1.mat'); % training data stored in arrays X, ym = size(X, 1);% Randomly select 100 data points to displayrand_indices = randperm(m);sel = X(rand_indices(1:100), :);displayData(sel);fprintf('Program paused. Press enter to continue.\n');pause;%% ============ Part 2a: Vectorize Logistic Regression ============% In this part of the exercise, you will reuse your logistic regression% code from the last exercise. You task here is to make sure that your% regularized logistic regression implementation is vectorized. After% that, you will implement one-vs-all classification for the handwritten% digit dataset.%% Test case for lrCostFunctionfprintf('\nTesting lrCostFunction() with regularization');theta_t = [-2; -1; 1; 2];X_t = [ones(5,1) reshape(1:15,5,3)/10];y_t = ([1;0;1;0;1] &gt;= 0.5);lambda_t = 3;[J grad] = lrCostFunction(theta_t, X_t, y_t, lambda_t);fprintf('\nCost: %f\n', J);fprintf('Expected cost: 2.534819\n');fprintf('Gradients:\n');fprintf(' %f \n', grad);fprintf('Expected gradients:\n');fprintf(' 0.146561\n -0.548558\n 0.724722\n 1.398003\n');fprintf('Program paused. Press enter to continue.\n');pause;%% ============ Part 2b: One-vs-All Training ============fprintf('\nTraining One-vs-All Logistic Regression...\n')lambda = 0.1;[all_theta] = oneVsAll(X, y, num_labels, lambda);fprintf('Program paused. Press enter to continue.\n');pause;%% ================ Part 3: Predict for One-Vs-All ================pred = predictOneVsAll(all_theta, X);fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100); 代码分步讲解 step1: 样本数据的可视化step2: 计算 Cost Function $J(\Theta)$，以及梯度$\nabla J(\Theta)$step3: 用 one-vs-all 方法实现多分类。调用 Octave/Matalb’s fminuncg function 求出所有分类器的最优解 $\Theta$step4: 模型的评估 step1: 样本数据的可视化 1234567load('ex3data1.mat'); % training data stored in arrays X, ym = size(X, 1);% Randomly select 100 data points to displayrand_indices = randperm(m);sel = X(rand_indices(1:100), :);displayData(sel); 其中 displayData(X, example_width) 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859function [h, display_array] = displayData(X, example_width)%DISPLAYDATA Display 2D data in a nice grid% [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data% stored in X in a nice grid. It returns the figure handle h and the % displayed array if requested.% Set example_width automatically if not passed inif ~exist('example_width', 'var') || isempty(example_width) example_width = round(sqrt(size(X, 2)));end% Gray Imagecolormap(gray);% Compute rows, cols[m n] = size(X);example_height = (n / example_width);% Compute number of items to displaydisplay_rows = floor(sqrt(m));display_cols = ceil(m / display_rows);% Between images paddingpad = 1;% Setup blank displaydisplay_array = - ones(pad + display_rows * (example_height + pad), ... pad + display_cols * (example_width + pad));% Copy each example into a patch on the display arraycurr_ex = 1;for j = 1:display_rows for i = 1:display_cols if curr_ex &gt; m, break; end % Copy the patch % Get the max value of the patch max_val = max(abs(X(curr_ex, :))); display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ... pad + (i - 1) * (example_width + pad) + (1:example_width)) = ... reshape(X(curr_ex, :), example_height, example_width) / max_val; curr_ex = curr_ex + 1; end if curr_ex &gt; m, break; endend% Display Imageh = imagesc(display_array, [-1 1]);% Do not show axisaxis image offdrawnow;end 随机选择100个样本数据，使用Matlab可视化的结果如下： step2: 计算 Cost Function $J(\Theta)$，以及梯度$\nabla J(\Theta)$ 1234567891011121314151617181920212223function [J, grad] = lrCostFunction(theta, X, y, lambda)%LRCOSTFUNCTION Compute cost and gradient for logistic regression with %regularization% J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using% theta as the parameter for regularized logistic regression and the% gradient of the cost w.r.t. to the parameters. % Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));h = sigmoid(X*theta);J = ( y'*log(h)+(ones(size(y))-y)'*log(ones(size(h))-h) )/(-m) + lambda/(2*m)*(theta(2:length(theta)))'*(theta(2:length(theta)));grad = ( X' * ( h-y ) )/m + ( lambda / m ) * ( [0; ones( length(theta) - 1 , 1 )].*theta );grad = grad(:);end 用 one-vs-all 方法实现多分类。调用 Octave/Matalb’s fminuncg function 求出所有分类器的最优解 $\Theta$ 12lambda = 0.1;[all_theta] = oneVsAll(X, y, num_labels, lambda); 其中 oneVsAll(X, y, num_labels, lambda) 的代码如下： 12345678910111213141516171819202122232425262728function [all_theta] = oneVsAll(X, y, num_labels, lambda)%ONEVSALL trains multiple logistic regression classifiers and returns all%the classifiers in a matrix all_theta, where the i-th row of all_theta %corresponds to the classifier for label i% [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels% logistic regression classifiers and returns each of these classifiers% in a matrix all_theta, where the i-th row of all_theta corresponds % to the classifier for label i% Some useful variablesm = size(X, 1);n = size(X, 2);% You need to return the following variables correctly all_theta = zeros(num_labels, n + 1);% Add ones to the X data matrixX = [ones(m, 1) X];initial_theta = zeros(n+1,1);options = optimset('GradObj','on','MaxIter',50);for c = 1:num_labels %num_labels 为逻辑回归训练器的个数，num of logistic regression classifiers all_theta(c, :) = fmincg(@(t)(lrCostFunction(t, X, (y == c),lambda)), initial_theta,options );endend step4: 模型的评估对于 $N$ 分类问题(N&gt;=3)，就需要 $N$ 个假设函数(预测模型)，也即需要 $N$ 组模型参数 $\Theta$（$\Theta$一般是一个向量） 然后，对于每个样本实例，依次使用每个模型预测输出，选取输出值最大的那组模型所对应的预测结果作为最终结果。 因为模型的输出值，在sigmoid函数作用下，其实是一个概率值。 12pred = predictOneVsAll(all_theta, X);tarin_accuracy = mean(double(pred == y)) * 100 其中 predictOneVsAll(all_theta, X) 代码如下： 12345678910111213141516171819202122function p = predictOneVsAll(all_theta, X)%PREDICT Predict the label for a trained one-vs-all classifier. The labels %are in the range 1..K, where K = size(all_theta, 1). % p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions% for each example in the matrix X. Note that X contains the examples in% rows. all_theta is a matrix where the i-th row is a trained logistic% regression theta vector for the i-th class. You should set p to a vector% of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2% for 4 examples) m = size(X, 1);num_labels = size(all_theta, 1);% You need to return the following variables correctly p = zeros(size(X, 1), 1);% Add ones to the X data matrixX = [ones(m, 1) X];[~,p] = max( X * all_theta',[],2); % 求矩阵(X*all_theta')每行的最大值，p 记录矩阵每行的最大值的索引end 关于优化算法Optimization Algorithms: Gradient Descent Conjugate Descent BFGS L-BFGS 后三种算法相比于 Gradient Descent：Advantages: No need to manually pick $\alpha$ often faster than Gradient Descent Disadvantage: more complex Note: 在线性回归和逻辑回归中，我们用到了两种优化算法 Gradient Descent(梯度下降法)和 Normal Equation(正规方程)。 参考链接 Stanford coursera Andrew Ng 机器学习课程编程作业（Exercise 2）及总结 ML Week 3 Lecture Notes — Stanford coursera Andrew Ng stanford coursera 机器学习编程作业 exercise 3（逻辑回归实现多分类问题）]]></content>
      <categories>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Octave tutorial]]></title>
    <url>%2Flanguages%2F65516c6f.html</url>
    <content type="text"><![CDATA[Octave 是 Standard ML 公开课建议的初学者学习ML 的编程语言，其语法特性和 Matlab 几乎一样，但前者是开源的，免费的。本文内容转自该课的 Lecture Notes. Basic Operations12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455%% Change Octave promptPS1('&gt;&gt; ');%% Change working directory in mac example:cd Users/your username/desktop%% elementary operations5+63-25*81/22^61 == 2 % false1 ~= 2 % true. note, not "!="1 &amp;&amp; 01 || 0xor(1,0)%% variable assignmenta = 3; % 句尾加分号则不会立即将结果输出到 terminal 上，而是保存在内存中b = 'hi';c = 3&gt;=1;%% Displaying them:a = pidisp(a)disp(sprintf('2 decimals: %0.2f',a))disp(sprintf('6 decimals: %0.6f',a))format longaformat shorta%% vectors and matricesA = [1 2; 3 4; 5 6]v = [1 2 3]v = [1; 2; 3]v = 1:0.1:2 % from 1 to 2, with stepsize of 0.1. Useful for plot axes.v = 1:6 %from 1 to 6, with stepsize of 1(row vector)C = 2*ones(2,3) % same as C = [2 2 2; 2 2 2]w = ones(1,3) % 1×3 vector of onesw = zeros(1,3)w = rand(1,3) % draw from a uniform distributionw = randn(1,3) % drawn from a normal distributionw = -6 + sqrt(10)*(randn(1,10000));hist(w) % plot histogram using 10bins (default)hist(w, 50)% note: if hist() crashes, try "graphics_toolkit('gnu_plot')" I = eye(4) % 4×4 identity matrix% help function help eyehelp randhelp help Moving Data AroundData files used in this section: featuresX.dat, priceY.dat 12345678910111213141516171819202122232425262728293031%% dimensionssz = size(A) % 1x2 matrix: [(number of rows) (number of columns)]size(A,1) % number of rowssize(A,2) % number of columnslength(v) % size of longest dimension%% loading dataload('q1x.dat')load q1y.datwho % list variables in workspacewhos % list variables in workspace(detailed view)v = q1x(1:10) % first 10 elements of q1x(counts down the columns)save hello.mat v % save variable v into file hello.matsave hello.txt v -ascii % save as ascii% fopen, fread, fprintf, fscanf also work%% indexing A(3,2) % indexing is (row,column)A(2,:) % get the 2nd rowA(:,2) % get the 2nd columnA([1,3],:) % print all the elements of rows 1 and 3.A(:,2) = [10; 11; 12] % change second rowA = [A, [100; 101; 102]]; %append column vec 分块矩阵A(:) %select all elements as a column vector% Putting data togentherA = [1 2; 3 4; 5 6]B = [11 12; 13 14; 15 16]C = [A B] % concatenating A and B matrices side by sideC = [A, B] % concatenating A and B matrices side by sideC = [A; B] % concatenating A and B top and bottom Computing on Data12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152%% initialize variabelsA = [1 2; 3 4; 5 6]B = [11 12; 13 14; 15 16]C = [1 1; 2 2]v = [1;2;3]%% matrix operations A * C % matrix multiplicationA .* B % element-wise multiplicationA .^ 2 % element-wise square of each element in A1./v % element-wise reciprocallog(v) % functions like this operate element-wise on vecs or matricesexp(v)abs(v)-v % -1*vv + ones(length(v),1)% 上式等价于 v+1A' % matrix transpose%% misc useful functions% max (or min)a = [1 15 2 0.5]val = max(a)val = max(A) % if A a matrix, returns max from from each column% compare values in a matrix &amp; finda &lt; 3 % checks which values in a are less than 3find(a &lt; 3) % gives location of elements less than 3A = magic(3) % generates a magic matrix - not much used in ML algorithms[r,c] = find(A&gt;=7) % row, column indices for values matching comparison% sum, prodsum(a)prod(a)floor(a) % or ceil(a)max(rand(3),rand(3))max(A,[],1) - maximum along columns(defaults to columns - max(A,[]))max(A,[],2) - maximum along rowsA = magic(9)sum(A,1)sum(A,2)sum(sum( A .* eye(9) ))sum(sum( A .* flipud(eye(9)) ))% Matrix inverse (pseudo-inverse)pinv(A) % inv(A'*A)*A' Plotting Data12345678910111213141516171819202122232425262728%% plotting t = [0:0.01:0.98];y1 = sin(2*pi*4*t);plot(t, y1);y2 = cos(2*pi*4*t);hold on; % "hold off" to turn offplot(t,y2,'r');xlabel('time');ylabel('value');legend('sin','cos');title('my plot');print -dpng 'myPlot.png'close; % or, "close all" to close all figsfigure(1); plot(t, y1);figure(2); plot(t, y2);figure(2), clf; % can specify the figure numbersubplot(1,2,1); % Divide plot into 1x2 grid, access 1st elementplot(t,y1);subplot(1,2,2); % Divide plot into 1x2 grid, access 2nd elementplot(t,y2);axis([0.5 1 -1 1]); % change axis scale%% display a matrix (or image) figure;imagesc(magic(15)), colorbar, colormap gray;% comma-chaining function calls. a=1,b=2,c=3a=1;b=2;c=3; Control statements: for, while, if statement12345678910111213141516171819v = zeros(10,1)for i=1:10, v(i)=2^iend% can also use "break" and "continue" inside for an while loops to control executioni = 1;while i &lt;= 5, v(i) = 100; i = i+1;endif v(1)==1, disp('The value is one!');elseif v(1)==2, disp('The value is two!');else disp('The value is not one or two!');end FunctionsExample function: 123function y = squareThisNumber(x)y = x^2; To call the function in Octave, Navigate to the directory of the function functionName.m file and call the function 12345% Navigate to directorycd /Users/username/Desktop/function folder% call the functionfunctionName(args) Add the directory of the function to the load path and save it. 12345% To add the path for the current session of octaveaddpath('/Users/username/Desktop/function folder')% To remember the path for future sessions of Octave, also do:savepath Octave’s function can return more than one value: 1234function [y1,y2] = squareandCubeThisNo(x)y1 = x^2;y2 = x^3; Call the above function this way: 1[a,b] = squareandCubeThisNo(x) VectorizationVectorization is the process of talking code that relies on loops and converting it into matrix operations. It is more efficient, more elegant, and more concise. With loops: 1234prediction = 0.0;for j = 1:n+1, prediction += theta(j)*x(j);end; With Vectorization: 1prediction = theta' * x; 参考链接 machine learning week2 lecture Notes — coursera Octave Docs]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>octave</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@解决Hexo对mathjax中部分公式无法正常解析的问题]]></title>
    <url>%2Fmanual%2F8d6d20a0.html</url>
    <content type="text"><![CDATA[解决Hexo和MathJax的兼容问题。 问题先重现以下问题，在写博文的时候，我码了一个公式： 1$$J(\theta_0,\theta_1)=\frac&#123;1&#125;&#123;2m&#125; \sum_&#123;i=1&#125;^&#123;m&#125; ( h_&#123;\theta&#125;(x^&#123;(i)&#125;)-y^&#123;(i)&#125; )^2 \quad (for \, j=0 \; and \; j=1)$$ 如果一切正常的话，应该渲染成这样： 但事与愿违，无法正常解析。 解决方案简单来说，要让你的Hexo支持MathJax渲染公式，你只需要使用两条命令：To fully support MathJax in your Hexo blog, you can simply use the following commands: 12$ npm uninstall hexo-renderer-marked --save$ npm install hexo-renderer-kramed --save 第一条命令用于卸载 hexo-renderer-marked（注意，如果你使用了其他的渲染插件，请卸载对应的插件），它是hexo自带的Markdown渲染引擎。The first command uninstall Hexo’s default Markdown renderer. 第二条命令用于安装 hexo-renderer-kramed 插件，这个渲染插件针对MathJax支持进行了改进。安装完成后，重新生成博客就会惊喜地发现你的公式已经能够正常显示了。The second command install new Markdown renderer which can support MathJax fully. After installation, you should regenerate your blog to see the changes. 另外，要确保主题配置文件博客根目录/themes/next/_config.yml开启了 MathJax 渲染： 1234567# Math Equations Render Supportmath: enable: enable per_page: false engine: mathjax mathjax: cdn: //cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML 若 per_page为 true，则 hexo 默认会对所有页面渲染 MathJax；若 per_page为 false，则 hexo 只会对 markdown 文件头部包含 mathjax: true 的博文。## 参考链接 如何处理Hexo和MathJax的兼容问题 | 林肯先生的Blog]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@线性回归]]></title>
    <url>%2Falgorithms%2F91fff0b1.html</url>
    <content type="text"><![CDATA[overview: linear regression with one variable or multiple variables, gradient descent, normal equation, feature scaling, contour plot. Example Input x Output y 0 2 1 4 2 6 3 8 从表中的数据，可以用 $h_{\theta}(x)=2+2x$，拟合表中的数据。于是当给定一个新的输入，如 $x=4$，可以预测出输出 $y=2+2*4=10$ 一元线性回归建模Hypothesis: h_{\theta}(x)=\theta_0+\theta_1x \tag{1-1}Cost Function: J(\theta_0,\theta_1)=\frac{1}{2m} \sum_{i=1}^{m} ( h_{\theta}(x^{(i)})-y^{(i)} )^2 \quad (for \, j=0 \; and \; j=1) \tag{1-2}Gradient Descent: \theta_j:=\theta_j-\alpha \frac{\partial}{\partial \theta_j} J(\theta_0,\theta_1) \tag{1-3}\label{1-3}其中，公式$\eqref{1-3}$即， \begin{aligned} & repeat \, until \, convergence: \lbrace \quad for \; j:=0..n \newline & \ \ \ \ \theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)}) \newline & \ \ \ \ \theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x^{(i)} \newline &\rbrace \end{aligned}另外，$\alpha$ 为 learning rate. 应用该实例来源于 coursera machine learning programming exercise1. 目的：实现单变量的线性回归 有一组历史数据[城市人口, 分店利润]。如果你需要在别的城市开一家分店，经过调查，你发现利润与城市的人口有关，现需要根据已掌握的数据，去预测在 A 市开分店的收益会如何？（即告诉你 A 市的人口，利用拟合出的模型，去预测可能的利润） DataSet 数据集的部分内容如下，完整数据集在这里。 Population of a city (x) Profit of a food truck in that city (y) 6.1101 17.592 5.5277 9.1302 8.5186 13.662 … … 说明：第一列表示城市人口数，单位为万人；第二列表示利润，单位为10000$ 完整代码完整代码可在这里下载。 下面只列出其中的主程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115%% Linear regression with one variable% x refers to the population size in 10,000s% y refers to the profit in $10,000s%%% Initializationclear ; close all; clc%% ==================== Part 1: Basic Function ====================% Complete warmUpExercise.mfprintf('Running warmUpExercise ... \n');fprintf('5x5 Identity Matrix: \n');warmUpExercise()fprintf('Program paused. Press enter to continue.\n');pause;%% ======================= Part 2: Plotting =======================fprintf('Plotting Data ...\n')data = load('ex1data1.txt');X = data(:, 1); y = data(:, 2);m = length(y); % number of training examples% Plot Data% Note: You have to complete the code in plotData.mplotData(X, y);fprintf('Program paused. Press enter to continue.\n');pause;%% =================== Part 3: Cost and Gradient descent ===================X = [ones(m, 1), data(:,1)]; % Add a column of ones to xtheta = zeros(2, 1); % initialize fitting parameters% Some gradient descent settingsiterations = 1500;alpha = 0.01;fprintf('\nTesting the cost function ...\n')% compute and display initial costJ = computeCost(X, y, theta);fprintf('With theta = [0 ; 0]\nCost computed = %f\n', J);fprintf('Expected cost value (approx) 32.07\n');% further testing of the cost functionJ = computeCost(X, y, [-1 ; 2]);fprintf('\nWith theta = [-1 ; 2]\nCost computed = %f\n', J);fprintf('Expected cost value (approx) 54.24\n');fprintf('Program paused. Press enter to continue.\n');pause;fprintf('\nRunning Gradient Descent ...\n')% run gradient descenttheta = gradientDescent(X, y, theta, alpha, iterations);% print theta to screenfprintf('Theta found by gradient descent:\n');fprintf('%f\n', theta);fprintf('Expected theta values (approx)\n');fprintf(' -3.6303\n 1.1664\n\n');% Plot the linear fithold on; % keep previous plot visibleplot(X(:,2), X*theta, '-')legend('Training data', 'Linear regression')hold off % don't overlay any more plots on this figure% Predict values for population sizes of 35,000 and 70,000predict1 = [1, 3.5] *theta;fprintf('For population = 35,000, we predict a profit of %f\n',... predict1*10000);predict2 = [1, 7] * theta;fprintf('For population = 70,000, we predict a profit of %f\n',... predict2*10000);fprintf('Program paused. Press enter to continue.\n');pause;%% ============= Part 4: Visualizing J(theta_0, theta_1) =============fprintf('Visualizing J(theta_0, theta_1) ...\n')% Grid over which we will calculate Jtheta0_vals = linspace(-10, 10, 100);theta1_vals = linspace(-1, 4, 100);% initialize J_vals to a matrix of 0'sJ_vals = zeros(length(theta0_vals), length(theta1_vals));% Fill out J_valsfor i = 1:length(theta0_vals) for j = 1:length(theta1_vals) t = [theta0_vals(i); theta1_vals(j)]; J_vals(i,j) = computeCost(X, y, t); endend% Because of the way meshgrids work in the surf command, we need to% transpose J_vals before calling surf, or else the axes will be flippedJ_vals = J_vals';% Surface plotfigure;surf(theta0_vals, theta1_vals, J_vals)xlabel('\theta_0'); ylabel('\theta_1');% Contour plotfigure;% Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100contour(theta0_vals, theta1_vals, J_vals, logspace(-2, 3, 20))xlabel('\theta_0'); ylabel('\theta_1');hold on;plot(theta(1), theta(2), 'rx', 'MarkerSize', 10, 'LineWidth', 2); 代码分步讲解 step1: 绘制散点图，观察训练集的数据分布。 12345678data = load('ex1data1.txt');X = data(:, 1); y = data(:, 2);m = length(y); % number of training examplesfigure; % open a new figure windowplot(x,y,'rx','MarkerSize',10);xlabel('Population of City in 10,000s');ylabel('Profit in $10,000s'); step2: Computing cost function $J(\theta)$ 1234567891011121314151617X = [ones(m, 1), data(:,1)]; % Add a column of ones to xtheta = zeros(2, 1); % initialize fitting parameters% Some gradient descent settingsiterations = 1500;alpha = 0.01;fprintf('\nTesting the cost function ...\n')% compute and display initial costJ = computeCost(X, y, theta);fprintf('With theta = [0 ; 0]\nCost computed = %f\n', J);fprintf('Expected cost value (approx) 32.07\n');% further testing of the cost functionJ = computeCost(X, y, [-1 ; 2]);fprintf('\nWith theta = [-1 ; 2]\nCost computed = %f\n', J);fprintf('Expected cost value (approx) 54.24\n'); 上面代码中的 computeCost(X, y, theta) 函数的代码如下： 123456789101112131415function J = computeCost(X, y, theta)%COMPUTECOST Compute cost for linear regression% J = COMPUTECOST(X, y, theta) computes the cost of using theta as the% parameter for linear regression to fit the data points in X and ym = length(y); % number of training examplesJ = 0;h = X * theta;for i=1:m, J = J + (h(i)-y(i))^2;end;J = J/(2*m);end step3: 用 gradient descent 找到 $J(\theta)$ 的最优解 $(\theta_0, \theta_1)$ 本例中即找出合适的 $(\theta_0, \theta_1)$，使得 $J(\theta)$ 最小(或者说在允许的差值范围内) 1234567fprintf('\nRunning Gradient Descent ...\n')% run gradient descenttheta = gradientDescent(X, y, theta, alpha, iterations);% print theta to screenfprintf('Theta found by gradient descent:\n');fprintf('%f\n', theta); 上面代码中 gradientDescent(X, y, theta, alpha, iterations) 函数的代码如下： 12345678910111213141516function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)%GRADIENTDESCENT Performs gradient descent to learn theta% theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by % taking num_iters gradient steps with learning rate alpha% Initialize some useful valuesm = length(y); % number of training examplesJ_history = zeros(num_iters, 1);for iter = 1:num_iters, theta = theta - X' * alpha / m * (X *theta - y); % Save the cost J in every iteration J_history(iter) = computeCost(X, y, theta);endend step4: 绘制拟合出的线性回归模型 $h_{\theta}(x)$ 12345% Plot the linear fithold on; % keep previous plot visibleplot(X(:,2), X*theta, '-')legend('Training data', 'Linear regression')hold off % don't overlay any more plots on this figure step5: 预测 预测分店开在人口为 35,000 and 70,000 城市的利润 123456predict1 = [1, 3.5] *theta;fprintf('For population = 35,000, we predict a profit of %f\n',... predict1*10000);predict2 = [1, 7] * theta;fprintf('For population = 70,000, we predict a profit of %f\n',... predict2*10000); (optional)step6: 绘制 $J(\theta)$。观察其在不同 $(\theta_0,\theta_1)$ 下的值 1234567891011121314151617181920212223242526272829303132fprintf('Visualizing J(theta_0, theta_1) ...\n')% Grid over which we will calculate Jtheta0_vals = linspace(-10, 10, 100);theta1_vals = linspace(-1, 4, 100);% initialize J_vals to a matrix of 0'sJ_vals = zeros(length(theta0_vals), length(theta1_vals));% Fill out J_valsfor i = 1:length(theta0_vals) for j = 1:length(theta1_vals) t = [theta0_vals(i); theta1_vals(j)]; J_vals(i,j) = computeCost(X, y, t); endend% Because of the way meshgrids work in the surf command, we need to% transpose J_vals before calling surf, or else the axes will be flippedJ_vals = J_vals';% Surface plotfigure;surf(theta0_vals, theta1_vals, J_vals)xlabel('\theta_0'); ylabel('\theta_1');% Contour plotfigure;% Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100contour(theta0_vals, theta1_vals, J_vals, logspace(-2, 3, 20))xlabel('\theta_0'); ylabel('\theta_1');hold on;plot(theta(1), theta(2), 'rx', 'MarkerSize', 10, 'LineWidth', 2); 多元线性回归建模非向量形式写法 Hypothesis: h_{\theta}(x)=\theta_0+\theta_1x+\theta_2x+\cdots+\theta_nx_n \tag{2-1}\label{2-1} Cost Function: J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2 \tag{2-2}\label{2-2} Gradient Descent: \theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta) \quad for \, j=1..n \tag{2-3}\label{2-3} 公式 $\eqref{2-3}$即： \begin{aligned} & repeat \, until \, convergence:\lbrace \newline & \ \ \ \ \theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)}) \cdot x_0^{(i)} \newline & \ \ \ \ \theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)}) \cdot x_1^{(i)} \newline & \ \ \ \ \theta_2:=\theta_2-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)}) \cdot x_2^{(i)} \newline & \ \ \ \ \cdots \newline & \rbrace \end{aligned}$\Leftrightarrow$ \begin{aligned} & repeat \, until \, convergence:\lbrace \quad for \, j:=0..n\newline & \ \ \ \ \theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)}) \cdot x_j^{(i)} \newline & \rbrace \end{aligned}向量形式写法 公式 $\eqref{2-1}$ 的向量形式: h_{\Theta}(X)=X\Theta \tag{2-1'}\label{2-1-1}推导过程如下：先看看当训练集只有一条记录时，向量形式如何表达， h_{\theta}(x)= \begin{bmatrix} \theta_0 & \theta_1 & \theta_2 & \cdots & \theta_n \end{bmatrix} \begin{bmatrix}x_0 \\ x_1 \\ x_2 \\ \cdots \\ x_n \end{bmatrix} = \theta^Tx \quad (x_0=1)当训练集有$m$条记录时，即可得到公式 $\eqref{2-1-1}$，令 X= \begin{bmatrix} x_0^{(1)} & x_1^{(1)} & \cdots & x_n^{(1)} \\ x_0^{(2)} & x_1^{(2)} & \cdots & x_n^{(2)} \\ \cdots & \cdots & \cdots & \cdots \\ x_0^{(m)} & x_1^{(m)} & \cdots & x_n^{(m)} \end{bmatrix}, \quad \Theta= \begin{bmatrix}\theta_0 \\ \theta_1 \\ \theta_2 \\ \cdots \\ \theta_n \end{bmatrix}, \quad \overrightarrow{x_j}= \begin{bmatrix} x_j^{(1)} \\ x_j^{(2)} \\ \cdots \\ x_j^{(m)} \end{bmatrix} 公式$\eqref{2-2}$的向量形式： J(\Theta)=\frac{1}{2m}(X\Theta-\overrightarrow{y})^T(X\Theta-\overrightarrow{y}) \tag{2-2'}\label{2-2-1} 公式$\eqref{2-3}$的向量形式： \Theta:=\Theta-\alpha\frac{1}{m}X^T(X\Theta-\overrightarrow{y}) \tag{2-3'}\label{2-3-1}推导过程如下： \Theta:=\Theta-\alpha \nabla J(\Theta) \nabla J(\Theta)= \begin{bmatrix} \frac{\partial J(\Theta)}{\partial \theta_0} \\ \frac{\partial J(\Theta)}{\partial \theta_1} \\ \cdots \\ \frac{\partial J(\Theta)}{\partial \theta_n} \end{bmatrix} \begin{aligned} \frac{\partial J(\Theta)}{\partial \theta_j} &= \frac{1}{m} \sum_{i=1}^{m} ( h_{\theta}(x^{(i)})-y^{(i)} ) \cdot x_j^{(i)} \\ &= \frac{1}{m} \sum_{i=1}^{m} x_j^{(i)} \cdot ( h_{\theta}(x^{(i)})-y^{(i)} ) \\ &= \frac{1}{m} \overrightarrow{x_j}^T(X\Theta-\overrightarrow{y}) \end{aligned} \quad (for \, j=1..n)$\Rightarrow$ \nabla J(\Theta)=\frac{1}{m}X^T(X\Theta-\overrightarrow{y})另外，$\alpha$ 为 learning rate. 应用该实例来源于 coursera machine learning programming exercise1. 目的：实现多变量线性回归 若房价与房子的面积，房间的数量有关，作为房东的你，想要预测手上已有房源的市场价。 DataSet数据集的部分内容如下，完整数据集在这里 Size of the house$(x_1)$ Number of bedrooms$(x_2)$ Price of the house 2104 3 399900 1600 3 329900 2400 3 369900 1416 2 232000 … … … 完整代码完整代码可在这里下载。 下面只列出其中的主程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134%% Linear regression with multiple variables%% Initialization%% ================ Part 1: Feature Normalization ================%% Clear and Close Figuresclear ; close all; clcfprintf('Loading data ...\n');%% Load Datadata = load('ex1data2.txt');X = data(:, 1:2);y = data(:, 3);m = length(y);% Print out some data pointsfprintf('First 10 examples from the dataset: \n');fprintf(' x = [%.0f %.0f], y = %.0f \n', [X(1:10,:) y(1:10,:)]');fprintf('Program paused. Press enter to continue.\n');pause;% Scale features and set them to zero meanfprintf('Normalizing Features ...\n');[X mu sigma] = featureNormalize(X);% Add intercept term to XX = [ones(m, 1) X];%% ================ Part 2: Gradient Descent ================% ====================== YOUR CODE HERE ======================% Instructions: We have provided you with the following starter% code that runs gradient descent with a particular% learning rate (alpha). %% Your task is to first make sure that your functions - % computeCost and gradientDescent already work with % this starter code and support multiple variables.%% After that, try running gradient descent with % different values of alpha and see which one gives% you the best result.%% Finally, you should complete the code at the end% to predict the price of a 1650 sq-ft, 3 br house.%% Hint: By using the 'hold on' command, you can plot multiple% graphs on the same figure.%% Hint: At prediction, make sure you do the same feature normalization.%fprintf('Running gradient descent ...\n');% Choose some alpha valuealpha = 0.01;num_iters = 400;% Init Theta and Run Gradient Descent theta = zeros(3, 1);[theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters);% Plot the convergence graphfigure;plot(1:numel(J_history), J_history, '-b', 'LineWidth', 2);xlabel('Number of iterations');ylabel('Cost J');% Display gradient descent's resultfprintf('Theta computed from gradient descent: \n');fprintf(' %f \n', theta);fprintf('\n');% Estimate the price of a 1650 sq-ft, 3 br house% ====================== YOUR CODE HERE ======================% Recall that the first column of X is all-ones. Thus, it does% not need to be normalized.price = featureNormalize([1 1650 3]) * theta; % You should change this% ============================================================fprintf(['Predicted price of a 1650 sq-ft, 3 br house ' ... '(using gradient descent):\n $%f\n'], price);fprintf('Program paused. Press enter to continue.\n');pause;%% ================ Part 3: Normal Equations ================fprintf('Solving with normal equations...\n');% ====================== YOUR CODE HERE ======================% Instructions: The following code computes the closed form % solution for linear regression using the normal% equations. You should complete the code in % normalEqn.m%% After doing so, you should complete this code % to predict the price of a 1650 sq-ft, 3 br house.%%% Load Datadata = csvread('ex1data2.txt');X = data(:, 1:2);y = data(:, 3);m = length(y);% Add intercept term to XX = [ones(m, 1) X];% Calculate the parameters from the normal equationtheta = normalEqn(X, y);% Display normal equation's resultfprintf('Theta computed from the normal equations: \n');fprintf(' %f \n', theta);fprintf('\n');% Estimate the price of a 1650 sq-ft, 3 br house% ====================== YOUR CODE HERE ======================price = [1 1650 3] * theta; % You should change this% ============================================================fprintf(['Predicted price of a 1650 sq-ft, 3 br house ' ... '(using normal equations):\n $%f\n'], price); 代码分步讲解 step1: 特征的归一化处理 feature normalization 123456789101112data = load('ex1data2.txt');X = data(:, 1:2);y = data(:, 3);m = length(y);% Scale features and set them to zero meanfprintf('Normalizing Features ...\n');[X mu sigma] = featureNormalize(X);% Add intercept term to XX = [ones(m, 1) X]; 代码中的 featureNormalize(X) 函数如下： 12345678910111213141516171819202122232425262728293031323334function [X_norm, mu, sigma] = featureNormalize(X)%FEATURENORMALIZE Normalizes the features in X % FEATURENORMALIZE(X) returns a normalized version of X where% the mean value of each feature is 0 and the standard deviation% is 1. This is often a good preprocessing step to do when% working with learning algorithms.% You need to set these values correctlyX_norm = X;mu = zeros(1, size(X, 2));sigma = zeros(1, size(X, 2));% Instructions: First, for each feature dimension, compute the mean% of the feature and subtract it from the dataset,% storing the mean value in mu. Next, compute the % standard deviation of each feature and divide% each feature by it's standard deviation, storing% the standard deviation in sigma. %% Note that X is a matrix where each column is a % feature and each row is an example. You need % to perform the normalization separately for % each feature. %% Hint: You might find the 'mean' and 'std' functions useful.% mu = mean(X);sigma = std(X);for i = 1:size(X,1), X_norm(i,:) = (X_norm(i,:)-mu) ./ sigma;end;end step2: 用 gradient descent 找到 $J(\Theta)$ 的最优解 $\Theta$ 1234567891011121314fprintf('Running gradient descent ...\n');% Choose some alpha valuealpha = 0.01;num_iters = 400;% Init Theta and Run Gradient Descent theta = zeros(3, 1);[theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters);% Display gradient descent's resultfprintf('Theta computed from gradient descent: \n');fprintf(' %f \n', theta);fprintf('\n'); 代码中的gradientDescentMulti(X, y, theta, alpha, num_iters)函数代码如下： 12345678910111213141516function [theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters)%GRADIENTDESCENTMULTI Performs gradient descent to learn theta% theta = GRADIENTDESCENTMULTI(x, y, theta, alpha, num_iters) updates theta by% taking num_iters gradient steps with learning rate alpha% Initialize some useful valuesm = length(y); % number of training examplesJ_history = zeros(num_iters, 1);for iter = 1:num_iters, theta = theta - X' * alpha / m * (X *theta - y); % Save the cost J in every iteration J_history(iter) = computeCostMulti(X, y, theta);endend 代码中的computeCostMulti(X, y, theta)函数代码如下： 123456789101112131415161718function J = computeCostMulti(X, y, theta)%COMPUTECOSTMULTI Compute cost for linear regression with multiple variables% J = COMPUTECOSTMULTI(X, y, theta) computes the cost of using theta as the% parameter for linear regression to fit the data points in X and y% Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;h = X * theta;for i=1:m, J = J + (h(i)-y(i))^2;end;J = J/(2*m);end step3: 绘制$J(\Theta)$关于迭代次数的曲线图，以帮助选择合适的 learning rate $\alpha$ 12345% Plot the convergence graphfigure;plot(1:numel(J_history), J_history, '-b', 'LineWidth', 2);xlabel('Number of iterations');ylabel('Cost J'); step4: 预测预测 $size=1650(feet^2),bedrooms=3$ 的房价。 12% Estimate the price of a 1650 sq-ft, 3 br houseprice = featureNormalize([1 1650 3]) * theta; %其中的 theta 在之前几步已经算出 (Optional)也可以使用 Normal Equation 代替 gradient descent 去寻找最优解 123456789101112131415161718fprintf('Solving with normal equations...\n');%% Load Datadata = csvread('ex1data2.txt');X = data(:, 1:2);y = data(:, 3);m = length(y);% Add intercept term to XX = [ones(m, 1) X];% Calculate the parameters from the normal equationtheta = normalEqn(X, y);% Display normal equation's resultfprintf('Theta computed from the normal equations: \n');fprintf(' %f \n', theta);fprintf('\n'); 代码中的normalEqn(X, y)函数代码如下： 123456789function [theta] = normalEqn(X, y)%NORMALEQN Computes the closed-form solution to linear regression % NORMALEQN(X,y) computes the closed-form solution to linear % regression using the normal equations.theta = zeros(size(X, 2), 1);theta = pinv(X' * X) * X' * y;end Note:使用 normal equation，相比于 gradient descent 来说代码量更小。 Gradient Descent Normal Equation need to choose learning rate ‘$\alpha$’ No need to choose learning rate ‘$\alpha$’ needs many iterations No need to iterate 时间复杂度$O(kn^2)$ 时间复杂度$O(n^3)$ works well when $n$ is large($n$ = nums of features) slow if $n$ is very large 参考链接 Stanford coursera Andrew Ng 机器学习课程编程作业（Exercise 1） ML Week 2 Lecture Notes — Stanford coursera Andrew Ng ML Week 1 Lecture Notes — Stanford coursera Andrew Ng]]></content>
      <categories>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@安装财经数据接口 tushare]]></title>
    <url>%2Fmanual%2Fe500e7cc.html</url>
    <content type="text"><![CDATA[解决使用 pip 安装 tushare 时，由于缺少响应的依赖，而导致无法安装 tushare. 问题执行 pip3 install tushare 安装 tushare 时，报错如下： 12345678910111213141516➜ ~ pip3 install tushareCollecting tushare Using cached tushare-0.8.7.tar.gz Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9dj8nqyy/tushare/setup.py", line 4, in &lt;module&gt; import tushare File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9dj8nqyy/tushare/tushare/__init__.py", line 6, in &lt;module&gt; from tushare.stock.trading import (get_hist_data, get_tick_data, File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9dj8nqyy/tushare/tushare/stock/trading.py", line 13, in &lt;module&gt; import lxml.html ModuleNotFoundError: No module named 'lxml' ----------------------------------------Command "python setup.py egg_info" failed with error code 1 in /private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9dj8nqyy/tushare/ 解决方案 解决：根据报错的内容，手动安装缺少的依赖，如：lxml, requests, bs4等。 可以看到，报错的主要原因是 ModuleNotFoundError: No module named &#39;lxml&#39;，所以我们先手动安装 lxml。 123456➜ ~ pip3 install lxmlCollecting lxml Downloading lxml-3.8.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (7.8MB) 100% |████████████████████████████████| 7.9MB 152kB/sInstalling collected packages: lxmlSuccessfully installed lxml-3.8.0 然后，执行pip3 install tushare，发现仍旧无法完成安装，报错如下： 12345678910111213141516➜ ~ pip3 install tushareCollecting tushare Using cached tushare-0.8.7.tar.gz Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-z29m16tu/tushare/setup.py", line 4, in &lt;module&gt; import tushare File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-z29m16tu/tushare/tushare/__init__.py", line 101, in &lt;module&gt; from tushare.trader.trader import TraderAPI File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-z29m16tu/tushare/tushare/trader/trader.py", line 12, in &lt;module&gt; import requests ModuleNotFoundError: No module named 'requests' ----------------------------------------Command "python setup.py egg_info" failed with error code 1 in /private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-z29m16tu/tushare/ 报错原因同样是由于缺少相应的依赖，ModuleNotFoundError: No module named &#39;requests&#39;，所以，我们手动安装 requests: 123456789101112131415161718➜ ~ pip3 install requestsCollecting requests Downloading requests-2.18.4-py2.py3-none-any.whl (88kB) 100% |████████████████████████████████| 92kB 654kB/sCollecting chardet&lt;3.1.0,&gt;=3.0.2 (from requests) Downloading chardet-3.0.4-py2.py3-none-any.whl (133kB) 100% |████████████████████████████████| 143kB 1.6MB/sCollecting idna&lt;2.7,&gt;=2.5 (from requests) Downloading idna-2.6-py2.py3-none-any.whl (56kB) 100% |████████████████████████████████| 61kB 3.8MB/sCollecting certifi&gt;=2017.4.17 (from requests) Downloading certifi-2017.7.27.1-py2.py3-none-any.whl (349kB) 100% |████████████████████████████████| 358kB 1.0MB/sCollecting urllib3&lt;1.23,&gt;=1.21.1 (from requests) Downloading urllib3-1.22-py2.py3-none-any.whl (132kB) 100% |████████████████████████████████| 133kB 2.9MB/sInstalling collected packages: chardet, idna, certifi, urllib3, requestsSuccessfully installed certifi-2017.7.27.1 chardet-3.0.4 idna-2.6 requests-2.18.4 urllib3-1.22 然后执行 pip3 install tushare，仍旧报错缺少依赖： 12345678910111213141516➜ ~ pip3 install tushareCollecting tushare Using cached tushare-0.8.7.tar.gz Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9hv2b7g7/tushare/setup.py", line 4, in &lt;module&gt; import tushare File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9hv2b7g7/tushare/tushare/__init__.py", line 119, in &lt;module&gt; from tushare.futures.domestic import (get_cffex_daily, get_czce_daily, File "/private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9hv2b7g7/tushare/tushare/futures/domestic.py", line 11, in &lt;module&gt; from bs4 import BeautifulSoup ModuleNotFoundError: No module named 'bs4' ----------------------------------------Command "python setup.py egg_info" failed with error code 1 in /private/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-build-9hv2b7g7/tushare/ ModuleNotFoundError: No module named &#39;bs4&#39;，同样，我们手动安装 bs4： 123456789101112➜ ~ pip3 install bs4Collecting bs4 Downloading bs4-0.0.1.tar.gzCollecting beautifulsoup4 (from bs4) Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86kB) 100% |████████████████████████████████| 92kB 496kB/sBuilding wheels for collected packages: bs4 Running setup.py bdist_wheel for bs4 ... done Stored in directory: /Users/seyvoue/Library/Caches/pip/wheels/84/67/d4/9e09d9d5adede2ee1c7b7e8775ba3fbb04d07c4f946f0e4f11Successfully built bs4Installing collected packages: beautifulsoup4, bs4Successfully installed beautifulsoup4-4.6.0 bs4-0.0.1 至此，再次执行 pip3 install tushare，tushare 便可成功安装了。]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@使用 Pandoc Markdown 进行学术论文写作]]></title>
    <url>%2Fmanual%2Ffc12d89.html</url>
    <content type="text"><![CDATA[一个 LaTeX 的替代解决方案，并非完全要放弃 LaTeX。因为科技论文写作不可避免要有许多数学符号和公式。而且许多期刊都提供了 LaTeX 模板，因此如果这种替代方案需要让我完全放弃 LaTeX，我也会有些犹豫的。一直有在用 Markdown 写笔记的习惯，意外的发现了 Markdown＋Pandoc 的组合，正是我所苦苦寻找的替代解决方案。 本科的论文是用 word 写的，无奈 word 在频繁修改文档时，表格和插图很容易乱掉，并且无法解决多人协助，版本管理问题。加上有纯文本癖，我很快将目光转到 LaTeX 上。用了一段时间 LaTeX ，表格和插图不再混乱，参考文献引用也完全没有问题，对数学公式的支持几乎可以用完美来形容，版本管理和多人协作也可以通过 Git 来实现。但也发现了一些 LaTeX 在创作时的问题： 写作时无法集中精力到内容上：使用 LaTeX 写作，特别当文档比较大并存在大量公式的时候，会存在一大堆的标签，文档结构不够清晰。 标签需要配对：虽说标签配对不是很大的问题。但编译报错，返回编辑器补全标签还是挺让人懊恼，容易打断写作思路。 无法做到所见即所得：所见即所得是 Word 做的比较好的地方，使用 LaTeX 进行写作的时候，你并不知道结果出来是什么样子的，一切只有编译以后才知道。你想修改 pdf 里的一句话，还需要找对应 tex 文件的所在行。虽然可以使用搜索，但是毕竟还是没有所见即所得来的方便。 另外：之前写过一篇“@高效写作 sublime3+markdown+evernote”，是关于如何将 Sublime Text 打造成一个 markdown 写作利器的，有兴趣的可以了解下。（其实，网上有很多现成的markdown编辑器，对于没有强迫症的人来说，会是更好的选择，比如：马克飞象，Mou，MWeb 等等） 未完待续 .post-body .fancybox img.pic_styl { display: inline !important; height: 140px; width: auto; }]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>pandoc</tag>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Install IPython on Mac Sierra(OS10.12.6)]]></title>
    <url>%2Fmanual%2Fe8867155.html</url>
    <content type="text"><![CDATA[安装 IPython 之前，计算机中得预先安装 python 以及 PIP，本文省略这部分的安装，只讨论在 Sierra 下安装 IPython 时，你可能会遇到的问题。 安装 IPython 时可能会遇到的问题(如果你使用的是 python3以下的版本)macOS 早期的版本，你只需要执行 pip install ipyhton 或者 sudo install ipython 即可完成安装，但在 macOS10 及其以上的系统上，你会发现执行上面的命令，并不能完成安装，会报错： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566➜ ~ pip install ipythonCollecting ipython Downloading ipython-5.4.1-py2-none-any.whl (757kB) 100% |████████████████████████████████| 757kB 1.1MB/sCollecting prompt-toolkit&lt;2.0.0,&gt;=1.0.4 (from ipython) Downloading prompt_toolkit-1.0.15-py2-none-any.whl (247kB) 100% |████████████████████████████████| 256kB 649kB/sCollecting decorator (from ipython) Downloading decorator-4.1.2-py2.py3-none-any.whlRequirement already satisfied: setuptools&gt;=18.5 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from ipython)Collecting pickleshare (from ipython) Downloading pickleshare-0.7.4-py2.py3-none-any.whlCollecting pygments (from ipython) Downloading Pygments-2.2.0-py2.py3-none-any.whl (841kB) 100% |████████████████████████████████| 849kB 561kB/sCollecting pexpect; sys_platform != "win32" (from ipython) Downloading pexpect-4.2.1-py2.py3-none-any.whl (55kB) 100% |████████████████████████████████| 61kB 1.2MB/sCollecting pathlib2; python_version == "2.7" or python_version == "3.3" (from ipython) Downloading pathlib2-2.3.0-py2.py3-none-any.whlCollecting backports.shutil-get-terminal-size; python_version == "2.7" (from ipython) Downloading backports.shutil_get_terminal_size-1.0.0-py2.py3-none-any.whlCollecting simplegeneric&gt;0.8 (from ipython) Downloading simplegeneric-0.8.1.zipCollecting traitlets&gt;=4.2 (from ipython) Downloading traitlets-4.3.2-py2.py3-none-any.whl (74kB) 100% |████████████████████████████████| 81kB 1.9MB/sCollecting appnope; sys_platform == "darwin" (from ipython) Downloading appnope-0.1.0-py2.py3-none-any.whlCollecting six&gt;=1.9.0 (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;ipython) Using cached six-1.10.0-py2.py3-none-any.whlCollecting wcwidth (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;ipython) Downloading wcwidth-0.1.7-py2.py3-none-any.whlCollecting ptyprocess&gt;=0.5 (from pexpect; sys_platform != "win32"-&gt;ipython) Downloading ptyprocess-0.5.2-py2.py3-none-any.whlCollecting scandir; python_version &lt; "3.5" (from pathlib2; python_version == "2.7" or python_version == "3.3"-&gt;ipython) Downloading scandir-1.5.tar.gzCollecting enum34; python_version == "2.7" (from traitlets&gt;=4.2-&gt;ipython) Downloading enum34-1.1.6-py2-none-any.whlCollecting ipython-genutils (from traitlets&gt;=4.2-&gt;ipython) Downloading ipython_genutils-0.2.0-py2.py3-none-any.whlInstalling collected packages: six, wcwidth, prompt-toolkit, decorator, scandir, pathlib2, pickleshare, pygments, ptyprocess, pexpect, backports.shutil-get-terminal-size, simplegeneric, enum34, ipython-genutils, traitlets, appnope, ipython Found existing installation: six 1.4.1 DEPRECATION: Uninstalling a distutils installed project (six) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling six-1.4.1:Exception:Traceback (most recent call last): File "/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py", line 215, in main status = self.run(options, args) File "/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py", line 342, in run prefix=options.prefix_path, File "/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py", line 778, in install requirement.uninstall(auto_confirm=True) File "/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py", line 754, in uninstall paths_to_remove.remove(auto_confirm) File "/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py", line 115, in remove renames(path, new_path) File "/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py", line 267, in renames shutil.move(old, new) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py", line 302, in move copy2(src, real_dst) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py", line 131, in copy2 copystat(src, dst) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py", line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: '/var/folders/1t/k5ry6mpn0gj6982jgm8_hm480000gn/T/pip-_p6xLF-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info' 查阅相关资料，了解到这与 OSX SIP 机制有关，网上有提到可通过取消 SIP 机制解决这个问题(比如这篇文章)。但个人不是很喜欢去碰系统权限，于是找到了下面这个方案。 解决方案基于用户的权限来安装模块包显得更加合理。1pip install ipython --user -U 验证 ipython 是否安装成功终端执行 python -m ipython，终端返回以下内容，表示安装成功。 1234567891011➜ ~ python -m IPythonPython 2.7.10 (default, Feb 7 2017, 00:08:15)Type "copyright", "credits" or "license" for more information.IPython 5.4.1 -- An enhanced Interactive Python.? -&gt; Introduction and overview of IPython's features.%quickref -&gt; Quick reference.help -&gt; Python's own help system.object? -&gt; Details about 'object', use 'object??' for extra details.In [1]: NOTES: 若你使用的是 zsh shell，在 .zshrc 配置文件中，加入以下内容后，之后只需输入ipython便可运行 ipython 了。 1alias ipython=&apos;python -m IPython&apos;]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@2017年天池大数据竞赛-新浪微博互动预测大赛]]></title>
    <url>%2Fbigdata%2Fdd569220.html</url>
    <content type="text"><![CDATA[关于赛制介绍、数据介绍请参看 新浪微博互动预测大赛 问题：根据抽样用户的原创博文在发表一天后的转发、评论、赞总数，建立博文的互动模型，并预测后续博文在发表一天后的互动情况。 思考 数据集的数据要整理成什么形式才可以被模型利用？ 比如，微博互动预测那题，拿到的一个 txt 文件，需要将数据处理成什么形式，才可以成为 useful data，编程关系型数据库那种形式么？]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[@MySQL语法之 Indexes]]></title>
    <url>%2Flanguages%2Fb1ae4170.html</url>
    <content type="text"><![CDATA[用来加快查询的技术很多，其中最重要的是索引。通常索引能够快速提高查询速度。如果不使用索引，MYSQL必须从第一条记录开始然后读完整个表直到找出相关的行。表越大，花费的时间越多。但也不全是这样。本文讨论在 MySQL 中如何创建、删除、重命名索引。 创建索引在执行 CREATE TABLE 语句时可以创建索引，也可以单独用 CREATE INDEX 或 ALTER TABLE 来为表增加索引。 例1 CREATE TABLE: 在创建表时就创建索引 123456789CREATE TABLE contacts( contact_id INT(11) NOT NULL AUTO_INCREMENT, last_name VARCHAR(30) NOT NULL, first_name VARCHAR(25), birthday DATE, CONSTRAINT contacts_pk PRIMARY KEY (contact_id), INDEX contacts_idx (last_name, first_name)); 例2 CREATE INDEX: 创建完表后，单独创建索引 12345678910CREATE TABLE contacts( contact_id INT(11) NOT NULL AUTO_INCREMENT, last_name VARCHAR(30) NOT NULL, first_name VARCHAR(25), birthday DATE, CONSTRAINT contacts_pk PRIMARY KEY (contact_id));CREATE INDEX contacts_idx ON contacts (last_name, first_name); 例3 ALTER TABLE: 创建完表后，添加索引 12345678910CREATE TABLE contacts( contact_id INT(11) NOT NULL AUTO_INCREMENT, last_name VARCHAR(30) NOT NULL, first_name VARCHAR(25), birthday DATE, CONSTRAINT contacts_pk PRIMARY KEY (contact_id));ALTER TABLE contacts ADD INDEX contacts_idx (last_name, first_name) 删除索引可利用 ALTER TABLE 或 DROP INDEX 语句来删除索引。类似于 CREATE INDEX 语句，DROP INDEX 可以在 ALTER TABLE 内部作为一条语句处理。 例1 DROP INDEX 1DROP INDEX contacts_idx ON contacts; 例2 ALTER TABLE 中使用 DROP INDEX 语句 1ALTER TABLE contacts DROP INDEX contacts_idx 重命名索引 MySQL5.6及其之前的版本，重命名索引，需要先删除之前的索引 123ALTER TABLE contacts DROP INDEX contacts_idx, ADD INDEX contacts_new_index (last_name, first_name); MySQL5.7及其之后的版本，使用关键字 RENAME 关键字即可重命名索引 12ALTER TABLE contacts RENAME INDEX contacts_idx TO contacts_new_index; 参考 MySQL: indexes]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Maven POM 详解]]></title>
    <url>%2Flanguages%2Fa2c435b5.html</url>
    <content type="text"><![CDATA[0 前言什么是 POM？就像 Make 的 MakeFile、Ant 的 build.xml 一样，Maven 项目的核心是 pom.xml。POM( Project Object Model，项目对象模型 ) 定义了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。 Quick Overview一个完整的 pom.xml 如下，放置在项目的根目录下： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- The Basics --&gt; &lt;groupId&gt;...&lt;/groupId&gt; &lt;artifactId&gt;...&lt;/artifactId&gt; &lt;version&gt;...&lt;/version&gt; &lt;packaging&gt;...&lt;/packaging&gt; &lt;dependencies&gt;...&lt;/dependencies&gt; &lt;parent&gt;...&lt;/parent&gt; &lt;dependencyManagement&gt;...&lt;/dependencyManagement&gt; &lt;modules&gt;...&lt;/modules&gt; &lt;properties&gt;...&lt;/properties&gt; &lt;!-- Build Settings --&gt; &lt;build&gt;...&lt;/build&gt; &lt;reporting&gt;...&lt;/reporting&gt; &lt;!-- More Project Information --&gt; &lt;name&gt;...&lt;/name&gt; &lt;description&gt;...&lt;/description&gt; &lt;url&gt;...&lt;/url&gt; &lt;inceptionYear&gt;...&lt;/inceptionYear&gt; &lt;licenses&gt;...&lt;/licenses&gt; &lt;organization&gt;...&lt;/organization&gt; &lt;developers&gt;...&lt;/developers&gt; &lt;contributors&gt;...&lt;/contributors&gt; &lt;!-- Environment Settings --&gt; &lt;issueManagement&gt;...&lt;/issueManagement&gt; &lt;ciManagement&gt;...&lt;/ciManagement&gt; &lt;mailingLists&gt;...&lt;/mailingLists&gt; &lt;scm&gt;...&lt;/scm&gt; &lt;prerequisites&gt;...&lt;/prerequisites&gt; &lt;repositories&gt;...&lt;/repositories&gt; &lt;pluginRepositories&gt;...&lt;/pluginRepositories&gt; &lt;distributionManagement&gt;...&lt;/distributionManagement&gt; &lt;profiles&gt;...&lt;/profiles&gt;&lt;/project&gt; tips：这里的 pom.xml 的 modelVersion 为 4.0. 1 POM 常用元素1.1 The Basics1.1.1 Maven 坐标( Coordinate )在 Maven 中坐标是构件的唯一标识，Maven 坐标的元素包括 groupId、artifactId、version、packaging、classifier。上述5个元素中，groupId、artifactId、version 是必须定义的，packaging 是可选的 ( 默认为 jar )。 groupId：组织标识，一般为：公司网址的反写+项目名 artifactId：项目名称，一般为：项目名-模块名 version：版本号 packaging：打包的方式，如：pom, jar, maven-plugin, ejb, war, … clissifier：用来帮助定义构件输出的一些附属构件。可参考此文 另外，关于 版本号 ，形式为0.0.1-SNAPSHOT： 第一个 0 表示大版本号，第二个 0 表示分支版本号，第三个 0 表示小版本号 SNAPSHOT — 快照版本，ALPHA — 内侧版本，BETA — 公测版本，RELEASE — 稳定版本，GA — 正式发布 在我们开发自己的 maven 项目的时候，需要为其定义适当的坐标，如： 123456789101112131415161718&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.seyvoue.demo生成的相对路径为：/com/seyvoue/demo--&gt; &lt;groupId&gt;com.seyvoue.demo&lt;/groupId&gt; &lt;!-- 构件的标识符，它和 groupId 一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的 artifactId 和 groupId；在某个特定的 groupId 下，artifactId也必须是唯一的。--&gt; &lt;artifactId&gt;demo-maven&lt;/artifactId&gt; &lt;!-- 项目当前版本，格式为:主版本.次版本.增量版本-限定版本号--&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;!-- 项目产生的构件类型，例如 jar、war、pom 等。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型--&gt; &lt;packaging&gt;jar&lt;/packaging&gt; ... &lt;/project&gt; 1.1.2 依赖: &lt;dependencies&gt;…&lt;/dependencies&gt;比如，我的项目 project-demo1 需要添加 junit 依赖： 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; ...&lt;/dependencies&gt; dependencies元素，包括以下子元素： groupId, artifactId, version 这三个是必须的，以下的那些子元素根据实际情况添加。 scope scope 元素为 maven dependency 下一个控制作用域的子元素，控制该依赖包在什么情况下会被加到 classpath 中。共 6 种 scope，包括：compile、provided、runtime、test、system、import。( 具体可参考@POM Dependency Scope ) type 对于于 &lt;packaging&gt;...&lt;/packaging&gt; ，即指定依赖包的后缀，默认为 jar optional 如果当前仙姑是 projectA，projectA 需要依赖 projectB，而 projectB 的 optional 为 true，表示依赖可选，那么之后所有声明依赖 projectA 的项目如果也依赖 projectB，就必须手动声明。比如，projectC 依赖 projectA 和 projectB，如果 projectC只声明了对 projectA 的依赖，那么 projectB 不会自动加入依赖，projectA 必须手动加入对 projectB 的依赖。也就是说依赖传递被打断了。 exclusions 依赖传递：如果我们的项目引用了一个 Jar 包，而该 Jar 包又引用了其他 Jar 包，那么在默认情况下项目编译时，Maven 会把直接引用和间接引用的 Jar 包都下载到本地。 排除依赖：如果我们只想下载直接引用的 Jar包，那么需要在 pom.xml 中做如下配置：(将需要排除的 Jar 包的坐标写在中) 1234567891011&gt;&gt; &lt;dependency&gt;&gt;&gt; ... &gt;&gt; &lt;exclusions&gt;&gt;&gt; &lt;exclusion&gt;&gt;&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;&gt;&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;&gt;&gt; &lt;/exclusion&gt;&gt;&gt; &lt;/exclusions&gt;&gt;&gt; ...&gt;&gt; &lt;/dependency&gt;&gt;&gt; &gt; 依赖冲突：若项目中多个 Jar 同时引用了相同的 Jar 时，会产生依赖冲突，但 Maven 采用了两种避免冲突的策略，因此在 Maven 中是不存在依赖冲突的。 短路优先本项目——&gt;A.jar——&gt;B.jar——&gt;X.jar本项目——&gt;C.jar——&gt;X.jar若本项目引用了 A.jar，A.jar 又引用了 B.jar，B.jar 又引用了 X.jar，并且 C.jar 也引用了X.jar。在此时，Maven 只会引用引用路径最短的Jar。 声明优先若引用路径长度相同时，在pom.xml中谁先被声明，就使用谁。 1.1.3 聚合: &lt;modules&gt;…&lt;/modules&gt; 通过 &lt;modules&gt;...&lt;modules&gt; 元素可将多个模块聚合在同一个 project 下。 123456789101112131415&lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.seyvoue.account&lt;/groupId&gt; &lt;artifactId&gt;account-aggregator&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; ... &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules&gt; &lt;module&gt;account-email&lt;/module&gt; &lt;module&gt;account-persist&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 1.1.4 继承: &lt;parent&gt;…&lt;/parent&gt; 和 &lt;dependencyManagement&gt;…&lt;/dependencyManagement&gt; 在聚合多个项目时，如果这些被聚合的项目中需要引入相同的 Jar，那么可以将这些 Jar 写入 父pom 中，各个子项目继承该pom即可。类似与 java 中的继承。(具体可参考@Maven的聚合与继承) 如何实现继承？ 示例如下： 父 pom.xml： &lt;packaging&gt;...&lt;/packaging&gt; 必须配置为 pom 将需要继承的 Jar 包的坐标放入&lt;dependencyManagement&gt;...&lt;/dependencyManagement&gt; 内即可 12345678910111213141516171819202122232425262728293031&gt;&gt; &lt;project&gt;&gt;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&gt;&gt; &lt;groupId&gt;com.seyvoue.demo&lt;/groupId&gt;&gt;&gt; &lt;artifactId&gt; demo-maven &lt;/artifactId&gt;&gt;&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&gt;&gt; &lt;packaging&gt;pom&lt;/packaging&gt;&gt;&gt; &gt;&gt; ...&gt;&gt; &lt;properties&gt;&gt;&gt; &lt;spring.version&gt;4.0.2.RELEASE&lt;/spring.version&gt;&gt;&gt; &lt;junit.versoin&gt;4.7&lt;/junit.version&gt;&gt;&gt; ...&gt;&gt; &lt;/properties&gt;&gt;&gt; &gt;&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact &gt;&gt; ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。--&gt;&gt;&gt; &lt;dependencyManagement&gt;&gt;&gt; &lt;dependencies&gt;&gt;&gt; &lt;dependency&gt;&gt;&gt; &lt;groupId&gt;com.github.brevy&lt;/groupId&gt;&gt;&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt;&gt;&gt; &lt;version&gt;1.2.2&lt;/version&gt;&gt;&gt; &lt;/dependency&gt;&gt;&gt; ...&gt;&gt; &lt;/dependencies&gt;&gt;&gt; &lt;/dependencyManagement&gt;&gt;&gt; ...&gt;&gt; &gt;&gt; &lt;/project&gt; &gt;&gt;&gt;&gt; 子 pom.xml： 在&lt;parent&gt;...&lt;/parent&gt; 标签内添加 父pom.xml 的坐标 123456789101112131415161718192021222324252627&gt;&gt; &lt;project&gt; &gt;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &gt;&gt; ... &gt;&gt; &lt;parent&gt; &gt;&gt; &lt;groupId&gt;com.seyvoue.demo&lt;/groupId&gt; &gt;&gt; &lt;artifactId&gt; demo-maven &lt;/artifactId&gt; &gt;&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&gt;&gt; &lt;!-- 父pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../&gt;&gt; pom.xml。Maven首先在构建当前项目的地方寻找父pom.xml，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。--&gt;&gt;&gt; &lt;relativePath&gt;...&lt;/relativePath&gt; &gt;&gt; &lt;/parent&gt;&gt;&gt; &gt;&gt; &lt;!-- 子 POM 若引用父 POM 在 dependencyManagement 中定义过的依赖，则只需填写 groupId 和 artifactid，其它的信息则会从父 POM 中继承 --&gt;&gt;&gt; &lt;dependencies&gt;&gt;&gt; &lt;dependency&gt;&gt;&gt; &lt;groupId&gt;com.github.brevy&lt;/groupId&gt;&gt;&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt;&gt;&gt; &lt;/dependency&gt;&gt;&gt; ...&gt;&gt; &lt;/dependencies&gt;&gt;&gt; &gt;&gt; ...&gt;&gt; &gt;&gt; &gt;&gt; &lt;/project&gt; &gt;&gt; &gt;&gt; Maven 可继承的 POM 元素： 123456789101112131415161718192021&gt; groupId ：项目组 ID ，项目坐标的核心元素； &gt; version ：项目版本，项目坐标的核心元素； &gt; description ：项目的描述信息； &gt; organization ：项目的组织信息； &gt; inceptionYear ：项目的创始年份； &gt; url ：项目的 url 地址 &gt; develoers ：项目的开发者信息； &gt; contributors ：项目的贡献者信息； &gt; distributionManagerment ：项目的部署信息； &gt; issueManagement ：缺陷跟踪系统信息； &gt; ciManagement ：项目的持续继承信息； &gt; scm ：项目的版本控制信息； &gt; mailingListserv ：项目的邮件列表信息； &gt; properties ：自定义的 Maven 属性； &gt; dependencies ：项目的依赖配置； &gt; dependencyManagement ：醒目的依赖管理配置； &gt; repositories ：项目的仓库配置； &gt; build ：包括项目的源码目录配置、输出目录配置、插件配置、插件管理配置等； &gt; reporting ：包括项目的报告输出目录配置、报告插件配置等。 &gt;&gt; 1.1.5 属性：&lt;properties&gt;…&lt;/properties&gt; Maven 的 properties 加载顺序： 中的配置 pom.xml 中的 mvn -Dproperty=value 中定义的 property相同 key 的 property，以最后一个文件中的配置为最终配置。 12345678910&lt;project&gt; ... &lt;properties&gt; &lt;maven.compiler.source&gt;1.7&lt;maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;/properties&gt; ...&lt;/project&gt; 通过 properties元素用户可以定义一个或多个 maven 属性，然后在 maven 的其他地方使用 ${属性名称} 的方式引用该属性，这种做法的意义在于消除重复和统一管理。比如，需要在多个地方重复声明同样的 SpringFramework 版本，现在只需要在一个地方声明就可以。Maven 共有6种属性(根据引用的来源不同)：内置属性、POM 属性、自定义属性、Settings 属性、环境变量属性等，引用方式是类似的，下面介绍其中的集中 内置属性 两个常用内置属性： ${basedir} 表示项目根目录 ${version} 表示项目版本 POM 属性 用户可以使用该类属性引用 pom.xml 中对应元素的值，如 ${project.artifactId} 就对应了 &lt;project&gt;&lt;artifactId&gt;&lt;/artifactId&gt;&lt;/project&gt; 中的值。常用的 POM 属性包括： ${project.build.sourceDirectory} 表示项目的主源码目录，默认为 src/main/java ${project.build.testDirectory} 表示项目的测试源码目录，默认为 src/test/java ${project.build.directory} 表示项目项目构建输出目录，默认为 /target ${project.outputDirectory} 表示项目主代码编译输出目录，默认为 /target/classes ${project.build.filename} 表示项目打包输出文件的名称，默认为 ${project.artifactId}-${project.version} 自定义属性 用户可以在 pom.xml 的&lt;properties/&gt; 元素下定义自己的 Maven 属性。如： 123456789&gt;&gt; &lt;project&gt;&gt;&gt; ...&gt;&gt; &lt;properties&gt;&gt;&gt; &lt;my.group&gt;hello&lt;/my.group&gt;&gt;&gt; &lt;/properties&gt;&gt;&gt; ...&gt;&gt; &lt;/project&gt;&gt;&gt; &gt;&gt; settings 属性 与 POM 属性同理。maven settings.xml 中定义的内容，可以通过 settings 前缀进行引用。 123&gt;&gt; $&#123;settings.localRepository&#125; 表示 maven 本地仓库的路径&gt;&gt; $&#123;settings.offline&#125; 表示构建系统是否在离线模式下工作&gt;&gt; 1.2 Build Settings根据 POM 4.0.0 XSD，build 元素概念性的划分为两个部分：BaseBuild（包含 poject build 和 profile build 的公共部分，见下）和 poject build 包含的一些高级特性。 12345678910111213141516&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; ... &lt;!-- "Project Build" contains more elements than just the BaseBuild set --&gt; &lt;build&gt;...&lt;/build&gt; &lt;profiles&gt; &lt;profile&gt; &lt;!-- "Profile Build" contains a subset of "Project Build"s elements --&gt; &lt;build&gt;...&lt;/build&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;/project&gt; 1.2.1 &lt;build&gt;…&lt;/build&gt;1.2.1.1 The BaseBuild Element SetBasic Elements123456789&lt;build&gt; &lt;defaultGoal&gt;install&lt;/defaultGoal&gt; &lt;directory&gt;$&#123;basedir&#125;/target&lt;/directory&gt; &lt;finalName&gt;$&#123;artifactId&#125;-$&#123;version&#125;&lt;/finalName&gt; &lt;filters&gt; &lt;filter&gt;filters/filter1.properties&lt;/filter&gt; &lt;/filters&gt; ... &lt;/build&gt; defaultGoal：执行build任务时，如果没有指定目标，将使用的默认值，如：在命令行中执行mvn，则相当于执行mvn install； directory：build目标文件的存放目录，默认在 ${basedir}/target目录 finalName：build目标文件的文件名，默认情况下为${artifactId}-${version} filter：定义*.properties文件，包含一个properties列表，该列表会应用的支持filter的resources中。也就是说，定义在filter的文件中的”name=value”值对会在build时代替 ${name} 值应用到 resources 中。Maven的默认filter文件夹是 ${basedir}/src/main/filters/ &lt;Resources&gt;…&lt;/Resources&gt; Maven 属性默认只有在 pom.xml 中才会被解析，对于放在 src/main/resources/ 目录下的文件，maven 是需要通过 maven-resources-plugin 插件帮忙处理的，它默认的行为是将项目资源文件复制到代码编译输出目录中，不过只要通过一些简单的 POM 配置，该插件就能解析资源文件中的 Maven 属性，即开启资源过滤。resources（通常）不是代码，他们不被编译，但是被绑定在你的项目或者用于其它什么原因，例如代码生成。&gt; 123456789101112131415161718192021&gt;&gt; &lt;build&gt; &gt;&gt; ... &gt;&gt; &lt;resources&gt; &gt;&gt; &lt;resource&gt; &gt;&gt; &lt;targetPath&gt;META-INF/plexus&lt;/targetPath&gt; &gt;&gt; &lt;filtering&gt;false&lt;/filtering&gt; &gt;&gt; &lt;directory&gt;$&#123;basedir&#125;/src/main/plexus&lt;/directory&gt; &gt;&gt; &lt;includes&gt; &gt;&gt; &lt;include&gt;configuration.xml&lt;/include&gt; &gt;&gt; &lt;/includes&gt; &gt;&gt; &lt;excludes&gt; &gt;&gt; &lt;exclude&gt;**/*.properties&lt;/exclude&gt; &gt;&gt; &lt;/excludes&gt; &gt;&gt; &lt;/resource&gt; &gt;&gt; &lt;/resources&gt; &gt;&gt; &lt;testResources&gt; &gt;&gt; ... &gt;&gt; &lt;/testResources&gt; &gt;&gt; ... &gt;&gt; &lt;/build&gt; &gt;&gt; &gt; resources：一个resource元素的列表，每一个都描述与项目关联的文件是什么和在哪里； targetPath：指定build后的resource存放的文件夹。该路径默认是basedir。通常被打包在JAR中的resources的目标路径为META-INF； filtering：true/false，表示为这个resource，filter是否激活。 directory：定义resource所在的文件夹，默认为 ${basedir}/src/main/resources includes：指定作为resource的文件的匹配模式，用 * 作为通配符； excludes：指定哪些文件被忽略，如果一个文件同时符合 includes 和 excludes，则 excludes生效； testResources：定义和 resource 类似，但只在 test 时使用，默认的 test resource文件夹路径是 ${basedir}/src/test/resources，test resource 不被部署。 &lt;plugins&gt;…&lt;/plugins&gt; &lt;plugins/&gt; 给出构建过程中所用到的插件，以及可以在这个元素下对插件进行配置。 123456789101112131415161718192021222324252627282930313233&gt;&gt; &lt;build&gt; &gt;&gt; ... &gt;&gt; &lt;plugins&gt; &gt;&gt; &lt;plugin&gt; &gt;&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &gt;&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &gt;&gt; &lt;version&gt;2.6&lt;/version&gt; &gt;&gt; &lt;extensions&gt;false&lt;/extensions&gt; &gt;&gt; &lt;inherited&gt;true&lt;/inherited&gt; &gt;&gt; &lt;configuration&gt; &gt;&gt; &lt;classifier&gt;test&lt;/classifier&gt; &gt;&gt; &lt;/configuration&gt; &gt;&gt; &lt;dependencies&gt;...&lt;/dependencies&gt; &gt;&gt; &lt;executions&gt;&gt;&gt; &lt;excution&gt;&gt;&gt; &lt;id&gt;echodir&lt;/id&gt;&gt;&gt; &lt;goals&gt;&gt;&gt; &lt;goal&gt;run&lt;/goal&gt;&gt;&gt; &lt;/goals&gt;&gt;&gt; &lt;phase&gt;verify&lt;/phase&gt;&gt;&gt; &lt;inherited&gt;false&lt;/inherited&gt;&gt;&gt; &lt;configuration&gt;&gt;&gt; &lt;task&gt;&gt;&gt; &lt;echo&gt;Build Dir: $&#123;project.build.directory&#125;&lt;/echo&gt;&gt;&gt; &lt;/task&gt;&gt;&gt; &lt;/configuration&gt;&gt;&gt; &lt;/excution&gt;&gt;&gt; &lt;/executions&gt; &gt;&gt; &lt;/plugin&gt; &gt;&gt; &lt;/plugins&gt; &gt;&gt;&lt;/build&gt; &gt;&gt; &gt;&gt; &gt; extensions：是否加载该插件的扩展，默认false inherited：该插件的 configuration 中的配置是否可以被（继承该POM的其他Maven项目）继承，默认true configuration：该插件所需要的特殊配置，在父子项目之间可以覆盖或合并 dependencies：该插件所特有的依赖类库 executions：plugin 可以有多个目标，每一个目标都可以有一个分开的配置，甚至可以绑定一个 plugin 的目标到一个不同的阶段。executions 配置一个 plugin 的目标的 execution。一个 execution 有如下设置： id，唯一标识 goals，要执行的插件的 goal（可以有多个），如 &lt;goal&gt;run&lt;/goal&gt; phase，目标执行的阶段，具体值看Maven的生命周期列表 inherited，该 execution 是否可被子项目继承 configuration，该 execution 的其他配置参数 &lt;pluginManagement&gt;…&lt;pluginManagement&gt; 在 &lt;build&gt; 中，&lt;pluginManagement&gt; 与 &lt;plugins&gt; 并列，两者之间的关系类似于 &lt;dependencyManagement&gt; 与 &lt;dependencies&gt; 之间的关系。&lt;pluginManagement&gt; 中也配置 &lt;plugin&gt;，其配置参数与 &lt;plugins&gt; 中的 &lt;plugin&gt; 完全一致。只是，&lt;pluginManagement&gt; 往往出现在父项目中，其中配置的 &lt;plugin&gt; 往往通用于子项目。子项目中只要在 &lt;plugins&gt; 中以 &lt;plugin&gt; 声明该插件，该插件的具体配置参数则继承自父项目中 &lt;pluginManagement&gt; 对该插件的配置，从而避免在子项目中进行重复配置。 1.2.2 &lt;reporting&gt;…&lt;/reporting&gt; 中的配置作用于 Maven 的 site 阶段( 见 Maven 生命周期)，用于生成报表。 中也可以配置插件 ，并通过一个 的 为该插件配置参数。注意，对于同时出现在 和 中的插件， 中对该插件的配置也能够在构建过程中生效，即该插件的配置是和中的配置的合并。 1.3 Environment Settings&lt;SCM&gt;…&lt;/SCM&gt; Maven中为我们集成了软件配置管理的（SCM：Software Configuration Management）功能，他可以支持我们常用SVN、CVS等，共支持18个命令： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&gt;&gt; scm:branch - branch the project（创建项目的分支）&gt;&gt; scm:validate - validate the scm information in the pom（校验SCM的配置信息）&gt;&gt; scm:add - command to add file（增加一个文件）&gt;&gt; scm:unedit - command to stop editing the working copy（停止编辑当前COPY）&gt;&gt; scm:export - command to get a fresh exported copy（拉一个全新的分支）&gt;&gt; scm:bootstrap - command to checkout and build a project（checkout并编译工程）&gt;&gt; scm:changelog - command to show the source code revisions（显示源码版本）&gt;&gt; scm:list - command for get the list of project files（列出工程的文件）&gt;&gt; scm:checkin - command for commiting changes（提交变更）&gt;&gt; scm:checkout - command for getting the source code（获取源码）&gt;&gt; scm:status - command for showing the scm status of the working copy（获取本地项目的状态）&gt;&gt; scm:update - command for updating the working copy with the latest changes（从服务器获取最新的版本）&gt;&gt; scm:diff - command for showing the difference of the working copy with the remote one（比较本地与远程服务器的差异）&gt;&gt; scm:update-subprojects - command for updating all projects in a multi project build（更新子项目）&gt;&gt; scm:edit - command for starting edit on the working copy（编辑）&gt;&gt; scm:tag - command for tagging a certain revision（打标签）&gt;&gt; &gt;&gt; ``` _tips：而其中的 `mvn scm:checkin`, `mvn scm:update`是其中比较常用的命令。_比如，对 `git` 的配置如下：&gt; ```xml&gt; &lt;project&gt;&gt; &gt; ...&gt; &gt; &lt;scm&gt; &gt; &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。--&gt; &gt; &lt;connection&gt; &gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &gt; &lt;/connection&gt; &gt; &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读--&gt; &gt; &lt;developerConnection&gt; &gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &gt; &lt;/developerConnection&gt; &gt; &lt;!--当前代码的标签，在开发阶段默认为HEAD--&gt; &gt; &lt;tag/&gt; &gt; &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。--&gt; &gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &gt; &lt;/scm&gt; &gt; &gt; &lt;plugin&gt;&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt;&gt; &lt;version&gt;2.5.3&lt;/version&gt;&gt; &lt;configuration&gt;&gt; &lt;tagBase&gt;$&#123;git.conn&#125;&lt;/tagBase&gt;&gt; &lt;branchBase&gt;$&#123;git.conn&#125;&lt;/branchBase&gt;&gt; &lt;username&gt;$&#123;git.username&#125;&lt;/username&gt;&gt; &lt;password&gt;$&#123;git.password&#125;&lt;/password&gt;&gt; &lt;/configuration&gt;&gt; &lt;/plugin&gt;&gt; &gt; ...&gt; &gt; &lt;/project&gt;&gt; &lt;distributionManagement&gt;…&lt;/distributionManagement&gt; maven 中的仓库分为两种，snapshot 快照仓库和 release 发布仓库。snapshot 快照仓库用于保存开发过程中的不稳定版本，release 正式仓库则是用来保存稳定的发行版本。定义一个组件/模块为快照版本，只需要在 pom 文件中在该模块的版本号后加上-SNAPSHOT即可(注意这里必须是大写)，在distributionManagement段中配置的是snapshot快照库和release发布库的地址。 1234567891011121314&lt;project&gt; &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。--&gt; &lt;distributionManagement&gt; &lt;!--部署项目产生的构件到远程仓库需要的信息--&gt; &lt;repository&gt; &lt;id&gt;$&#123;distribution.releases.id&#125;&lt;/id&gt; &lt;url&gt;$&#123;distribution.releases.url&#125;&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;$&#123;distribution.snapshots.id&#125;&lt;/id&gt; &lt;url&gt;$&#123;distribution.snapshots.url&#125;&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt;&lt;/project&gt; &lt;profiles&gt;…&lt;/profiles&gt; 不同环境的构建很可能是不同的，典型的情况就是数据库的配置。要想使得一个构建不做任何修改就能在任何环境下运行，往往是不可能的，为了能让构建在各个环境下方便地移植，Maven 引入了 profile 的概念，profile 能够在构建的时候选择性的激活 pom.xml 中的元素。用户可以使用很多方式激活 profile，以实现构建在不同环境下的移植。123456789101112131415161718192021&gt; &lt;project xmlns="http://maven.apache.org/POM/4.0.0"&gt; xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt; xsi:schemaLocation="http://maven.apache.org/POM/4.0.0&gt; https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&gt; ...&gt; &lt;profiles&gt;&gt; &lt;profile&gt;&gt; &lt;id&gt;test&lt;/id&gt;&gt; &lt;activation&gt;...&lt;/activation&gt;&gt; &lt;build&gt;...&lt;/build&gt;&gt; &lt;modules&gt;...&lt;/modules&gt;&gt; &lt;repositories&gt;...&lt;/repositories&gt;&gt; &lt;pluginRepositories&gt;...&lt;/pluginRepositories&gt;&gt; &lt;dependencies&gt;...&lt;/dependencies&gt;&gt; &lt;reporting&gt;...&lt;/reporting&gt;&gt; &lt;dependencyManagement&gt;...&lt;/dependencyManagement&gt;&gt; &lt;distributionManagement&gt;...&lt;/distributionManagement&gt;&gt; &lt;/profile&gt;&gt; &lt;/profiles&gt;&lt;/project&gt;&gt; 2. pom.xml 完整注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.seyvoue.demo生成的相对路径为：/com/seyvoue/demo--&gt; &lt;groupId&gt;com.seyvoue.demo&lt;/groupId&gt; &lt;!-- 构件的标识符，它和 groupId 一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的 artifactId 和 groupId；在某个特定的 groupId 下，artifactId也必须是唯一的。--&gt; &lt;artifactId&gt;demo-maven&lt;/artifactId&gt; &lt;!-- 项目当前版本，格式为:主版本.次版本.增量版本-限定版本号--&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;!-- 项目产生的构件类型，例如 jar、war、pom 等。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型--&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- 项目的名称，Maven产生的文档用--&gt; &lt;name&gt;project-demo&lt;/name&gt; &lt;!-- 项目主页的URL，Maven产生的文档用--&gt; &lt;url&gt;http://demo.seyvoue.com&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。--&gt; &lt;description&gt;A demo of maven project to study maven.&lt;/description&gt; &lt;parent&gt; &lt;!--被继承的父项目的构件标识符--&gt; &lt;artifactId/&gt; &lt;!--被继承的父项目的全球唯一标识符--&gt; &lt;groupId/&gt; &lt;!--被继承的父项目的版本--&gt; &lt;version/&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。--&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!--依赖的group ID--&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!--依赖的artifact ID--&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。--&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。--&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。--&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用--&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例&#123;java. home&#125;。--&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。--&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules&gt; &lt;module&gt;account-email&lt;/module&gt; &lt;module&gt;account-persist&lt;/module&gt; ... &lt;/modules&gt; &lt;scm&gt; &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。--&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读--&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!--当前代码的标签，在开发阶段默认为HEAD--&gt; &lt;tag/&gt; &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。--&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。--&gt; &lt;distributionManagement&gt; &lt;!--部署项目产生的构件到远程仓库需要的信息--&gt; &lt;repository&gt; &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素--&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素--&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout/&gt; &lt;/snapshotRepository&gt; &lt;!--部署项目的网站需要的信息--&gt; &lt;site&gt; &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置--&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!--部署位置的名称--&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!--部署位置的URL，按protocol://hostname/path形式--&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。--&gt; &lt;downloadUrl/&gt; &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。--&gt; &lt;relocation&gt; &lt;!--构件新的group ID--&gt; &lt;groupId/&gt; &lt;!--构件新的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--构件新的版本号--&gt; &lt;version/&gt; &lt;!--显示给用户的，关于移动的额外信息，例如原因。--&gt; &lt;message/&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。--&gt; &lt;status/&gt; &lt;/distributionManagement&gt; &lt;build&gt; &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--&gt; &lt;defaultGoal&gt;install&lt;/defaultGoal&gt; &lt;!--build目标文件的存放目录，默认在 $&#123;basedir&#125;/target 目录--&gt; &lt;directory&gt;$&#123;basedir&#125;/target&lt;/directory&gt; &lt;finalName&gt;$&#123;artifactId&#125;-$&#123;version&#125;&lt;/finalName&gt; &lt;filters&gt; &lt;filter&gt;filters/filter1.properties&lt;/filter&gt; &lt;/filters&gt; &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--&gt; &lt;resources&gt; &lt;!--这个元素描述了项目相关或测试相关的所有资源路径--&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例 子，如果你想资源在特定的包里( org.apache.maven.message，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--&gt; &lt;targetPath/&gt; &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--&gt; &lt;filtering/&gt; &lt;!--描述存放资源的目录，该路径相对POM路径--&gt; &lt;directory/&gt; &lt;!--包含的模式列表，例如**/*.xml.--&gt; &lt;includes/&gt; &lt;!--排除的模式列表，例如**/*.xml--&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--&gt; &lt;testResources&gt; &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--&gt; &lt;testResource&gt; &lt;targetPath/&gt; &lt;filtering/&gt; &lt;directory/&gt; &lt;includes/&gt; &lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;configuration&gt; &lt;tagBase&gt;$&#123;git.conn&#125;&lt;/tagBase&gt; &lt;branchBase&gt;$&#123;git.conn&#125;&lt;/branchBase&gt; &lt;username&gt;$&#123;git.username&#125;&lt;/username&gt; &lt;password&gt;$&#123;git.password&#125;&lt;/password&gt; &lt;/configuration&gt; &lt;/plugin&gt; ... &lt;/plugins&gt; &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--&gt; &lt;pluginManagement&gt; &lt;plugins&gt; ... &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 参考 POM Reference — Apache Maven Project pom.xml 详解 — adeyi Maven实战 — 许晓斌 dependency 中的 classifier属性 利用maven的filter和profile实现不同环境使用不同的配制 使用 maven profile Maven多环境配置实战 filter Maven Dependency Scope Maven基本命令 仓库 坐标 依赖 聚合 继承 pom.xml详解 Maven pom.xml 配置详解]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@SSH 远程登录的实现]]></title>
    <url>%2Fmanual%2F68483533.html</url>
    <content type="text"><![CDATA[环境：macOS+iterm2目的： 实现 mac 通过 iterm2 shell 以口令登录远程主机（即需要输入密码，才能登录远程主机） 实现 mac 通过 iterm2 shell 以公钥登录远程主机(即不需要每次都输入密码，就能登录远程主机) 口令登录如果远程主机的信息如下： host ip: 192.168.1.101username: userhostname: host 运行以下命令即可登录远程主机 12# 直接 ssh 远程主机的 IP，回车，然后输入口令即可$ ssh user@192.168.1.101 公钥登录使用密码登录，每次都必须输入密码，非常麻烦。好在SSH还提供了公钥登录，可以省去输入密码的步骤。 创建公私钥使用 ssh-keygen 生成公私钥 1$ ssh-keygen -t rsa -C "your_email@example.com" 运行上面的命令以后，系统会出现一系列提示，可以一路回车。其中有一个问题是，要不要对私钥设置口令（passphrase），如果担心私钥的安全，这里可以设置一个。 系统默认会在 $HOME$/.ssh/ 目录下生成两个文件: id_rsa 和 id_rsa.pub，其中id_rsa.pub 就是我们需要的公钥。 将公钥上传到远程主机 host 上输入下面的命令，将公钥传送到远程主机host 1$ ssh-copy-id user@host 如果还是不行，就打开远程主机的 /etc/ssh/sshd_config 这个文件，确保文件中存在以下内容，且未被 # 注释掉 123RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 至此，你便实现了通过公钥登录远程主机，即通过当前的电脑登录远程主机，不再需要手动输入密码。 authorized_keys 文件远程主机 $HOME/.ssh/ 目录下的 authorized_keys 文件，用于保存那些通过公钥方式登录的客户端的公钥。也就是说，上文 ssh-copy-id 命令，将公钥内的信息复制到了远程主机的 authorized_key 文件中。 参考链接 SSH原理与作用—阮一峰]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@MySQL语法之JOIN]]></title>
    <url>%2Flanguages%2Fbd53954e.html</url>
    <content type="text"><![CDATA[如果数据存储在多个表中，如何用一条 SELECT 语句就检索出数据呢？—— 使用联结(join) 通过一个简单的例子理解 mysql 中的： INNER JOIN LETF OUTTER JOIN (or sometimes called LEFT JOIN) RIGHT OUTTER JOIN (or sometimes called RIGHT JOIN) 案例： 现有两张表 suppliers、orders，两表通过字段 supplier_id 关联。 suppliers table supplier_id supplier_name 10000 IBM 10001 Hewlett Packard 10002 Microsoft 10003 NVIDIA orders table order_id supplier_id order_date 500125 10000 2017/05/12 500126 10001 2017/05/13 500127 10004 2017/05/14 INNER JOIN使用 INNER JOIN 对于两张关联的表 table1 和 table2 进行查询时，返回的是两张表的交集，即 $table1 \bigcap table2$，如下图： 对于案例中的 table 执行下面的 INNER JOIN 语句 1234SELECT suppliers.supplier_id, suppliers.supplier_name, orders.order_dateFROM suppliersINNER JOIN ordersON suppliers.supplier_id = orders.supplier_id; 执行结果： supplier_id supplier_name order_date 10000 IBM 2017/05/12 10001 Hewlett Packard 2017/05/13 LEFT OUTTER JOIN使用 LEFT OUTTER JOIN 对于两张关联的表 table1 和 table2 进行查询时，返回的是 $table1 \bigcap table2$ 以及 $table1 - table2$，如下图： 对于案例中的 table 执行下面的 LEFT OUTTER JOIN 语句 1234SELECT suppliers.supplier_id, suppliers.supplier_name, orders.order_dateFROM suppliersLEFT JOIN ordersON suppliers.supplier_id = orders.supplier_id; 执行结果： supplier_id supplier_name order_date 10000 IBM 2017/05/12 10001 Hewlett Packard 2017/05/13 10002 MICROSOFT 10003 NVIDIA RIGHT OUTTER JOIN使用 LEFT OUTTER JOIN 对于两张关联的表 table1 和 table2 进行查询时，返回的是 $table1 \bigcap table2$ 以及 $table2 - table1$，如下图： 对于案例中的 table 执行下面的 LEFT OUTTER JOIN 语句 1234SELECT orders.order_id, orders.order_date, suppliers.supplier_name, orders.supplier_idFROM suppliersRIGHT JOIN ordersON suppliers.supplier_id = orders.supplier_id; 执行结果： order_id order_date supplier_name supplier_id 500125 2017/05/12 IBM 10000 500126 2017/05/13 Hewlett Packard 10001 500127 2017/05/14 10004 结果表明，对于 supplier_id=10004，虽然不满足 suppliers.supplier_id = orders.supplier_id，但由于语句中用的是 RIGHT JOIN 且该条记录是在 orders 表中，所以还是会被返回。 参考 MySQL: JOIN Mysql Join语法解析与性能分析]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@MySQL 聚合函数 分组和排序]]></title>
    <url>%2Flanguages%2F8543dcef.html</url>
    <content type="text"><![CDATA[案例表 OrderItems：存储每个订单中的实际物品，每个订单中的每个物品一行， 问题： 现需要检索出订单中包含3个以上物品的订单号，以及订单数量，并且按物品订购数目排序输出。 执行： 12345SELECT order_num, COUNT(*) AS itemsFROM OrderItemsGROUP BY order_numHAVING COUNT(*) &gt;=3ORDER BY items, order_nums 输出： 参考 MySQL: GROUP BY Clause MySQL: ORDER BY Clause MySQL: HAVING Clause]]></content>
      <categories>
        <category>languages</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@如何快速找到高清电子书和视频资源]]></title>
    <url>%2Fmanual%2F51ebc9b4.html</url>
    <content type="text"><![CDATA[收集了一些下载高清电子书/视频资源的网站，亲测可用。 电子书资源英文电子书 IT eBooks SaltTiger EBOOKEE Library Genesis 七彩英语 FREE BOOKS IN PDF 中文电子书 鸠摩搜索 皮皮书屋搜索(镜像) 爱问共享资料 搜狗微信搜索 浩扬电子书城 读秀 超星 读远 好读 益书网 掌上书苑 mlook( 需要邀请码才能注册 ) 网上读书园地(需要邀请码才能注册) kindle 人社区 kindle 伴侣 电影资源英文资源 torrentkitty the pirate bay EZTV 中文资源 80s BT天堂 网盘资源 胖次网盘搜索 麦库搜索 去转盘网 西林街 云搜 参考 如何搜索和下载mobi或epub格式电子书—kindle 伴侣 google 高级搜索—小土刀]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>effectiveness</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@在 CentOS Linux 中安装 Hadoop-1.2.1 ( single-node cluster)]]></title>
    <url>%2Fmanual%2F17188a01.html</url>
    <content type="text"><![CDATA[本文介绍如何在 CentOS7 中以伪分布式模式 ( Pseudo-Distributed Mode ) 运行 Hadoop-1.2.1。 前期准备安装 Linux 系统可参考这篇“@Vmware Funsion8.5中安装 CentOS 7(macOS Sierra)” 建议在虚拟机下安装 Linux 系统，并善用虚拟机的 snapshot 功能，可以节省很多时间。 安装 JDK1.8 并设置环境变量可参考这篇”@Linux 系统下 JDK 安装与配置“ Hadoop 的安装及配置 Hadoop 版本有很多，建议安装 hadoop.1.2.1 或 hadoop 的最新版本。本文以 hadoop-1.2.1 为例。另外，Hadoop Wiki 上有更系统更权威的资料。 step1：下载安装 Hadoop 在 Apache Download Mirrors 下载 hadoop-1.2.1.tar.gz ( 或者下载 hadoop-2.8.0.tar.gz ) 将下载的包解压缩到 /usr，如下： 12345678# 切换到 root 身份[zodas@localhost ~]$ su# 将下载到桌面上的包 hadoop-1.2.1.tar.gz 拷贝到 /opt/installpackages 目录下[root@localhost zodas]# cp ./Desktop/hadoop-1.2.1.tar.gz /opt/installpackages# 切换工作目录到 /opt[root@localhost zodas]# cd /opt# 将 hadoop-1.2.1.tar.gz 解压到 /opt 目录下[root@localhost opt]# tar -xvzf /opt/installpackages/hadoop-1.2.1.tar.gz step2：修改环境变量 /etc/profile 打开终端输入vi /etc/profile，增加以下内容，配置 Hadoop 环境变量： 123# Hadoop export HADOOP_HOME=/opt/hadoop-1.2.1export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 打开终端输入source /etc/profile，使新添加的环境变量立即生效 打开终端输入hadoop version，验证环境变量是否配置成功 注：由于是在 /etc/profile 中配置的环境变量，所以建议配置完后重启一次系统，让环境变量永久生效 step3：配置hadoopHadoop-1.2.1 的配置文件默认是放在其 conf/ 目录下，我们只需要配置其中的4个文件即可，分别是：hadoop-env.sh, core-site.xml, hdfs-site.xml, mapred-site.xml。 hadoop-env.sh在该文件中我们只需要修改 JAVA_HOME 这一变量的值为 JDK 安装的真实路径即可，如果按照笔者的教程操作的话，JAVA_HOME=/opt/jdk1.8.0，修改内容如下： Change hadoop-env.sh 12# The java implementation to use. Required.# export JAVA_HOME=/usr/lib/j2sdk1.5-sun to 12# The java implementation to use. Required.export JAVA_HOME=/opt/jdk1.8.0_131 conf/*-site.xml conf/core-site.xom 修改为： 12345678910111213&lt;configuration&gt; &lt;!-- hadoop.tmp.dir 是hadoop文件系统依赖的基础配置，很多路径都依赖它。如果 hdfs-site.xml 中不配置namenode和datanode的存放位置，默认就放在这个路径中--&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/workspace/hadoop/hdfs/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- fs.default.name 这是一个描述集群中NameNode结点的URI(包括协议、主机名称、端口号)，集群里面的每一台机器都需要知道NameNode的地址。DataNode结点会先在NameNode上注册，这样它们的数据才可以被使用。独立的客户端程序通过这个URI跟DataNode交互，以取得文件的块列表。--&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; conf/mapred-site.xml 修改为： 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;localhost:9001&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; conf/hdfs-site.xml 修改为： 12345678910111213141516171819&lt;configuration&gt; &lt;!-- dfs.replication 它决定着 系统里面的文件块的数据备份个数。对于一个实际的应用，它应该被设为3（这个数字并没有上限，但更多的备份可能并没有作用，而且会占用更多的空间）。少于三个的备份，可能会影响到数据的可靠性(系统故障时，也许会造成数据丢失)--&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;!-- dfs.data.dir 这是DataNode结点被指定要存储数据的本地文件系统路径。DataNode结点上的这个路径没有必要完全相同，因为每台机器的环境很可能是不一样的。但如果每台机器上的这个路径都是统一配置的话，会使工作变得简单一些。默认的情况下，它的值hadoop.tmp.dir, 这个路径只能用于测试的目的，因为，它很可能会丢失掉一些数据。所以，这个值最好还是被覆盖--&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/usr/workspace/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;!-- dfs.name.dir 这是NameNode结点存储hadoop文件系统信息的本地系统路径。这个值只对NameNode有效，DataNode并不需要使用到它。上面对于/temp类型的警告，同样也适用于这里。在实际应用中，它最好被覆盖掉。--&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/usr/workspace/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; step4：修改 Hadoop 工作目录的 owner 和 group建议创建一个新的群组，并将用户添加到该新群组中，否则，在 hadoop namenode -format 可能会报 Cannot create directory /usr/workspace/hadoop/hdfs/name/current 的错误，这是因为新创建的 workspace 目录其owner=root, group=root，所以 Hadoop 在 -format 无法自动创建需要的目录，解决办法是修改 workspace/hadoop/ 及其子目录的 owner 和 group。 创建一个新的群组hadoop(名字随意) 12345# 创建一个新的群组 hadoop[zodas@localhost ~]$ sudo groupadd hadoop# 将用户 zodas 添加到新的群组中 [zodas@localhost ~]$ sudo usermod -G hadoop zodas 修改工作目录的权限 12345678[zodas@localhost ~]$ cd /usr[zodas@localhost usr]$ sudo mkdir -p /usr/workspace/hadoop/hdfs# 修改 workspace 目录及其子目录的 owner=zodas, group=hadoop [zodas@localhost usr]$ sudo chown -R zodas:hadoop workspace/# 修改 workspace 目录及其子目录的 权限为 rwxrwxr-x(即775)[zodas@localhost usr]$ sudo chmod -R g+w workspace/ 同上，修改 /opt/hadoop-1.2.1 的拥有者及群组为 zodas:hadoop 12[zodas@localhost ~]$ sudo chown -R zodas:hadoop /opt/hadoop-1.2.1[zodas@localhost ~]$ sudo chmod -R g+x /opt/hadoop-1.2.1 step5：配置 SSH 免密码登录不了解 SSH 的，可参考阮一峰的这篇博文”SSH原理与运用（一）：远程登录“ CentOS 默认是已经安装了 OpenSSH的，可在终端中输入ssh -V，查看已安装的OpenSSH版本 使用 ssh-keygen 生成公私钥： 12# 生成公私钥。会在 ~/.ssh 目录下生成两个文件：id_rsa.pub 和 id_rsa[zodas@localhost ~]$ ssh-keygen -t rsa -P "" tips：-P 表示密码，-P &quot;&quot; 就表示空密码，也可以不用 -P 参数，这样就要三次回车，用 -P 就一次回车。 再输入下面的命令，将公钥传送到远程主机host上面： 12[zodas@localhost ~]$ ssh-copy-id zodas@localhost 好了，从此你再登录，就不需要输入密码了。 如果还是不行，就打开 /etc/ssh/sshd_config 这个文件，检查下面几行前面”#”注释是否取掉 123RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 重启远程主机的ssh服务。 1234# ubuntu系统service ssh restart# debian系统/etc/init.d/ssh restart 打开终端输入ssh zodas@localhost，若能不输入密码即可登录主机 localhost，则表示 SSH 免密码登录配置成功 另外，Ubuntu 默认是没有安装 openssh-server，这也是为什么在/etc/ssh 目录下找不到 sshd_config 文件。解决方案执行sudo apt-get install openssh-server 安装 openssh-server 启动 HadoopFormatting the HDFS filesystem via the namenode运行: 1[zodas@localhost ~]hadoop namenode -format 输出类似于以下： 123456789101112131415161718192021222324252627282930313233343536[zodas@localhost ~]$ hadoop namenode -formatWarning: $HADOOP_HOME is deprecated.17/07/10 11:13:31 INFO namenode.NameNode: STARTUP_MSG: /************************************************************STARTUP_MSG: Starting NameNodeSTARTUP_MSG: host = ./192.168.12.184STARTUP_MSG: args = [-format]STARTUP_MSG: version = 1.2.1STARTUP_MSG: build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by &apos;mattf&apos; on Mon Jul 22 15:23:09 PDT 2013STARTUP_MSG: java = 1.8.0_131************************************************************/17/07/10 11:13:31 INFO util.GSet: Computing capacity for map BlocksMap17/07/10 11:13:31 INFO util.GSet: VM type = 64-bit17/07/10 11:13:31 INFO util.GSet: 2.0% max memory = 101364531217/07/10 11:13:31 INFO util.GSet: capacity = 2^21 = 2097152 entries17/07/10 11:13:31 INFO util.GSet: recommended=2097152, actual=209715217/07/10 11:13:31 INFO namenode.FSNamesystem: fsOwner=zodas17/07/10 11:13:31 INFO namenode.FSNamesystem: supergroup=supergroup17/07/10 11:13:31 INFO namenode.FSNamesystem: isPermissionEnabled=true17/07/10 11:13:31 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=10017/07/10 11:13:31 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)17/07/10 11:13:31 INFO namenode.FSEditLog: dfs.namenode.edits.toleration.length = 017/07/10 11:13:31 INFO namenode.NameNode: Caching file names occuring more than 10 times 17/07/10 11:13:32 ERROR namenode.NameNode: java.io.IOException: Cannot create directory /usr/workspace/hadoop/hdfs/name/current at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.clearDirectory(Storage.java:294) at org.apache.hadoop.hdfs.server.namenode.FSImage.format(FSImage.java:1337) at org.apache.hadoop.hdfs.server.namenode.FSImage.format(FSImage.java:1356) at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1261) at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1467) at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1488)17/07/10 11:13:32 INFO namenode.NameNode: SHUTDOWN_MSG: /************************************************************SHUTDOWN_MSG: Shutting down NameNode at ./192.168.12.184************************************************************/ Starting single-node cluster运行： 1[zodas@localhost ~]$ start-all.sh 输出： 1234567891011121314[zodas@ ~]$ start-all.sh Warning: $HADOOP_HOME is deprecated.starting namenode, logging to /opt/hadoop-1.2.1/libexec/../logs/hadoop-zodas-namenode-..outlocalhost: Warning: $HADOOP_HOME is deprecated.localhost: localhost: starting datanode, logging to /opt/hadoop-1.2.1/libexec/../logs/hadoop-zodas-datanode-..outlocalhost: Warning: $HADOOP_HOME is deprecated.localhost: localhost: starting secondarynamenode, logging to /opt/hadoop-1.2.1/libexec/../logs/hadoop-zodas-secondarynamenode-..outstarting jobtracker, logging to /opt/hadoop-1.2.1/libexec/../logs/hadoop-zodas-jobtracker-..outlocalhost: Warning: $HADOOP_HOME is deprecated.localhost: localhost: starting tasktracker, logging to /opt/hadoop-1.2.1/libexec/../logs/hadoop-zodas-tasktracker-..out 用 jps 命令查看 java 进程，验证伪分布式集群是否安装成功 运行： 1[zodas@localhost ~]$ jps 输出： 1234567[zodas@localhost ~]$ jps7431 Jps7192 TaskTracker6858 DataNode6989 SecondaryNameNode7069 JobTracker6735 NameNode Stoping single-node cluster运行： 1[zodas@localhost ~]$ stop-all.sh 输出： 1234567891011121314[zodas@localhost ~]$ stop-all.sh Warning: $HADOOP_HOME is deprecated.stopping jobtrackerlocalhost: Warning: $HADOOP_HOME is deprecated.localhost: localhost: stopping tasktrackerstopping namenodelocalhost: Warning: $HADOOP_HOME is deprecated.localhost: localhost: stopping datanodelocalhost: Warning: $HADOOP_HOME is deprecated.localhost: localhost: stopping secondarynamenode 参考 Hadoop DOC SSH 原理与运用(一)—阮一峰 Running Hadoop on Ubuntu Linux (Single-Node Cluster)—Michael G. Noll Hadoop 的安装—brain9999 linux的 CP 命令—董俊杰 rpm命令—linux 命令大全 linux 下的 tar压缩解压缩命令详解 SSH远程登录配置文件sshd_config详解 Linux添加/删除用户和用户组—董俊杰]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Vmware Funsion8.5中安装 CentOS 7(macOS Sierra)]]></title>
    <url>%2Fmanual%2Fae6c2890.html</url>
    <content type="text"><![CDATA[step1: 安装虚拟机 VMware Fusion8 VMware 的安装破解非常简单，可以直接下载最新的官方包，在网上基本都能搜到可用的序列号去激活。 方式一： 官网下载 VMware Fusion8 pro 使用下方的序列号完成激活，若序列号不可用，再使用下方的注册机完成激活。 12345678序列号：FY75A-06W1M-H85PZ-0XP7T-MZ8E8ZY7TK-A3D4N-08EUZ-TQN5E-XG2TFFG1MA-25Y1J-H857P-6MZZE-YZAZ6注册机：链接: http://pan.baidu.com/s/1t1aMy 密码: 3vkq 方式二：参考：VMware Fusion 8.5.3 Mac 破解版—史蒂芬周 step2: 在虚拟机中安装 Linux 系统(CentOS7) 官网下载 centos-DVD 版 参考此文安装 建议虚拟机给 2G 内存，60G 以上磁盘空间（由于个人可能会在 linux 中安装 oracle 等大型软件） 另外，对于刚接触 Linux 系统的用户，推荐鸟哥的 Linux 私房菜 ；也可参考 鸟哥 的安裝 CentOS7.x，里面涉及了 Linux 中如何分区的问题，以及 GPT 模式安装。]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@CentOS7 下 JDK 安装与配置]]></title>
    <url>%2Fmanual%2F7a78fd34.html</url>
    <content type="text"><![CDATA[step1：卸载 OpenJDK (建议卸载)Centos 系统默认是已经安装了 OpenJDK 的，这也就是为什么在你刚装好 CentOS 时，在终端输入java -version 这串命令时，不会返回Command not found 的错误，如下图： 方式一：yum 方式卸载 OpenJDK1234# 查询与Java 相关的包[zodas@localhost ~]$ yum list java*# 卸载[zodas@localhost ~]$ yum -y remove java* 方式二：rpm 方式卸载 OpenJDK 在终端依次输入以下指令，便可卸载 OpenJDK 12345678# 查询系统中已安装的与 OpenJDK 有关的包[zodas@localhost ~]$ rpm -qa | grep java# 切换到 root 身份[zodas@localhost ~]$ su# 只需卸载以下3个包即可[root@localhost zodas]# rpm -e --nodeps tzdata-java-2016g-2.el7.noarch[root@localhost zodas]# rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64[root@localhost zodas]# rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64 终端输入java -version ，验证是否安装成功，出现Command not found，则表示卸载成功。 step2：安装 JDK方式一：Wget 方式安装1234# JDK 的下载路径可从官网获得，JDK 的 rmp 包将会下载到当前目录[zodas@localhost ~]$ wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.rpm# JDK将会安装在 /usr/java 目录下[zodas@localhost ~]$ rpm -ivh jdk-8u181-linux-x64.rpm 方式二：RPM 方式安装 JDK 官网下载 jdk-8u131-linux-x64.rpm 将下载的jdk-8u131-linux-x64.rpm放到桌面，打开终端(terminal)依次输入以下指令： 123456# 先切换到 root 身份[zodas@localhost ~]$ su# 切换工作目录到 Desktop[root@localhost zodas]# cd Desktop/# 使用 rmp 命令安装 JDK[root@localhost zodas]# rpm -ivh jdk-8u131-linux-x64.rpm tips: 执行rpm -ivh jdk-8u131-linux-x64.rpm 后，不断按回车默认安装就可以了 方式三：手动解压安装 JDK 官网下载 jdk-8u131-linux-x64.tar.gz 将下载的jdk-8u131-linux-x64.tar.gz放到桌面，打开终端(terminal)依次输入以下指令： 12345678# 先切换到 root 身份[zodas@localhost ~]$ su# 将 jdk-8u131-linux-x64.tar.gz 拷贝到 /opt/installpackages 目录下[root@localhost zodas]# mkdir /opt/installpackages[root@localhost zodas]# cp ./Desktop/jdk-8u131-linux-x64.tar.gz /opt/installpackages/# 将 JDK 解压到 /opt 目录下[root@localhost zodas]# cd /opt[root@localhost opt]# tar -xzvf /opt/installpackages/jdk-8u131-linux-x64.tar.gz step3：配置 Java 环境变量若想让系统下所有用户均使用相同的环境变量，建议在/etc/profile.d目录下创建相应的脚本，而不是直接修改 /etc/profile 文件；若只是为当前用户配置环境变量，则在 ~/.bash_profile文件中配置环境变量。 123[root@localhost ~]# cd /etc/profile.d[root@localhost profile.d]# touch java.sh[root@localhost profile.d]# vi java.sh 在 java.sh 文件中输入以下内容 1234JAVA_HOME = /usr/java/jdk1.8.0_181-amd64PATH = $JAVA_HOME/bin:$PATHexport JAVA_HOMEexport PATH 然后修改 java.sh 文件的权限为755 1[root@localhost profile.d]# chmod 755 /etc/profile.d/java.sh 另外，如果按照以上步骤配置 JDK 环境变量后，新开一个终端，输入java -version后，仍然出现Command not found 的问题？每次都必须重新输入source /etc/profile，才能解决上述的问题，这是为什么？明明已经配置好环境变量了？！具体原因可参考”@Shell 的两种启动方式以及环境变量的配置“解决办法：方法一修改完/etc/profile 后，重启系统，使环境变量永久生效。 方法二 打开终端输入vi .bashrc，即打开用户目录下的.bashrc文件 修改文件中的内容，增加. /etc/profile这一行 12345# Source global definitionsif [ -f /etc/bashrc ]; then . /etc/bashrc . /etc/profilefi]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@高效写作 sublime3+markdown+evernote]]></title>
    <url>%2Fmanual%2Fb67313b.html</url>
    <content type="text"><![CDATA[本文介绍在 SublimeText3(下文统一简称为 ST3)下用 markdown 语法写文章/笔记，并同步到 Evernote 中。 对于有强迫症的我来说，一直在寻找一个工具，具备以下功能： 手可以不离开键盘(即尽可能的不需要用鼠标进行操作)，便可以实现，如：加粗，多级标题，表格，列表，加粗，斜体，数学公式等基本格式 写好的笔记不仅可以保留在本地，同时还可以自动同步到 evernote 以做备份 类似于系统自带的文本编辑器，界面简单，且支持打开各种文本格式的文件 敲代码与写作两不误，不再需要在各种软件间频繁的切换 … Markdown 是一种非常方便非常容易上手的写作格式，你只要记住十来种最多几十种大不了上百种语法，就可以轻松地写出各种格式的文章了；Evernote 是个笔记软件，其功能类似于 Microsoft 的 OneNote； 下载安装 SublimeText3step1: 下载SublimeText3step2: 在 ST3 中安装 package control 插件，安装方法参考这篇文章 配置 SublimeText安装以下插件: MarkdownEditing Markdown 编辑及语法高亮支持 MarkdownExtended Markdown syntax highlighter for Sublime Text, with extended support for GFM fenced code blocks. MonokaiExtended 不错的 markdown 主题，支持多种语言高亮 MarkdownPreviewMac 用户依次点击菜单栏中的Preferences -&gt; Package Settings -&gt; Markdown Preview -&gt; Settings-User打开用户设置文件，加入如下内容： 1234567891011121314151617181920212223242526&#123; "parser": "github", "build_action": "browser", "enable_mathjax": true, "enable_uml": true, "enable_highlight": true, "enable_pygments": true, "enabled_parsers": ["github"], "github_mode": "markdown", "github_inject_header_ids": true, "enable_autoreload": false, "enable_mathjax": true, "enable_highlight": true, "enabled_extensions": [ "extra", "github", "toc", "headerid", "meta", "sane_lists", "smarty", "wikilinks", "admonition", "codehilite(guess_lang=False,pygments_style=emacs)" ]&#125; Table Editor Markdown中的表格书写体验很差，所以有人为这个开发了一个插件，具有较好的自适应性，会自动对齐，就像在 Excel 中编辑表格一样 MarkdownTOC 根据文章中的标题层次，在文章的开头自动生成目录 Mac 用户依次点击菜单栏中的Preferences -&gt; Package Settings -&gt; Markdown Preview -&gt; Settings-User打开用户设置文件，加入如下内容： 12345&#123; "default_autolink": true, "default_bracket": "round", "default_depth": 0&#125; Evernote 支持将文章同步到 Evernote 的指定笔记本中，且支持增量更新编辑过的内容。 参考 SublimeText下写作利器之MarkdownEditing 打造軟體工程師的個人筆記: Sublime Text 3 + Evernote + Markdown 用 SublimeText3编写 markdown 文档 markdown 语法手册 让文档回归本质，为什么应该用Markdown]]></content>
      <categories>
        <category>manual</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
